{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c9a37c",
   "metadata": {},
   "source": [
    "# Assignment 1 - Yoann Morello"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c41599f",
   "metadata": {},
   "source": [
    "# Part 1: collecting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7364f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6edcb53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=21.24s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "coco = COCO(annotation_file=\"/scratch/lt2316-h18-resources/coco/annotations/instances_train2017.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbb0df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.27s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "captions = COCO(annotation_file=\"/scratch/lt2316-h18-resources/coco/annotations/captions_train2017.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a4c9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'supercategory': 'person', 'id': 1, 'name': 'person'},\n",
       " 2: {'supercategory': 'vehicle', 'id': 2, 'name': 'bicycle'},\n",
       " 3: {'supercategory': 'vehicle', 'id': 3, 'name': 'car'},\n",
       " 4: {'supercategory': 'vehicle', 'id': 4, 'name': 'motorcycle'},\n",
       " 5: {'supercategory': 'vehicle', 'id': 5, 'name': 'airplane'},\n",
       " 6: {'supercategory': 'vehicle', 'id': 6, 'name': 'bus'},\n",
       " 7: {'supercategory': 'vehicle', 'id': 7, 'name': 'train'},\n",
       " 8: {'supercategory': 'vehicle', 'id': 8, 'name': 'truck'},\n",
       " 9: {'supercategory': 'vehicle', 'id': 9, 'name': 'boat'},\n",
       " 10: {'supercategory': 'outdoor', 'id': 10, 'name': 'traffic light'},\n",
       " 11: {'supercategory': 'outdoor', 'id': 11, 'name': 'fire hydrant'},\n",
       " 13: {'supercategory': 'outdoor', 'id': 13, 'name': 'stop sign'},\n",
       " 14: {'supercategory': 'outdoor', 'id': 14, 'name': 'parking meter'},\n",
       " 15: {'supercategory': 'outdoor', 'id': 15, 'name': 'bench'},\n",
       " 16: {'supercategory': 'animal', 'id': 16, 'name': 'bird'},\n",
       " 17: {'supercategory': 'animal', 'id': 17, 'name': 'cat'},\n",
       " 18: {'supercategory': 'animal', 'id': 18, 'name': 'dog'},\n",
       " 19: {'supercategory': 'animal', 'id': 19, 'name': 'horse'},\n",
       " 20: {'supercategory': 'animal', 'id': 20, 'name': 'sheep'},\n",
       " 21: {'supercategory': 'animal', 'id': 21, 'name': 'cow'},\n",
       " 22: {'supercategory': 'animal', 'id': 22, 'name': 'elephant'},\n",
       " 23: {'supercategory': 'animal', 'id': 23, 'name': 'bear'},\n",
       " 24: {'supercategory': 'animal', 'id': 24, 'name': 'zebra'},\n",
       " 25: {'supercategory': 'animal', 'id': 25, 'name': 'giraffe'},\n",
       " 27: {'supercategory': 'accessory', 'id': 27, 'name': 'backpack'},\n",
       " 28: {'supercategory': 'accessory', 'id': 28, 'name': 'umbrella'},\n",
       " 31: {'supercategory': 'accessory', 'id': 31, 'name': 'handbag'},\n",
       " 32: {'supercategory': 'accessory', 'id': 32, 'name': 'tie'},\n",
       " 33: {'supercategory': 'accessory', 'id': 33, 'name': 'suitcase'},\n",
       " 34: {'supercategory': 'sports', 'id': 34, 'name': 'frisbee'},\n",
       " 35: {'supercategory': 'sports', 'id': 35, 'name': 'skis'},\n",
       " 36: {'supercategory': 'sports', 'id': 36, 'name': 'snowboard'},\n",
       " 37: {'supercategory': 'sports', 'id': 37, 'name': 'sports ball'},\n",
       " 38: {'supercategory': 'sports', 'id': 38, 'name': 'kite'},\n",
       " 39: {'supercategory': 'sports', 'id': 39, 'name': 'baseball bat'},\n",
       " 40: {'supercategory': 'sports', 'id': 40, 'name': 'baseball glove'},\n",
       " 41: {'supercategory': 'sports', 'id': 41, 'name': 'skateboard'},\n",
       " 42: {'supercategory': 'sports', 'id': 42, 'name': 'surfboard'},\n",
       " 43: {'supercategory': 'sports', 'id': 43, 'name': 'tennis racket'},\n",
       " 44: {'supercategory': 'kitchen', 'id': 44, 'name': 'bottle'},\n",
       " 46: {'supercategory': 'kitchen', 'id': 46, 'name': 'wine glass'},\n",
       " 47: {'supercategory': 'kitchen', 'id': 47, 'name': 'cup'},\n",
       " 48: {'supercategory': 'kitchen', 'id': 48, 'name': 'fork'},\n",
       " 49: {'supercategory': 'kitchen', 'id': 49, 'name': 'knife'},\n",
       " 50: {'supercategory': 'kitchen', 'id': 50, 'name': 'spoon'},\n",
       " 51: {'supercategory': 'kitchen', 'id': 51, 'name': 'bowl'},\n",
       " 52: {'supercategory': 'food', 'id': 52, 'name': 'banana'},\n",
       " 53: {'supercategory': 'food', 'id': 53, 'name': 'apple'},\n",
       " 54: {'supercategory': 'food', 'id': 54, 'name': 'sandwich'},\n",
       " 55: {'supercategory': 'food', 'id': 55, 'name': 'orange'},\n",
       " 56: {'supercategory': 'food', 'id': 56, 'name': 'broccoli'},\n",
       " 57: {'supercategory': 'food', 'id': 57, 'name': 'carrot'},\n",
       " 58: {'supercategory': 'food', 'id': 58, 'name': 'hot dog'},\n",
       " 59: {'supercategory': 'food', 'id': 59, 'name': 'pizza'},\n",
       " 60: {'supercategory': 'food', 'id': 60, 'name': 'donut'},\n",
       " 61: {'supercategory': 'food', 'id': 61, 'name': 'cake'},\n",
       " 62: {'supercategory': 'furniture', 'id': 62, 'name': 'chair'},\n",
       " 63: {'supercategory': 'furniture', 'id': 63, 'name': 'couch'},\n",
       " 64: {'supercategory': 'furniture', 'id': 64, 'name': 'potted plant'},\n",
       " 65: {'supercategory': 'furniture', 'id': 65, 'name': 'bed'},\n",
       " 67: {'supercategory': 'furniture', 'id': 67, 'name': 'dining table'},\n",
       " 70: {'supercategory': 'furniture', 'id': 70, 'name': 'toilet'},\n",
       " 72: {'supercategory': 'electronic', 'id': 72, 'name': 'tv'},\n",
       " 73: {'supercategory': 'electronic', 'id': 73, 'name': 'laptop'},\n",
       " 74: {'supercategory': 'electronic', 'id': 74, 'name': 'mouse'},\n",
       " 75: {'supercategory': 'electronic', 'id': 75, 'name': 'remote'},\n",
       " 76: {'supercategory': 'electronic', 'id': 76, 'name': 'keyboard'},\n",
       " 77: {'supercategory': 'electronic', 'id': 77, 'name': 'cell phone'},\n",
       " 78: {'supercategory': 'appliance', 'id': 78, 'name': 'microwave'},\n",
       " 79: {'supercategory': 'appliance', 'id': 79, 'name': 'oven'},\n",
       " 80: {'supercategory': 'appliance', 'id': 80, 'name': 'toaster'},\n",
       " 81: {'supercategory': 'appliance', 'id': 81, 'name': 'sink'},\n",
       " 82: {'supercategory': 'appliance', 'id': 82, 'name': 'refrigerator'},\n",
       " 84: {'supercategory': 'indoor', 'id': 84, 'name': 'book'},\n",
       " 85: {'supercategory': 'indoor', 'id': 85, 'name': 'clock'},\n",
       " 86: {'supercategory': 'indoor', 'id': 86, 'name': 'vase'},\n",
       " 87: {'supercategory': 'indoor', 'id': 87, 'name': 'scissors'},\n",
       " 88: {'supercategory': 'indoor', 'id': 88, 'name': 'teddy bear'},\n",
       " 89: {'supercategory': 'indoor', 'id': 89, 'name': 'hair drier'},\n",
       " 90: {'supercategory': 'indoor', 'id': 90, 'name': 'toothbrush'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c6abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "annIds=captions.getAnnIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "658ff59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "591753"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annIds)   #number of captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4aa0393",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "random.shuffle(annIds)\n",
    "ran_Id=annIds[:10000]  #we will use only 1000 of them that have a unique category associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b3771b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_captions_ann=captions.loadAnns(ids=ran_Id)\n",
    "list_captions = [ann['caption'] for ann in list_captions_ann]\n",
    "list_image_ids = [ann['image_id'] for ann in list_captions_ann]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9df1444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image_id': 94120, 'id': 774868, 'caption': 'A hot dog with pickles and mustard on it.'}\n",
      "{'image_id': 393075, 'id': 433174, 'caption': 'An elderly couple sits at the end of a cement bench.'}\n",
      "{'image_id': 162414, 'id': 762105, 'caption': 'a small blue seated toilet in a small room'}\n"
     ]
    }
   ],
   "source": [
    "for ann in list_captions_ann[:3]:\n",
    "    print(ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab967a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_annot=coco.getAnnIds(imgIds=list_image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59a0f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot=coco.loadAnns(ids= list_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3564363c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': [[451.82,\n",
       "   77.71,\n",
       "   464.26,\n",
       "   88.43,\n",
       "   470.84,\n",
       "   91.12,\n",
       "   525.44,\n",
       "   103.06,\n",
       "   558.35,\n",
       "   108.42,\n",
       "   564.44,\n",
       "   108.18,\n",
       "   575.17,\n",
       "   97.7,\n",
       "   576.39,\n",
       "   83.07,\n",
       "   575.66,\n",
       "   75.51,\n",
       "   568.83,\n",
       "   68.93,\n",
       "   553.23,\n",
       "   61.13,\n",
       "   531.78,\n",
       "   59.18,\n",
       "   519.59,\n",
       "   57.96,\n",
       "   502.53,\n",
       "   53.58,\n",
       "   485.95,\n",
       "   49.68,\n",
       "   467.91,\n",
       "   48.21,\n",
       "   461.58,\n",
       "   48.21,\n",
       "   455.48,\n",
       "   52.11,\n",
       "   451.82,\n",
       "   61.13,\n",
       "   448.17,\n",
       "   70.64,\n",
       "   452.07,\n",
       "   75.76,\n",
       "   452.07,\n",
       "   76.49]],\n",
       " 'area': 5226.5061000000005,\n",
       " 'iscrowd': 0,\n",
       " 'image_id': 94120,\n",
       " 'bbox': [448.17, 48.21, 128.22, 60.21],\n",
       " 'category_id': 77,\n",
       " 'id': 322014}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0d16a7",
   "metadata": {},
   "source": [
    "One image can be associated to many categories, but we are only interested to get one category per image.\n",
    "2 ways to go : either we randomly keep only one category by image (with the issue that we will penalize our learner when it learns a category that is in the image but is not the one chosen), or we keep only images that have a unique category associated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "594eb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_by_cat = [an['image_id'] for an in annot]\n",
    "dic_im_cat={item:im_by_cat.count(item) for item in im_by_cat} #make a dictionnary with im_id and n_categories associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08f99cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9555"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dic_im_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "737cae1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1041"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_one_cat=[key for key,value in dic_im_cat.items() if value==1]  #find the images that have only one category associated\n",
    "len(im_one_cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8eda08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_ids = im_one_cat[:1000]         #these are the images we want to keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18c88db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_captions = [ann['caption'] for ann in list_captions_ann if ann['image_id'] in im_ids]\n",
    "len(list_captions)          #we keep the corresponding cations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62b76a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_cat = [an['category_id'] for an in annot if an['image_id'] in im_ids]\n",
    "len(list_cat)               #we keep the corresponding categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b91794bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def get_data(meta, datadir=\"/scratch/lt2316-h18-resources/coco/train2017\"):\n",
    "    return [(x['file_name'], Image.open(\"{}/{}\".format(datadir, x['file_name'])).resize((100,100))) for x in meta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d7274ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_meta_data = coco.loadImgs(ids=im_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7cf1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_data = get_data(cap_meta_data)                        #get the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41cb9479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('000000316250.jpg', <PIL.Image.Image image mode=RGB size=100x100>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49ef853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_df = pd.DataFrame(images_data)\n",
    "\n",
    "data_df['imgs'] = data_df[1].apply(lambda x: x.convert('RGB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b32b9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['caption']=list_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43e686d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['cat']=list_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5eee257",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(data_df['imgs'][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87e7e313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>imgs</th>\n",
       "      <th>caption</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000316250.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A small clock hanging up with some lamps.</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000497187.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>a button on a black keyboard on a desk</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000483348.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A toilet with the seat up in a run down panele...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000367400.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>a zebra and some billy goats grazing in the op...</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000540784.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A large tall tower with a clock on the top.</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>000000574592.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>a vase with some flowers growing out of it</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>000000281427.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>a toilet also made into a sink with pipe runni...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>000000422423.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A train is parked on the side of the road.</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>000000163107.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>The young horse is struggling to get up from a...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>000000010964.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>a clock on a tower of a small building with mo...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1  \\\n",
       "0    000000316250.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "1    000000497187.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "2    000000483348.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "3    000000367400.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "4    000000540784.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "..                ...                                                ...   \n",
       "995  000000574592.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "996  000000281427.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "997  000000422423.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "998  000000163107.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "999  000000010964.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                                  imgs  \\\n",
       "0    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "1    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "2    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "3    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "4    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "..                                                 ...   \n",
       "995  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "996  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "997  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "998  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "999  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                               caption  cat  \n",
       "0            A small clock hanging up with some lamps.   85  \n",
       "1               a button on a black keyboard on a desk   76  \n",
       "2    A toilet with the seat up in a run down panele...   70  \n",
       "3    a zebra and some billy goats grazing in the op...   24  \n",
       "4          A large tall tower with a clock on the top.   85  \n",
       "..                                                 ...  ...  \n",
       "995        a vase with some flowers growing out of it    86  \n",
       "996  a toilet also made into a sink with pipe runni...   81  \n",
       "997        A train is parked on the side of the road.     7  \n",
       "998  The young horse is struggling to get up from a...   19  \n",
       "999  a clock on a tower of a small building with mo...   85  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56713e8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['imgs'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39db91de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Crude shoes have been tied to the elephant's feet.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['caption'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d68af310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['cat'].iloc[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab764978",
   "metadata": {},
   "source": [
    "We immediatly load 1000 more images and 1000 captions that don't match to produce negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37721c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_Id=annIds[10000:12000]\n",
    "list_captions=captions.loadAnns(ids=ran_Id)\n",
    "list_captions_neg = [ann['caption'] for ann in list_captions[:1000]]    #this way we are sure that the images\n",
    "list_image_ids_neg = [ann['image_id'] for ann in list_captions[1000:2000]]   #and captions don't match\n",
    "cap_meta_data_neg = coco.loadImgs(ids=list_image_ids_neg)\n",
    "images_data_neg = get_data(cap_meta_data_neg)\n",
    "\n",
    "df_neg = pd.DataFrame(images_data_neg)\n",
    "df_neg['imgs'] = df_neg[1].apply(lambda x: x.convert('RGB'))\n",
    "df_neg['caption']=list_captions_neg\n",
    "df_neg['y'] = 0\n",
    "df_neg['cat'] = 0 #We won't use the categories for the negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b23de90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>imgs</th>\n",
       "      <th>caption</th>\n",
       "      <th>y</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000525152.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A man in a suit and tie is riding on a train.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000271401.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A white plate topped with gourmet food covered...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000130625.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A white truck with a black back filled with pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000062423.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A young person leisurely working on a computer...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000134334.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A smaller veggie pizza is ready to be eaten.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>000000215024.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>a bedroom with a bed an dresser inside of it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>000000332706.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A man about to swing a tennis racket on a tenn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>000000389351.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>a monk sitting on a bus and looking out the wi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>000000509792.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A bus sitting parked in the parking lot.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>000000468796.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A person standing on the beach flying a kite.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1  \\\n",
       "0    000000525152.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "1    000000271401.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "2    000000130625.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "3    000000062423.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "4    000000134334.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "..                ...                                                ...   \n",
       "995  000000215024.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "996  000000332706.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "997  000000389351.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "998  000000509792.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "999  000000468796.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                                  imgs  \\\n",
       "0    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "1    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "2    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "3    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "4    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "..                                                 ...   \n",
       "995  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "996  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "997  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "998  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "999  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                               caption  y  cat  \n",
       "0        A man in a suit and tie is riding on a train.  0    0  \n",
       "1    A white plate topped with gourmet food covered...  0    0  \n",
       "2    A white truck with a black back filled with pe...  0    0  \n",
       "3    A young person leisurely working on a computer...  0    0  \n",
       "4        A smaller veggie pizza is ready to be eaten.   0    0  \n",
       "..                                                 ... ..  ...  \n",
       "995      a bedroom with a bed an dresser inside of it   0    0  \n",
       "996  A man about to swing a tennis racket on a tenn...  0    0  \n",
       "997  a monk sitting on a bus and looking out the wi...  0    0  \n",
       "998           A bus sitting parked in the parking lot.  0    0  \n",
       "999      A person standing on the beach flying a kite.  0    0  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f751a695",
   "metadata": {},
   "source": [
    "This way of coupling images with captions that don't match seems more meaningfull than generating random sequences of words, as such sequences would be grammatically incorrect, creating a bias that the learner could fit to. (In other words, it would predict that something is not a caption if it is not grammarly correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02699096",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['y']=1\n",
    "df = pd.concat([data_df,df_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a033677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>imgs</th>\n",
       "      <th>caption</th>\n",
       "      <th>cat</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>000000474711.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A red fire hydrant sitting next to a wooden wall.</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>000000448274.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>The young skateboarder is jumping above his bo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>000000540259.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A camera with a pair of small scissors and two...</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>000000104900.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A wet cell phone sitting on a surface besides ...</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>000000439995.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>Close up view of a wall-mounted oven in a kitc...</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>000000309528.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A dressed uneaten hot dog sitting on paper.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>000000398665.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>Two players in shorts colliding while playing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>000000444073.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>A dog that is carrying something in its mouth.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>000000127997.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>There are people in wet suits who are surfing ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>000000499989.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>Giraffe in its natural habitat snacking on a tree</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1  \\\n",
       "849  000000474711.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "520  000000448274.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "482  000000540259.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "976  000000104900.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "685  000000439995.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "..                ...                                                ...   \n",
       "584  000000309528.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "759  000000398665.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "738  000000444073.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "980  000000127997.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "120  000000499989.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                                  imgs  \\\n",
       "849  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "520  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "482  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "976  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "685  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "..                                                 ...   \n",
       "584  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "759  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "738  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "980  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "120  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                               caption  cat  y  \n",
       "849  A red fire hydrant sitting next to a wooden wall.   11  1  \n",
       "520  The young skateboarder is jumping above his bo...    0  0  \n",
       "482  A camera with a pair of small scissors and two...   87  1  \n",
       "976  A wet cell phone sitting on a surface besides ...   77  1  \n",
       "685  Close up view of a wall-mounted oven in a kitc...   78  1  \n",
       "..                                                 ...  ... ..  \n",
       "584        A dressed uneaten hot dog sitting on paper.    0  0  \n",
       "759  Two players in shorts colliding while playing ...    0  0  \n",
       "738     A dog that is carrying something in its mouth.    0  0  \n",
       "980  There are people in wet suits who are surfing ...    0  0  \n",
       "120  Giraffe in its natural habitat snacking on a tree   25  1  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444498d2",
   "metadata": {},
   "source": [
    "# Translate captions to sequences of 100 dim vectors.\n",
    "The words embedding is learned by a gensim model trained on all the sentences in all the captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f7f0e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "all_captions = captions.loadAnns(ids=annIds)\n",
    "all_sentences = [ann['caption'].lower() for ann in all_captions]\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ad9404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "for i in range(len(all_words)):\n",
    "    all_words[i] = [w for w in all_words[i] if w not in stopwords]   #we get rid of stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a8ddb16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "word2vec = Word2Vec(all_words, min_count=2)   #only words that appear at least twice are taken into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6001a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need a padding function so that all the sequences will have the same length\n",
    "def pad(encoded, seq_len=25):\n",
    "    n=encoded.shape[0]\n",
    "    return np.concatenate((encoded, np.zeros((seq_len-n,encoded.shape[1]))),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1835b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_pad(cap):\n",
    "    return pad(np.array([word2vec.wv[w.lower()] for w in cap.split(' ') if w.lower() in word2vec.wv.index_to_key\n",
    "                ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a18fc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['caption_w']=df['caption']   #keep trace of the captions in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09bf55c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['caption']=df['caption'].apply(encode_and_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c52bfcc",
   "metadata": {},
   "source": [
    "## Images scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "887afe0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 100, 100, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images=np.array([np.array(im) for im in df['imgs']])\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d386ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "images_scaled = StandardScaler().fit_transform(images.reshape(images.shape[0],30000)).reshape(images.shape[0], 100, 100, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b549b2d",
   "metadata": {},
   "source": [
    "## Divide in train(80%)/val(10%)/test(10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e32eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = round(.8*images.shape[0])\n",
    "n_val =round(.1*images.shape[0])\n",
    "im_train = images_scaled[:n_train]\n",
    "cap_train = np.stack(np.array(df['caption'].iloc[:n_train]))\n",
    "y_train = np.array(df['y'].iloc[:n_train])\n",
    "im_val = images_scaled[n_train:n_train+n_val]\n",
    "cap_val = np.stack(np.array(df['caption'].iloc[n_train:n_train+n_val]))\n",
    "y_val = np.array(df['y'].iloc[n_train:n_train+n_val])\n",
    "im_test = images[n_train+n_val:]\n",
    "cap_test = np.stack(np.array(df['caption'].iloc[n_train+n_val:]))\n",
    "y_test= np.array(df['y'].iloc[n_train+n_val:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7dbac4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n",
      "1600\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "print(len(im_train))\n",
    "print(len(cap_train))\n",
    "print(len(im_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9b448a",
   "metadata": {},
   "source": [
    "## Make batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3eac7b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batcher:   #when next is called, return a zip iterator containing the list of all batches\n",
    "    def __init__(self, im, cap, y, batch_size=64, max_iter=None):\n",
    "        self.im = im\n",
    "        self.cap = cap\n",
    "        self.y = y\n",
    "        self.batch_size=batch_size\n",
    "        self.max_iter = max_iter\n",
    "        self.curr_iter = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.curr_iter == self.max_iter:\n",
    "            raise StopIteration\n",
    "               \n",
    "        idx_perm = np.random.permutation(self.im.shape[0])\n",
    "        perm_im = self.im[idx_perm]\n",
    "        perm_cap = self.cap[idx_perm]\n",
    "        perm_y = self.y[idx_perm]\n",
    "        \n",
    "        list_split_im=[]\n",
    "        list_split_cap=[]\n",
    "        list_split_y=[]\n",
    "        for i in range(0,self.im.shape[0],self.batch_size):\n",
    "            try:\n",
    "                split_im = perm_im[i:i+self.batch_size,:,:,:]\n",
    "                split_cap = perm_cap[i:i+self.batch_size,:,:]\n",
    "                split_y = perm_y[i:i+self.batch_size]\n",
    "            except:\n",
    "                split_im = perm_im[i:,:,:,:]\n",
    "                split_cap = perm_cap[i:,:,:]\n",
    "                split_y = perm_y[i:]\n",
    "            \n",
    "            list_split_im.append(split_im)\n",
    "            list_split_cap.append(split_cap)\n",
    "            list_split_y.append(split_y)\n",
    "        \n",
    "        self.curr_iter += 1\n",
    "        return zip(list_split_im, list_split_cap, list_split_y)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0143a865",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Batcher(im_train,cap_train,y_train,batch_size=64, max_iter=10)\n",
    "\n",
    "           \n",
    "            \n",
    "#tens=m((torch.tensor(next(next(b))[0],dtype=torch.float64, device=device),encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63ecbd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 25, 100)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(next(b))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "476c00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2144c",
   "metadata": {},
   "source": [
    "# Part 2: modeling"
   ]
  },
  {
   "cell_type": "raw",
   "id": "205e069e",
   "metadata": {},
   "source": [
    "Our model will be fed with tupple of tensors\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2be2e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our batch should be a tupple of a batch of pictures and a corresponding batch of captions\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "class Caption_checker(nn.Module):\n",
    "    def __init__(self, hidden_size, LSTM_out_size=500, height=100, width=100,device=device):\n",
    "        super(Caption_checker, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.LSTM_out_size = LSTM_out_size\n",
    "        \n",
    "        \n",
    "        self.layers1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, 3, padding=1), # three input channels, three output channels, 3x3 window\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.MaxPool2d(2, 2), # 2x2 window with stride of 2\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.layers2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, 3, padding=1), # three input channels, three output channels, 3x3 window\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.MaxPool2d(2, 2), # 2x2 window with stride of 2\n",
    "            nn.Tanh() \n",
    "        )\n",
    "        \n",
    "        self.layers3 = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, 4, padding=1), # three input channels, three output channels, 4x4 window\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Tanh() \n",
    "        )\n",
    "        \n",
    "                \n",
    "        self.lstm = nn.LSTM(100, LSTM_out_size, batch_first=True)\n",
    "        \n",
    "        self.layers4 = nn.Sequential(                               #3 dense layers to classify the output\n",
    "            nn.Linear(((int(self.height * self.width * 3/16))+ self.LSTM_out_size), hidden_size),  \n",
    "            nn.Dropout(0.4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, int(hidden_size/2)),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(hidden_size/2), 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, batch):            #batch is a tupple \n",
    "        batch_size = batch[0].size()[0]\n",
    "        \n",
    "        # permute the channels to the form pytorch expects for convolution\n",
    "        current_matrix = batch[0].float().permute(0, 3, 1, 2)\n",
    "        current_matrix = self.layers1(current_matrix)\n",
    "        Im_matrix = self.layers2(current_matrix)\n",
    "        Im_matrix = Im_matrix.reshape(-1, int(self.height * self.width * 3/16))\n",
    "        \n",
    "        h_0 = Variable(torch.zeros(1, batch_size, self.LSTM_out_size).to(device))\n",
    "        c_0 = Variable(torch.zeros(1, batch_size, self.LSTM_out_size).to(device))\n",
    "\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(batch[1], (h_0, c_0))\n",
    "        out =final_hidden_state[-1]        \n",
    "        out_vec = torch.cat((Im_matrix,out),dim=1)\n",
    "        return self.layers4(out_vec)\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7179867e",
   "metadata": {},
   "source": [
    "# Part 3: training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3900bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(im_train,cap_train,y_train, im_val, cap_val, y_val, batch_size, epochs, device, model=None):\n",
    "    b = Batcher(im_train,cap_train,y_train, batch_size, max_iter=epochs)\n",
    "    if not model:\n",
    "        m =Im_conv_layer(3000, im_train.shape[1], im_train.shape[2]).to(device)\n",
    "    else:\n",
    "        m = model\n",
    "    m.train()\n",
    "    loss = nn.BCELoss().to(device)\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.005)\n",
    "    epoch = 0\n",
    "    train_loss_his=[]\n",
    "    val_loss_his=[]\n",
    "    for split in b:\n",
    "        train_acc = []           #keeps trace of the number of matching captions properly predicted in each bach \n",
    "        tot_loss = 0             #and the size of the batch\n",
    "        for batch in split:      \n",
    "            \n",
    "                      \n",
    "            optimizer.zero_grad()\n",
    "            o = m((torch.tensor(batch[0],dtype=torch.float32, device=device),torch.tensor(batch[1],dtype=torch.float32, device=device)))\n",
    "            l = loss(o.reshape(batch[0].shape[0]), torch.tensor(batch[2],dtype=torch.float32, device=device))\n",
    "            tot_loss += l\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            batch_train_accuracy = torch.sum((o.squeeze(-1)>.5)==torch.LongTensor(batch[2]).to(device))\n",
    "            train_acc.append((batch_train_accuracy,batch[0].shape[0]))\n",
    "        print(\"Total loss in epoch {} is {}.\".format(epoch, tot_loss))\n",
    "        train_loss_his.append(tot_loss.cpu().detach().numpy())\n",
    "        epoch += 1\n",
    "        \n",
    "        if epoch %5 == 0:      #every 5 epochs, print the training accuracy, the validation accuracy and loss, \n",
    "            np=0                #and save the model param\n",
    "            tp=0\n",
    "            for n,denom in train_acc:\n",
    "                tp+=n\n",
    "                np+=denom\n",
    "            train_accuracy = tp/np\n",
    "            m.eval()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                b_val = Batcher(im_val,cap_val,y_val,  batch_size, max_iter=1)\n",
    "\n",
    "                correct = 0\n",
    "                split = next(b_val) \n",
    "                val_acc = []\n",
    "                l_val=0\n",
    "                for batch in split:  # Iterate in batches over the validation dataset.\n",
    "\n",
    "\n",
    "                    o =  m((torch.tensor(batch[0],dtype=torch.float32, device=device),torch.tensor(batch[1],dtype=torch.float32, device=device))) \n",
    "                    l_val+=loss(o.reshape(batch[0].shape[0]), torch.tensor(batch[2],dtype=torch.float32, device=device))\n",
    "                    batch_val_accuracy = torch.sum((o.squeeze(-1)>.5)==torch.LongTensor(batch[2]).to(device))\n",
    "                    val_acc.append((batch_val_accuracy,batch[0].shape[0]))\n",
    "                val_loss_his.append(l_val.cpu().detach().numpy())\n",
    "                tpv=0\n",
    "                npv=0\n",
    "                for n,denom in val_acc:\n",
    "                    tpv+=n\n",
    "                    npv+=denom\n",
    "                val_accuracy = tpv/npv\n",
    "                print('val_loss={}'.format(l_val))\n",
    "                print('train_acc={}'.format(train_accuracy))\n",
    "                print('val_acc={}'.format(val_accuracy))\n",
    "                \n",
    "                if val_loss_his!=[] and l_val.cpu().detach().numpy()<min(val_loss_his):               #save the model only if the validation loss is smaller than the precedent\n",
    "                    \n",
    "                    for i in range(epoch):                                                  #cleaning before saving\n",
    "                        if 'caption4'+str(i) in os.listdir(os.getcwd()):\n",
    "                            os.remove('caption4'+str(i))\n",
    "                    file_name = 'caption4'+str(epoch)\n",
    "                    torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': m.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': loss,\n",
    "                    }, file_name)\n",
    "                \n",
    "            m.train()\n",
    "\n",
    "    return m, train_loss_his, val_loss_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "827878c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(im,cap,y, m, batch_size=64, device=device):\n",
    "    b = Batcher(im,cap,y, batch_size, max_iter=2)\n",
    "      \n",
    "    m.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        split = next(b) \n",
    "        l=0\n",
    "        for batch in split:  # Iterate in batches over the training/test dataset.\n",
    "\n",
    "\n",
    "            o = m((torch.tensor(batch[0],dtype=torch.float64, device=device),torch.tensor(batch[1],dtype=torch.float32, device=device))) \n",
    "            \n",
    "            pred = (o>.5).int().cpu().numpy()\n",
    "            \n",
    "            correct += np.sum(np.squeeze(pred)==batch[2])\n",
    "    return correct / im.shape[0]  # Derive ratio of symbols correctly predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73864a3",
   "metadata": {},
   "source": [
    "# Part 4: evaluation and error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef5c9e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "90f2a447",
   "metadata": {},
   "outputs": [],
   "source": [
    " m = Caption_checker(3000, im_train.shape[1], im_train.shape[2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f13b5ee2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 57.08171844482422.\n",
      "Total loss in epoch 1 is 21.73719596862793.\n",
      "Total loss in epoch 2 is 19.297189712524414.\n",
      "Total loss in epoch 3 is 17.76403045654297.\n",
      "Total loss in epoch 4 is 18.334379196166992.\n",
      "val_loss=2.6741151809692383\n",
      "train_acc=0.5231249928474426\n",
      "val_acc=0.5099999904632568\n",
      "Total loss in epoch 5 is 17.198518753051758.\n",
      "Total loss in epoch 6 is 16.880935668945312.\n",
      "Total loss in epoch 7 is 17.632192611694336.\n",
      "Total loss in epoch 8 is 17.29955291748047.\n",
      "Total loss in epoch 9 is 16.69623374938965.\n",
      "val_loss=3.0994482040405273\n",
      "train_acc=0.5849999785423279\n",
      "val_acc=0.4599999785423279\n",
      "Total loss in epoch 10 is 16.562435150146484.\n",
      "Total loss in epoch 11 is 16.612564086914062.\n",
      "Total loss in epoch 12 is 17.026527404785156.\n",
      "Total loss in epoch 13 is 16.442148208618164.\n",
      "Total loss in epoch 14 is 16.862878799438477.\n",
      "val_loss=2.887681245803833\n",
      "train_acc=0.6206249594688416\n",
      "val_acc=0.5699999928474426\n",
      "Total loss in epoch 15 is 15.495359420776367.\n",
      "Total loss in epoch 16 is 14.035637855529785.\n",
      "Total loss in epoch 17 is 13.555011749267578.\n",
      "Total loss in epoch 18 is 13.434181213378906.\n",
      "Total loss in epoch 19 is 10.979385375976562.\n",
      "val_loss=2.563485860824585\n",
      "train_acc=0.7793749570846558\n",
      "val_acc=0.6800000071525574\n",
      "Total loss in epoch 20 is 10.618484497070312.\n",
      "Total loss in epoch 21 is 9.866988182067871.\n",
      "Total loss in epoch 22 is 9.76566219329834.\n",
      "Total loss in epoch 23 is 9.508867263793945.\n",
      "Total loss in epoch 24 is 9.062744140625.\n",
      "val_loss=2.528991222381592\n",
      "train_acc=0.8318749666213989\n",
      "val_acc=0.7099999785423279\n",
      "Total loss in epoch 25 is 10.633159637451172.\n",
      "Total loss in epoch 26 is 9.57044792175293.\n",
      "Total loss in epoch 27 is 9.049147605895996.\n",
      "Total loss in epoch 28 is 8.072400093078613.\n",
      "Total loss in epoch 29 is 7.182440280914307.\n",
      "val_loss=4.331312656402588\n",
      "train_acc=0.8856250047683716\n",
      "val_acc=0.6800000071525574\n",
      "Total loss in epoch 30 is 6.9325079917907715.\n",
      "Total loss in epoch 31 is 6.5745344161987305.\n",
      "Total loss in epoch 32 is 6.7426323890686035.\n",
      "Total loss in epoch 33 is 7.55292272567749.\n",
      "Total loss in epoch 34 is 6.6666717529296875.\n",
      "val_loss=5.302961826324463\n",
      "train_acc=0.890625\n",
      "val_acc=0.7299999594688416\n",
      "Total loss in epoch 35 is 6.208230972290039.\n",
      "Total loss in epoch 36 is 6.380222797393799.\n",
      "Total loss in epoch 37 is 5.79842472076416.\n",
      "Total loss in epoch 38 is 5.414334297180176.\n",
      "Total loss in epoch 39 is 4.971076965332031.\n",
      "val_loss=3.927074909210205\n",
      "train_acc=0.9149999618530273\n",
      "val_acc=0.7199999690055847\n",
      "Total loss in epoch 40 is 5.070476531982422.\n",
      "Total loss in epoch 41 is 6.128619194030762.\n",
      "Total loss in epoch 42 is 5.479814052581787.\n",
      "Total loss in epoch 43 is 5.198931694030762.\n",
      "Total loss in epoch 44 is 5.053618907928467.\n",
      "val_loss=6.375703811645508\n",
      "train_acc=0.921875\n",
      "val_acc=0.6699999570846558\n",
      "Total loss in epoch 45 is 4.896288871765137.\n",
      "Total loss in epoch 46 is 4.327759742736816.\n",
      "Total loss in epoch 47 is 4.312124252319336.\n",
      "Total loss in epoch 48 is 3.945411443710327.\n",
      "Total loss in epoch 49 is 4.0083909034729.\n",
      "val_loss=5.949506759643555\n",
      "train_acc=0.9356249570846558\n",
      "val_acc=0.6349999904632568\n",
      "Total loss in epoch 50 is 4.219121932983398.\n",
      "Total loss in epoch 51 is 3.554368495941162.\n",
      "Total loss in epoch 52 is 3.8766849040985107.\n",
      "Total loss in epoch 53 is 3.1431002616882324.\n",
      "Total loss in epoch 54 is 3.247135877609253.\n",
      "val_loss=7.0288615226745605\n",
      "train_acc=0.9474999904632568\n",
      "val_acc=0.6499999761581421\n",
      "Total loss in epoch 55 is 2.713043451309204.\n",
      "Total loss in epoch 56 is 2.318859815597534.\n",
      "Total loss in epoch 57 is 2.7522339820861816.\n",
      "Total loss in epoch 58 is 3.429711103439331.\n",
      "Total loss in epoch 59 is 3.2659411430358887.\n",
      "val_loss=6.169533729553223\n",
      "train_acc=0.949999988079071\n",
      "val_acc=0.6549999713897705\n",
      "Total loss in epoch 60 is 3.245218515396118.\n",
      "Total loss in epoch 61 is 3.6899712085723877.\n",
      "Total loss in epoch 62 is 2.9660162925720215.\n",
      "Total loss in epoch 63 is 2.4753363132476807.\n",
      "Total loss in epoch 64 is 4.616711616516113.\n",
      "val_loss=9.529521942138672\n",
      "train_acc=0.9274999499320984\n",
      "val_acc=0.6150000095367432\n",
      "Total loss in epoch 65 is 4.589412689208984.\n",
      "Total loss in epoch 66 is 4.674121379852295.\n",
      "Total loss in epoch 67 is 4.424299716949463.\n",
      "Total loss in epoch 68 is 3.9224467277526855.\n",
      "Total loss in epoch 69 is 3.9733505249023438.\n",
      "val_loss=6.187783241271973\n",
      "train_acc=0.9312499761581421\n",
      "val_acc=0.6399999856948853\n",
      "Total loss in epoch 70 is 3.201932191848755.\n"
     ]
    }
   ],
   "source": [
    "_, train_loss,val_loss = train(im_train,cap_train,y_train, im_val,cap_val, y_val, batch_size=64, epochs=71, device=device,model=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dedba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2479cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.arange(1,\n",
    "          len(train_loss),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c865276",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "76aa8b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(len(train_loss)),train_loss)\n",
    "plt.plot(np.arange(1,len(train_loss),5),val_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14edf558",
   "metadata": {},
   "source": [
    "While the loss increases, the accuracy on the validation set is aroun 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44cd5b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.715"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(im_test,cap_test,y_test,m, batch_size=64)                              #test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6c8949a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(im_val,cap_val,y_val,m,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a42cb296",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.eval()                    #predictions on test set\n",
    "with torch.no_grad():\n",
    "    y_pred =  m((torch.tensor(im_test,dtype=torch.float32, device=device),torch.tensor(cap_test,dtype=torch.float32, device=device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "78a97ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=df.iloc[n_train+n_val:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "86ebd038",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['y_pred']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d0493e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>imgs</th>\n",
       "      <th>caption</th>\n",
       "      <th>cat</th>\n",
       "      <th>y</th>\n",
       "      <th>caption_w</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>000000305684.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-2.4979703426361084, -1.4018757343292236, -1...</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>A dog is staring intently out the window.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>000000067726.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-1.6898845434188843, -1.176702618598938, 0.9...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>A plane flying in the sky above the clouds dur...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>000000010964.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-2.1130001544952393, 1.9674150943756104, 0.3...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>a clock on a tower of a small building with mo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>000000271970.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[0.3408733308315277, -0.07852344214916229, -0...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>The town has a small church in it.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>000000087029.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[0.41485485434532166, -0.30711451172828674, 0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A bedroom with beige curtains and a chair</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>000000309528.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[0.7441691756248474, 1.827741026878357, 1.089...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A dressed uneaten hot dog sitting on paper.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>000000398665.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-2.04241681098938, -0.9905272722244263, -0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Two players in shorts colliding while playing ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>000000444073.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-2.4979703426361084, -1.4018757343292236, -1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A dog that is carrying something in its mouth.</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>000000127997.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-1.8310496807098389, -0.41348081827163696, -...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>There are people in wet suits who are surfing ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>000000499989.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[1.5379664897918701, 0.23885054886341095, 0.6...</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>Giraffe in its natural habitat snacking on a tree</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1  \\\n",
       "183  000000305684.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "742  000000067726.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "999  000000010964.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "296  000000271970.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "540  000000087029.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "..                ...                                                ...   \n",
       "584  000000309528.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "759  000000398665.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "738  000000444073.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "980  000000127997.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "120  000000499989.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                                  imgs  \\\n",
       "183  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "742  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "999  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "296  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "540  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "..                                                 ...   \n",
       "584  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "759  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "738  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "980  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "120  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                               caption  cat  y  \\\n",
       "183  [[-2.4979703426361084, -1.4018757343292236, -1...   18  1   \n",
       "742  [[-1.6898845434188843, -1.176702618598938, 0.9...    5  1   \n",
       "999  [[-2.1130001544952393, 1.9674150943756104, 0.3...   85  1   \n",
       "296  [[0.3408733308315277, -0.07852344214916229, -0...   85  1   \n",
       "540  [[0.41485485434532166, -0.30711451172828674, 0...    0  0   \n",
       "..                                                 ...  ... ..   \n",
       "584  [[0.7441691756248474, 1.827741026878357, 1.089...    0  0   \n",
       "759  [[-2.04241681098938, -0.9905272722244263, -0.0...    0  0   \n",
       "738  [[-2.4979703426361084, -1.4018757343292236, -1...    0  0   \n",
       "980  [[-1.8310496807098389, -0.41348081827163696, -...    0  0   \n",
       "120  [[1.5379664897918701, 0.23885054886341095, 0.6...   25  1   \n",
       "\n",
       "                                             caption_w  y_pred  \n",
       "183          A dog is staring intently out the window.    True  \n",
       "742  A plane flying in the sky above the clouds dur...    True  \n",
       "999  a clock on a tower of a small building with mo...    True  \n",
       "296                The town has a small church in it.     True  \n",
       "540         A bedroom with beige curtains and a chair     True  \n",
       "..                                                 ...     ...  \n",
       "584        A dressed uneaten hot dog sitting on paper.   False  \n",
       "759  Two players in shorts colliding while playing ...   False  \n",
       "738     A dog that is carrying something in its mouth.    True  \n",
       "980  There are people in wet suits who are surfing ...   False  \n",
       "120  Giraffe in its natural habitat snacking on a tree    True  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7bcecb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "right=df_test[df_test['y']==df_test['y_pred']]      #good and bad predictions\n",
    "wrong=df_test[df_test['y']!=df_test['y_pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "394297a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "65955229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAIAAAD/gAIDAAACwmlDQ1BJQ0MgUHJvZmlsZQAAeJx9lE1oE0EUx/+JLRUs9aDWKhXmIEWkLUvjSVRoth/0wzSkqdYilO1m8tFussvsNlbpSQSPonjwJPiBF71bPIkUPAj2UKsgItSbqCAUSkFrfLObdIfWOmGY37z5z/u/eQkB6lsMx7GiDHDNkkj1x9n4pQnWsIwGROAPw3Sd7mRy2GfSYsdYfx9olzv+ff7fsU+QIRDZS3wwF3Cr5KmANclXPMcj7pFs5o0M8Thxu0indOIbxE05hacUznDXJL5LfNZ0BOWpe0fcnXHNIsWJo3/km4NyvCHg3DFgz5swNuECz54Ah9vC2IkW4NBFYCEWxtZSfh8izUtuNtblhyKNcaD+c6Wy1gY03AE2b1cqvx5WKpuPyOMT8NIyZ0W52otINAYE9frjgG4UuTCY/FqSws4WLK50bpfTojVbu7+fZiMvjY3SepzeeZ+7vZLbyWo4Y/TQW3GK+GOG9/RW4/eyhb4B+UCai1nRN0brGbr7quANpANNVJSsxHA1Z1PJTowQUw8ic44XTwV3o4NueVTmPEnz+7QxmKS1VTZnxh6SGupftOtaPk09xFGKE+sJ4mbiRQzBQBEcgtYS5U6hH3F0wKGIjSwK9LFo7oxbpM5infZMzaI91Va1r1uZmPZB+6GtaA+0x9o3PjdyvrwxPRmeXheTBXPp1k8k/du1vNVTcjP8yhh0rJJDsKvVMqPUrtZVO09uq/X39lrhljdyp0M/WQm/mVjfyjBFOpd8BOUoE1u046T3qjnVXDs7xH2NHmreei/Sz+dDv5W6hcvLja/nd3l9xvfS8WXLQ32RrSj7aOfRNJV6FF9FqWbg2zqUwgXF12JH/L4G3wH3NfJ1+aoXPD7nyR+/bjtXRSGX91iXpsVYN/01cabbRWfW44INlMzOdmZYFvM1LhPc5aLMM53y7l83VwTq0a+9hAAAS1tJREFUeJxN/Umwpct2HoatJjP/Zrenq1N93brt63tAeCQIgCRkAZRlUpQpkZIGVsjhduBweOqpIxyhCMsTjxx2aOCBYAWtkCyZEGlJVICEATwQDw94993+1q2+6nS7/bvMXGt58J96oZpVnDq1985/Za6vW7nxP/w//gfZZD4/vNqvXj17vL+68I5jjMk0DYNzXJSzMpTbfsOWDhdHi+M79996VwE8h9X64smjj67OX8yP7iDyN7/xXWN6/MUvXj79OPf5+NZD8sEXrigqUPBMV91Fq+3l5VMuHDBakoIn92588Pb9bxLAZrsqq8nTp49K78uqbrv2+Pjmdne12WxOT+8eLk+GvpvOJkOMKfXTyXTo4ztf+3qzbTer8+lsaWST6cx5V09nTF5FTLWsqpQyoNX1BJHUFAAISE2z5JyziPgQEFBNmQgAzaxtGgBz3jf75mp1yezqqo5t745Ob63WF/3Q7neri/NXp8e322YdnE9D431QTabRwrRfDcuqcq7qh+bZ80fLg5P57BCIb91+V0VAtZzNXp+/ni0WVT1l9LPlwjFv9utDdzSrZj5UH5/95J99+l8mi+gNNwre0CEDf7z//925eO+bt//qSXV7v10jYMziRNari6IoNNvNm/fef/+biipZLs9eD7EDMwU8unEzDvHoxg32jESI1PX9BOu+7aoKkZDIDWnw7BFhiDGlRIihKJDRAIg4p14kIYABDmkIPgAgIaaUiDm13XazRskA2PcdMjp0vN1uqqLa77Z91z1/8UQtVd6TGXnPfkKIV69eHB/ecA7L6eLw8Gi1Onv66JPb9972oaiPDgHff/bkY9CUc2agu3cevnr+uJof5hxBbLY47NNQVNXzq89y2JYlAyIoSmIwI9ZOtp9e/cnjqw+/efvXv3fzrzHirtm07fpwsaiKapvb+cHh0cnxp599fHV1OZ/OCl/EYRBRI0s5tf1+Mp13zY4cdk3LCPOievXqpYEsFweI3NqeiAEQCctQDl23zwmJETHG6Jn3u72qIDGKsXPkvHeOHYvBjeMbfd8qoHNuaDsnkr3309myuKzm9fTGnfuPv/qs7WMRfE1mmsrZ4WQ6MwPnWNTIlz/44W989fjTT37xk7Kav/3ud27fflDXxRef/ZTYrbZUVeXi8LjZrn1RLw6PYxwAYLe9OqpOv9gjM5oiMpiBdQzekKwIJJJ+8ui/umpefWv+49R188XBZHFoCGhpdfnqL/6iu3x9ZgDTqlRVkdx1+7ArwrLw5GbzGbM7e/kspWGzHQ5PTk6Pbw6xy1lCYDBmJARGQgMIPngXiDnmWISCnUPYMzN7Z4iIyESIECVWs6mkGLNnRHRcTiduvb66uDqPaShCeXByc7O6XEyXk+l836z6Zhd8sb58Aexmszlg+cHbHyDDxXaVDE5vvnX58unzZ5+Dw4PlyY0bD58+/SInHQ5OUmxz7Kfzg/PVVQgVIqyb7QyPgs5S1xEzASAgMEEyCKoZCDC48otXf9lv+7/5jX+wurrMyS6unty59UBE2l378O2vxSFenL/MKrP5kogPDo9Siv3QbZ+tkfjuW29/8uFfDDGen72+fffBcnYsIkPXsvdgQEyIJCKGQOxijs45USWzajpRMwREAFUVFUQMHJh41/eTyYSYYz/shta9fP3y8vKybVomXq0vPcDy4GjbrJwhO1/NjorU5qyquN2snj7/cjKZTurpfrsmKu6/+5222T776tPnjg8WJ2i4XV/68A0AMclm6MnXk0XbnO9Wz2fzmyfFneftp4BMBGAAYCYMA5gHIESy4IpXzRfPuo8+uPfjybSOcRA1csEFDwRFXR6enG53m+XyEJAn0+l6tdptt0PfkXOT2ezO3bdSjpPpvGs7KI2YnS+cd6aaUlZLRVkxcTYhQCQiJFEhZEBIw+BCQMT9fldVVQghSZ5MJpKl7zvvfFlWhMCmut9umDkwGeK+afpm1/RdjMP66rmITBcHB4fHwbs0xNevnr548fjenbcfvP1eNZtNl0dvv/XNk4PT/f4qlAHAXrx4sru6RGAgPr15GzCCxRsn9w8OT4/Lu5AIEpoiKiIQIGJ2GtESoSI7IOd+8tl/3dvOEO4/ePv2nQfOU05DjkMa+tXqcjFfIFkIdHb+4urqQiQ7FxBofbGezKfHpzeJydRSyjoeHSI5J2QkxLZththbFiQyVVNlZFWRLN57AiTCSTXJOXexM7CUMyKiYd+1RShczH3XdYHcen253VyWRV2UE3KFc069i1233W/FYEEHRVnst1fD0A1t96J+cnJymiVPp4t7D99ZzObPnn75+ItPXzz74umjjyAOXNcxDoC6fvbVbHG6vHGTCe8cvfuL1z9JXbSI6JAJgYyATQ0JEBAV0LiNu48e/+mvvv8v37p1N+f84uWLt+49LMryyesvUhhedTtrDcGYGJUTHR0vT4Fwn85/8osPh9T1cTC1sigLX5VhMqkXlZ8vZkd1NSVAlWxoiGCIokreJ5EyhL7vU4pFUSJiitF5R0Deh5xzUZZpH3d94y5evQLRYlJud+ssllM8f/2UkJzDEGpE6AYxl3DfeYegcTZb5izNrvFuPZsuuqF79eLZhSdiuvPw7ely8emHf24tKvHl+Svp1r6e1KIx5sVi4bA8qe8833xpRpjQGMEZMZISqIBDBSAGNXq2+uJ3Dv5BXdVn569mk3k9nXx68bPL9iyrSpYikGcXB0PDz57/bNtcIILjsvKT6eTocH5jEqYTtyBgSPT08aPz9ctQ+m++/8N3730HDETEee/YOYam2bNzIhkBq6pm53KMk8lUspiZqca+DyGkIe3bnbv/4N0Xz786O39ZlTWxF9GynAGTpFQUZZeIFJpmu1gsYx5S17Hzoazbfn+AN45vHn32/M//5Kf/78GaJE02dewLV1WTokIuyB2cfIAu1JPp4eHh+flzHfLbN7/3YvsEDAARAQBIgRBQRFkBjQzRIa27s588+v2j1S0cyno6++T1T1/tnwXiJNkhZaFmj327Od88LXw9mx7ePrh9+/Ddd9761r07X79anYGZ82E6W4aisCyb7fonf/YH/+l/8f/4/vd+9Lu/8e86hZyFiQ1hMp2KKCH6ymeROAzOMREjYDYlolAUSDhfLMg79/jpl0+ePp547yYhiYCxK6ttswfV1eZClHwonOPtejWZTqfzA+cLdqXH9hcv/9k/+vDDdXcBZoLmyAiJkTAYMngqJuEw+nePiwd916/Pu7bp33r7G5fbi/mTP1i3V8hoRiroyLx3lsQUAQCMCEE0/ZM//n9Oytk7d7975/idDNlbaPud92YcrlZdv1813eXJyalYulo9tiY//eRFcOXdOx+8ev5EVW/dvgOzmeTIxPODg3/lX/6777/93f/4P/2/vP/wL7/+9o+k72JOhAjOqWoydY4RMHiPiPt2v233xwfHgEiICLjab4qidGBy+/ROPzRdvxMwRt7vrsow8Q5VQJSI/c3Tu+dXr7u2KUIIVXm2f/TJ2Z+uuksmx+iJtAg++KCaRDMakZop7PTiF69eMv3RQbj9/o1fOTl8cPfu/cl2cfPzB1fbSwMWIyIWNF8CA+Vs7FARzFBEbyzfGmC1yV89CB8EKqf1IuXDmDer3VrzldIVhPj0xWdH04e/+d2///V3fvW//cPfa/Jl3/UAAGihKOMQ2Ruz5ZQB7cE7D//e/+h/vt1fJMnsXIwxZammrGZ92yhYVVaew2pz+bO//PM+9d/79veIXFmUKabJZOKcd10/3Dg+PTvvDDyptH0HgORCoCK4uo8Dh3C+Pm/bfj4tiRyU8ctHH3uc3ZndKHmyrA8d4Vt3vz6ZHYFaiu3Hn//RLp713AzYJOnBYNU//8Ovni6rm1f5+VunP7x/8o2ff/4zZA8GAGhqOZsa5myqgAyApgCbdt3KVc+bk4tHdViyC0xuNjkqXPXnH3+6Wa8rt/TBHZxMXrYfnv3i81fNl5snLx8++F4xmSymy6KckUdH3gBCUZjpdr2+c+/uXbwPBmBWeB8RTBXMHHNRVtvdth9W++126OOtG6fPn70Agjs3b5tiTGk6neK/9ff/rqo64qIIwxDbbogpHh2cTCbFbrtS8pIzGhwsD9PQGvvD4xMm571PSaqyvlqvvMNJHbLi9777a0eHi//69/+TV08ez45vRh7cAp6tPl41zxBRTCTnRXHv3uG3/8XP/7Ad9syO2NQUiQJzGgyRiJGInXN9M7R2aWDfeu8Hi8khkkPE+XRWhmnT7iuufvi1v3m+fvlP/+w/e7H+5PDg8PhwUZRFyQf9ID/+7r/ynff/miMvpqbZhzJlIQTvAxo0bUsEZmZgRSj6IaY49EM8vzjv+mYYUuHcZrdh9vPFrCzrSV0T0H7o8H/8b/7rV5fnh8uD6XSZczTi1xcXk1DcPL1xeXWO5INjRvRlKSIp56qsl8ujsp4GT8Cu8IWK1HWdYtt0u7qun33xqWUVMAP/1/8Hf2c6q//xP/+9R69/uonnSKrJKry75Lur9bqY+JiadugQsCrD0MUhZXRABDna5evXXddKlG/+6OvlJDD5wld1XRsSOceQf+WD33p499tD3/3hn/3TR1f//MbN6WJ2EnD6+PnLl+ev3rn/wd/5G//+tD7KIozgQ2GEjESAbdsOMXbdnhjH5q6qr169/PLRV0kGBBqG4eXrF28/eGtSTaPk4+PD2MVnL584ADw5uhlju29bRHOsVVF655t2v5wf9EMXQkAAyTmJZdF2iPHi1cHhEbFjClWdZvX0Yn3p2Zl6MvbBZRv6PgLaZrdSzBM4+drBb8A0//lHPzmdvv/Wva9/9eTTJJepHdgRk1fTKLHtu/2+AVARMYUkGQEOby1cwM16g8iu2FVd7X2BRGbDZn/pfLFanx3f9FLfjdIlEeB4cmNRldWXX3zy/8r/13/rd/83IVQIZgaxG5AMFIehH4bh8vIyFC6EcrfvXrx8tt/v0PT169f9ELebqzs376SUXu5elWUIgSVKEUrniUWE2Oc0ICAXePvGzT4lia0vPDmPyNtmp2Kz2XyI6ejwuOubR48evf/eN06Oji+uLtquffL0y2k5m89nk+l9JIcWUxy4LAhgtTrbbi4mkyXHxa9+7W+fHB+knJbLxdkq5AweC3IsYmoJMRI4RMsZRDMizE/rWw8WhrpabRHAF6ENrQ+BHc3CstmxYvyzR//N2dWXu7YpHCe9Cq7IIpN6evvWva+++PLpq0++/cGvGcCQsqoE50W167qrq4uh74pisbpad12b+7hZ72KKkvX2yY2Tg4OqKJ6/fJ3TcHh0KKKnx6dnr8/cfHncNJs0JGJj5xCh7Zt6UvfZXr56KVR84/1vnZzeefTkyXe+86MvH39a+sKXIWcdUnx29uJwdtANzcHy5sO33lWV7XbbNnvUDMSTSf3zD3/qGJfzYx/qB2+/h5Q//PDDlOTezdtX29fnV5dkTFgxg0LUYFCxmARvMTWDmq+o7zvLiMYpRslD07SFC2/dfPidd39TcviPfu8/vNh9iczDvplP5r2mmOLx8uhi+xpADg5ubtfrmLKhpWEI3qnBECMx1dVktVpv9k+nk3lRhlt3bp/cOLm6Wm8Wc+/9dDJ5dX5eF+UXL56g2c3btza7TTmpXNvu6nI2uTE/v3jdtruUZDqZdE03mR2G+uDi6soHv1hO9avhsy8/aru2WIaD5UHwvN1sLMGuWQdf/PhXf3z//v3lwdHz51/9/n/+mbSdC1VVVpP5AbO/efN2zEPbri+v1tNq0liDQG/ffXcQBQOTpKai5DwWRdUPbYwpws4poNjqcoCo02rSCyHiew+++YPv/NWHD9+PMb8+++rlTz46XE6vLi/fOzl0ldutLp9nP+9bXsxnxXy3fZG1adrWE+Wc+th5dn3XNu0+pVSWZbtpRHLObrXZeMeb/Za8m8xm+6Z78fzldndx4/TGycmtrum++OyLLNHduftgtVm/On/hyU0mM1P13hNBTtEX9eHR0YuXT37+i0tTeNYNh4vF+eX5+eXZ5WYzm0yrUGz2u/lsvlpdAkpKw9nZs5wiE9WTaR/7868+Lqp5n+PJweHV+ipl/Pr7716cn/vgprNpE/vn58+AvUGmDAhKmNlPfUqDrjRR1/Sxp7oIk7KaTSqC6t/5+//Le/ff/fgXP/34T//Rs4/++TfdVZHid4/a27OwyuvJQfpU7zzonu22oTq4+z6e737+f/88bxa3f4zAsW+zqKmpZHY+FMH7arvb1qJPnz9HlNPjW7vd7vmzx3037Hbb+XS+3zUf/uWfHRwe375z7/GjR+7i6rzvYtv2COidC0UBRHHoYt8tD6vl/EAkbjbrUBaTejoMfSjCvuveuf9OVZVlWZ2e3IgpzqbTIQ5Pnjza73ZFvdxtNk6sKv3N0wcfffZR3w0nB0cOeTqblEW4cXJysX4tKZsqEwoCGnEAyQZMBOo9u9JJHFYXqa6mZVmyd1fry9nMDymtXn325B/9B/zsk9v98PCOEm3r0s+k0/1uUU/udV/eKGnWbJsXryjZWwcT+ug/+pN/9t8sv/u3VSDFGHM8ODxWw6brDuaLbt98+Itf1HXx9sN3lvPZbrNt981mvTm9dfrOw/fOz8+L8N5qvUkpHh0u3ObqIhTlYj4b+r7vuv125UJBlhezRVlUx4dHZip5ePTkGRNerddmFooya86WReXs6uzo6JjYYup3u/3Q7RGwLkuWYXvV3n335l/9td98ffZ6sVimNEwnNREikiPX5vTi7LkrwLKIKkBSGVIWFc2oZtrsel+6w5MFmvXDjjAQ09nTzz7+/f9TtXtc52q64AUDF84plWpVx9OSb3koGBYTt2rNsfRnzQnx3zr8eLOjR/SNffGw7aOkZMio8Pjpk65pc9/vZXjy5Nmr1y8PDo7v3b1f+LPtdvfRxx9dXl0A6q2bd1SVnXfHJ7fU8na/895N6mWzb/f7pqwKF8ok/VdPvyyrSVlNJ5N63zYpDYeHx03bPHv+WFScc8GXN09vtEPnke/evj+fLZrN1Xy+ZMdlH3PqO9T79x8QoYoWRQEGIYQbN27/d3/6T5t+M6MJAaSUiU1NhtQbIIDJkIlpflgjokq6umoOl0fzxeHjP/mHt/ePXWTgfFDYNDB78o4gZepsesOhALNUgT1RFoUyXz7ezA6LW/TTE/3purj3mL/+9OqhFIcP7tx9+NbDFy9fv3j1zLNjdmfn51eXF7du3885Teuq6QYAbLe7x/1Xk9mCCN2+a1brq6FP3vvgqC6Lo6Nj0GSWt/t9YA4+bLqm7ZvdentyfNK3OwYGUBSpq9nx8UkZSsk6KcuYesk29K3mCKYUSrPJerWaTefbzSoOQ11PRc17v96vnr18bGB9it45MVVVUUVRATBTEUMPIBpjl9M+DXJm50eLydH28yoiB6xnFgzmNQlbQfL6VcQeSkdGCKyBNVRuUACB8m188mnfbuzet945lfXN7j/73vTOl+XvPGsPV7v+489+MbRN8H5xcFiWZbNfmSQk/+r1i9l0Pqkni/l8uTxYb/ahYHewOJhV9Wa3yyk59mrivDNR732/75Jz6/VKESHp0cFR8LzdxIODw8ODAyTy3s9nEwW7cXgIoH3XFSE47+IwOBcCeUI+PryBiNv9/uDgcDabrK7WIZSvz89zFmKMsWcs0TRLirkXjVnAQEBzllRKnWInOTvybxfxRy9+cmSpOiYA3Z3R+99yzoN32GyH9VmsSkCzgp1SZiRVm9RBM2mdHn5Tv/p5/+STi+Nf+e0QSr74s/df/96d+o//xeaO9gfLo9uXr1807ZPJdFFNZlmlCCE4N5/PqunEUXF5dV5XoaonDn39jXe/oZg3q929O3dd4KvL1x9//BfzyfGDB4uu7+p65r07v3gtWYrgy3LinT88OCRm70sDYBURzblnFwQMiB1xKEtf1bdu3pov5peXFxLzYnnQ990owWx2K1MDJABNOYMZgDFTpzlFzbkHBGKyrGbqgL5f7n+I7UGlXOJmA/ECDpc4mSMS9ym+/ioyGxD0fZwc1INmQjl71vfSvfeNpWQqFnj3A3v04SX8wX+Mb33j8vTXX6+75cvPb8HPfm2AP3n5fQxHy8nhZnvlvHv6+InzjgOvVldn5y9TVkA7PrrVr67cwpJsL4wA09CuXgbvCrCynJRlmE+rg+WcAQQUDpd9n5azSbPfXq239+69PV8u2j4SKBMTo6oiAJhsrl6h84ZkOXmC/XbVtK2oiOT1pq+ryeXV1dB1RqpqpmKWHQcRDc6b5qGPSgkVZE8pRIb869PmO+Uwr+xi4LOnNolwVNr8BjtH+yF99Wn0hsUU0NvFal8vZzgptGtE9bMPG2F674OlIzk4rs6O88VlWn71i/mLX6yOfvgv+EcFfc/Zc+DCJO/3ayb36sVzH0LeST2p5vODZr9HR2TWtW3T7N2z9dVF1/oQ9rvtX3zelvVsMZvFtlWFV12XUjyqwpNXF5r1xtFxQutVUxYuitNbt4NzaejFrCyrUBTtdnO1umDnERwSbpr9p0+/AtWj5clkOkspppy88+vN2jtPaIqmWbIBUjK1mJNIzDlTgSCGApLTnTKVJquEP9+Gp33xnrTvnSQFe76Fo2yffhbXF/bOA0Q25/WLx/llu/7+jw8sYNd23tsXz+nF/b/2vv3Ex5fVBGzLVwphcvdG8yjffm9XvTt9+I6Jts2u7ZpseOvm7e122/dNWVZV4YubN0XSdDpPSQ3MtTn3uV0WwZh9VWMZVv2e+n6xOMiqQ85tJ4UvlseLoe/2XT+ImMlus/7q8WNkR6gMuDg4vndvmeKwb5rNZlWHYro4rItKtk0xnyeNdZg6x8MwpJxSzszeu3KQzghMQLImiXnoCcwxB88pJxewdLhS/6W6xzE+iuGd3N+YS3T6It9+/Gz/+TpOBp0FaJWmVXYnXytu/saf/3/+b/vcvf3BffvG35jSHxc3Hhz99v9q8+Lpi9//P+ezPzKz6Qe/3edue/Td+vBBzYWYGfrZbBbj0LR7AZzNly9evKxKOL15xwzUDMxW660AOEopZ7h88RIMJ87h0IuaIQz9sL1cSddiVRnYp8+fzqtp3u+jaErp8vLyBz/41aoqLlcrx+727dsHhws4OlwsZudnT5rLC8lSldV8Hi72Xdv0R8uTmFIofJ9EVZ0viqIcdh0hKKqKpTRESeSYvRgYEDpngGaueGxKwWPSF2HxM6qP8cb8vR+kF7/3dK33Hn5r8+rDzz6J3/3tf+07/9r/7leP76Pnz//wH0Lxm6e/+m+ubvyVyXQKV6/r46O3/u3/w+s//ccXT/4kfOd3DmZ38ouvMNTBF1mkqCaqambB+e2+8TO/nE3RBiYUMZVsapPCx2riDGmxnM2ms7ZvF0VARuRwefVKUn7w1sM0NACcRUI1BcDDw+UR0b5py2qKBIZw+9ZNU91uLptmE5wbYh9CkcqaUIeUjj/4lp6/3Gx2zDTEWJah77skQuhKV64VAHU849MwZMmhMNEkwgDgOBwuF9t2A2AE2plF1d3R1x5+/a/Uk+nx138t5eHkR//q+i+WR4v5d/7e/95Xc4D8K//2//aD3/4Hl7sdQ7r/4AEhAUBsdsG7kx/89f3Bfa4XVJTV7JDIEVHFpQFGkUlV1FUxnUz2TYPdziE8f/KV854Yl5P54W574Mm9/857IYRqMt23+9KX9aTOOZOTPMA7738D0Ihc8F5y2nfdcr4QSWqwXCyJWQGymmfP7MHAh6pp97HvmLkbuqOTw5s3b602q1BENYkxlmURUwYgZjg+OL3YXmYRJDMxyaoKCkZMiggkv/XXftf74r/6p/+JdwYGo5p6euN+UU5CVX3zb/1PRGy12XzzX/9fv//1b6KKaYyRCBGLMl2dI5FDCqU3RW8sWbr95nAxJ+cBOZRTZso5D0NUyc55RAKE6WwWiqpw5YvXzxkUAVTsarMKy4Ou6dyduw9SGpjccrEQMecDEaxXrzabdc7p+OQk5ZziUJah7VtEmE4nMeeUelImoi71rZkjJsSm2XXN3sBEEoF1+83Z2cuua8uiEhFmjimllAvvgvfLRf347MvtvkMHUXpRMVUzYEYV86H8/nf+ys8/+mM0dY7NlJkPlscHB7eVWA2DL1rpAaxr9ph6VQMARGz7fhi62aSeTWc5ZyRiFxDBeydiAKiaHZPKqZiaWhYJjrNoCMGxV1NR3e86+Rl99fRRSoNj0pTOL68UwN29e5fZee8RtO0Hx4woOb11cpzu3b49mdV9PyBMVfXo4CDmCAbTulaTYYimgmCFd1kECXPsUuw26zXEoZ4tXQh9t1e1svRDTM77ddN4RiZSxJtHN26f3Er9vtM+aTbQnKMTRjZJMisWIvDl40c5AlQgykDw4M4HB8vTDOBDbYghhCKUzX7/+PGjEEJdz9p+SCkyQs4iYgCQcvbeq5r3jMiIkLOEEAipaRo1ZcIQSkNMKSOhmTnvi7r4lR/96N13300pBucBoe0aFXTPXz7xzgEgovXDkNPA5HwoDNPPfv4TEfChyDmGUHrHQz8gWc65DEXT9YUPzjtyjpCSSBzal0+/2u/3y9mSnN/vm/V6K2IGMAypQJKk7KiNcjKbEeDB9OCj3MfYgSkimkKKuSqRALx3YPns6hw8hJJzC5Nq+vWv/WA+O9y1MYN1Q0RQZBqiHh7fDKGs6uqYPQCAWhYx0LKoJGdiUgN7kyVSsRgHdnzqwhBjTtGH4F3ouy6lGMpCDVTFTfDg5Ljvh7Iosohj7tvBbVcbJCDk6WxehjIaiRkBL2ZHha+JeDabMxMAVVWZRBjRh9J7D4jeMRESsqgC4q5Zi0hVzRazxeLg8Oj4FBk/+eyzrh/MQMSQuctaej+vKzWr/IwUAc0FyEmB0MDQETFMivrV2cuLq/P5skiGUeDbD77z4O47bUxmtu/7YRiIQHNOKTrH8+XBGHpkIgUDQgQXJTOTmIkaEYoAAiqIITBRkqwqoSwAoI+9ghZVZWYGCgZDzENMCNi0rYERYNcM7td/828wEiIpgmTJKVdVJZpUIec0xFSGwMxI5IM3VVFxziOiqaSciRjMAmIfh6PDG7/1m79DhKbatHvisN1cIjEiIDN75wymVThczouq2OzaUMwOF8dPL9ZlTSowxj2ZEUDU4JMvPgRMoSy2K62r6Y9/+FtFWaphpIyUAQEMDMCx6/rhkGh0A9WMiAAAgExFVZmZCMdOwsRkwJ4VDMwYWUQREQDNAMFSzmoafAAAxyRipkLskGi37ZzzYRhSVXoEI0Q1I+/QUEUBjJ1zzhNjzppyDiF4DClHAwIkQBQR70OKAzuXVEPwZlpUJRCFotztr5jJIfoQ2DEzTavSB9f0edv2i/ns2x9896tXXziPRTHxVG3bSxCwjOvN1fpyM5uVkn3S9m/88Lc+eO+bTdsVBUzUkKkfBlNREyRSySklZvIhxJwISUy9ZxNg5xBQ7TpckVUY0UDBcPQNg/c5Z8cODZquL0OAbMxoxkkETOu6GmIyg5TFqRozs6Nu6D35ehJMFYFUcwgFsUMEJgoBckoGSEjOu/GBOOeZGRHHVx2Gvqom46mJSKbS9x0h9Cm6EJi4YGbnAamunOPFtK6qyXvzyUGXLrwvbp/c/vCrlWazDOurbTHhsuJmF7/28Ju/+9f/jgL44IFwQqRqMSYBQQMASDE5x6qqpgjgC88KZsbOZ1VHpCpjbs3MouQQCjULjlXVe1eEoGZq3vtgpr5AZlaNHkGVRYGIHLGpkkjOOTZN551XBCYCM1EtywoI1YyYgMkAnHNgFiVL1r7rVdT74J0zFTCLMRZFycwhBADw3iGzSS6CI0sg4j2HwtdFmE0mVV0vF3Pnw8nB8Tv33nXsh5y+/sH3vvPe97JkdoRm3lns86Sa/Bv/6r9b1XNRY+bSl8RclGVVloSgZoiWJA8xiZjm7J0bYkqSAEzBmEjViMDAiMk7P8SopoiISMScsiZVIAJAduS8Y2Yw894VZVGUhZkSGpj0Q3TEzvvCexdjYqa+79kxoSNih4BAKSdQc96nlIYYEcGAyHkfCu+diBCxWfahMCIzQyQRjSkxI7NDs75tZ9NFXRbT6bSqaucLBCQmNQuhuHnj9k8//e9UabE4ef/d7338+KcBiJQYeR+b3/iX/tbdO++qWVlUaiqiJdcI6JhTTrrdAhqhVVWVYnLeiUjwXlVVBJCc94xm6JBM1fq+9+wQDMwUTCSLiEXw3qnIWBDOub7rHCEAIwATEjkmPyR1alYXZcpx3IyiEmP0oSJCyWYIjmjf7YOpqpahRAT2LqbomM10iAOzm8/nBqBmKfYWARCC9zknYhaVIcNiebhYHNSTiXceiIa+L+tKVZHoxvGpSkYgZl5vL1WzZnSF7zU/uPvu3/z1vz3EXATP3kEWMXBIPJnGlKZDv1m5lAdGTHHwLiARGCIQI5LjmPqUEEEZSc2cc5O6TikTIcB1RIsJ1UBFRMUUEAGJfQgAY/7JyBERZdGm752qZkk5a1kGA3PeiVgRPCACgpmoWT2ZqEBVB8dsailH7xyA5iGimeackFSl7ftQ+JzypK67fohDy0QpJcd+UlVVNQlFwUCK5kPo+24YIoCpgSWu6snLl2cfffEXSN4yaKlm9P2v/VWmQmTouphycM45x44IiHJKhffz+bzvm6qqAMAQwUBNzAARJWdVAB1CKEWUHWdVAEBCAwMg59gMzJAQyHkCD2DOeVUwsJESAIB3zszAAExdUZTErvZeVR05BaSKTVUACYmZAQCIUkpmIGpZkmZBgpjMOe9UAIkcO2ByzjNLEDErq+rq8vUnn32x33cK8PL8Ytt2KQ3Nvu26dt+2Qz8AWE45pabwi7qs/uwv//nF5jWA5+AKrpZ+/vrp5r88/y8QEQiJqCyKoqwmdV3XNRI1TdO1rVp+/Oz5dHm8LCdmwswqGjVPimoAbJo9s3MuSH4D0JmBGAFMDRlVafwRE2mWHJMCIIJjRCNRE1FEAIM+RpclxpQW8xkCisoQU1EUqtky+OCZqesjWFYRNaVrIViZERCJmZmyKAD2aYAxuIfECMh0fnF+dXkFSGrw+PETQmTCISYVafvYDwkJZlWZshgm1GXUBhkggSktpseH8/eyOBEBsz5KH7MaIOJiXk/rioiIHSAS0267j2kYcRcCiioZDmlAoslk6pwHU/auGwYiEGPIQoSEZGYI4LzPOana2MQBUUQBSEANbYwmxZg2252bTuZmeo3lGFnHMiYDNTUBZbQhZxVhcgBqCpO6AgADjTEyMXvnCNUcADARIuYsbJBTOjpcAjMiTorSh8CI/dD1Q2TnLGuWDKZ9XDxb/Ww+K/vcv15tMfvlZPbe/a+dntwDpJwzgokasfM+IGJZuMlkenx8NJvOkZzmLKpMpCJyTadJVVLKjp0BZMmgCgSARuhU1VTiIMQMCHj97xUBlVGSqamBMjMCqSkhMruU8r7pHBOLWs5ZgdghADKhARGxmWYxInLOubIEU1E1NDUAsCQSnFMAMFNFz07NVIXJEbGoxGHY7nZm6J2TMoYQwJCJCIkAEqoPzjGHsrx5fH+1f5Z0UwSPHN5/+9uHy9O+H4gQEdUs+ECOnWMkTCmfX1wSGnNo2hZNy7IE5pgGBCImBFDLzI6Ys2QVYWZAJLScMztvgDFFZy6EwMw5i5kCYs6YcjK1ogg5CjkxGyefZIgp5+hEZTy9omRI2vXDZDL1zM5zztk7b6rOEQIAkScGBFBTBGfMjiGLYycqIuqYyXlRYXap7/f7Xdt1OeWiLLLkUsw7PlutVQQNuPBVWTjvJ1V95/St19uPsrWhogrqWzceTGeLmCKoqpmIKIJlARRSNDDv3HbXIL4syjoUHgnS0BESIuecPLMZ5ixggEhAkCSPKqDzQVQRYDadGQAgiJiZEbGNiN6MHaWU1JTBETswMLM4DF3Xu2EYmCFlAbCc87SqmdnMmmZPbzoGAhkYGDjvck45Swg+Qmz7HFxIKiYiZiKCSApmjF3fxdjnoc9ImJIBTuqZakKyMhRgRm6M4UHOaVYf3zq8//zqwxBkOV14V4kIEToXxKyAsX/BOGyVRdS07dNmu51O66oqZ9NZCOUIO8lIDQiRmQxQRNgxI2bJjgkICGiEVAamomCoZjSKYahFCAigZCmlmMQ5QgRG7KM0XeuYCYF8IFMLoQSAkRUikgHELGAKoIRITDknU/PeIQLYGAAdHz+gacrqGRTUEFW169PFaj2ZVIfzGyEUYBpTapq9Y19PKlQEMADr+p4dz4vjZz1SwWVVAmLXd2ZWhmAI2dA5BjCE8SQQEx1pw3q1jcMgInU17dq2rDDnyMTk/TUmIFQFRGR2SAQKZjo2IjAwQ1BhQhthFSIAJBEm8kyKNh7BiND3PaI6BQTNznkOnHPqhr7wAQCKUJgpIOEoA6moKAA477LkOEjOUpRlSonJEVFOGRCByaNzjuLQm2ooiuX88GC5cM7lbF0vRVES0dhuSFRFkdAyeKoLH1rZExKAOSYxFM1IDGY5qakCCBgBURYxFRURkd0uqpkqdl1TlTUCqZrEJDk7ZjUwUwQgovGZZs1o18TazNBUDEWEEBTQTBHQVAkRCdX6caguxu7mydKN2WZVUTNQ9c6z8wgmZsw49D0ie+9EbdSucs6I5Bw5F7IkRBQVVDBAxzQec2DQNI1qXs4mcWifPY8hFPP5DECYuSqLvh+YkBBMx6EPDVVVTSa71Q7EgwJ7jyqmY6NWABz3IaKJJjA0AzEDs6y637eE9NWjR8+evRQRVU05ScoAkEVEEhiImYmMFYVIYEZEojru7xEMIBHaNbw0UXbM5LJkxw5U7p8sXExDjKkqSib2wRMiGJppSkM0cERikjKMzUVydo6RGEzHyPcofcQ4DDF69qrSyB4QN9utGTj2GSKANldfbi/rarasqirGCIj9MEyd88EDmBkaMDKDMpNP0qthThEJ0HAc7lLRmCIgICAhKZiKEDGbqUrb9XR1icBmIwI3UzW1bEqIYxsHAGY2A5WcVREwphS8R0ADUBVmprFsEUAUAMbNa2aq4tg5R+xK571nvu7TSIBI3sL4myiqoin1Iqnr+rFn5JyGvk+ikhMApNiPoo3klHIiZIWMoIjo2CfJ6CY6JDA1wLIom65RtaIoq6rsuk6S5JyK0h3cmBZF0XYtg5RVRUSaM15XviIgsTODnCKMih0aAKhIyslsXFgDNWQahiHnjACeGZAMDAG7vjfREcr2cUCAFC1lyTllyc5xXdZmBohiBipIWdU0JzFTVWcwDoQLIWfJKcc4pCEOMaaUY47JwFTENKuaSJKsaooGbw4UHfuuiKgIEgKgcyaSED2zmmmSlM2HulaA1dXV4uCwCH7o43q9ulpbXYe6KipxIZQhh6Z93XNz9+i7jDj0vYEykRqCWVVVZqoGjksAEJGYM1zbOhhT3G+2oywDxAimpt75QYRQbeQ3iMCEgONMjopkyftmR4TEru+laXszHR0NHZUyxulsVnpvBu7i/LLruhiHYRhSSpKz5GygBGSgBiAyvj+67iOmoubYgalqBGbUGFMiREMiMFXL3uV0/UckSY6IapoIuSx8jgOi986JalkU7IWnDXZN37XNplFf3Tl5H8GJqCGCMRLHlNB0iMbsRkycUk4pAgAAZlWnIefkAk8nUxExMHaeiXAc9yUyADAAhBRTyrnt2izSD4Pk3MUYvDdNjniI0VSImQn7IWoeerOuH+pJDQDu7NXLfuizSBmCSjJVATOxbFFzziJAJFkQRgkIDExUTAWAHDsAyzmKASoogJqAWl1ViGCazVTVvC+JLKch9p0PJRLklCkERIzDIKrid32/vrq6GNJwvLxRuWWMEYBSzMwwqZfMbhi6lHLX9qNgopKY3Uh01URNg4ghXqxWYJCzGACBpZwBYFTix1JKKWZJiKRZbTR2Afu2BQBxjgDVrN1sslyffQhqBs1uk1N2m+06pVR41+YkOcWYAMkxKUAcenIecxriAKqqYmY5JiDKOcUhETOA9m1nSI6pquos2TEjYVU4GvOjZGqZwBVVIckQma4HdBAMJScRsyF2wyal7HxRl6VzGKOpJcfMnne7ZhxORABiAgAmBGMdB6u9M+CctYnNxcXV2dmZqcD4ygDDMBBzToMjHiVyRHDOdV2f0lCWlYlmyWooY6Fk0WtoIFk05wSGY1dFBJdiRICYsqScclIzRBz6rGaSkph5JgFwzGaQch6XwLEL0wLADKAIgRCKshq7kAvBDFJKBkCEZjQeZ+xCUTqVPJ62OaUxjgEKsPd9zIhjTx/fMBDRSLPIk4illEx1Np85H5pmHwfQkaEgeHYIqpbOXr3+6tHnqgKII3YFwKIMZqiSicmFIg79COVijN77vuu7rhdJajaCJ0RUVREFNBwlQEADRUDXDz2oimrOqiaOXRaJQ0+ETIyIIzhJSczEkTNAMEEEMzFRNY05IWA/JBEBw5T62eKwLoNjUkEzIyIiUtGYB0BEM+fIdJyfU2Lytgx2qyieJBUVL9GIyHtvZjFGyRneSOZdH/O+V0mqknPOWYjZvANgEWu79vzsJSKZ6og5iUhXauNjMQAEU0XCEIKqEhI7YsdFWTnvvHM+hCJ477wPwXvvnQuhCMH7Mf+ZczbRlGLTdSJal6WAOaaUhiZmlQyAVVkZmOQkkvuh79p+Mp0zU0oxi2y2a+9LBN3tdj6Eoijny2McB7FUcgYAVBUCJAYiHqfjiXDUvM0A0CTGNCh5P/IBJDZRJPTsENEM1Eb7JgEAESGhqJYFi2mMySCZYj2ZMDM79s4570IIRRHqqqzruiyryaSeTifT6aQsq7KsiqIIoQguoOPxRQnJAFRhhEeSJeasojnlLFlNXbtvyrI0UJUMYOvNar44QMAY09XVBaKrq3Lf7nbrbUpplMJC8Ao4xKFr9sEXk9nk4OBQTY6OjgyhawdDGmOiiMTsJAsCGiIAgREYec/jFTmEdj31kAGEOYRR6GVCM0sxjRoGADhGQlRDNQVDMPDO5ZxHJ2aISdXeenD/1370Le98CIFdYGIDIyJTNICcJaWkqkNMKaWmG1Lcj0P3Q4ySYlYREc0iKqNfaypgioAjDnDb3Wazueq7QRDNtG+al69fQ5Z+6KeLZd/vXr3slocHPjhybr/fzmczRBpyzKkPhe+6LoSwXa2iqGZRSTHqjdPbMG5UyaPAPeof4ww5IhDiCKCIHTuVlH3w7CHmLDldq/+giBCCH4/CsbgAEQENr68qUFKDUYPjmCQrv3h1lXLOMeasKUfNeRxA0dEaszzOPAPi9dsYtVEcubR5QHNo6NDADADGZ2Niagbu448+LstwcX42mcwAQQ188JJj4cPQ95oTqOWYZ8tlP/Q5ydnrs/1233YtGmSRvm+bfZNSFsk5RVW999b73/3hjxh1SAlwhF9IhGaGCAjAxIDkmMFgxPrb9LLTtQ8uD71qJEQFBCAclYbrd4yjAoUIoAaAajYKBQZIxMSQcm5W5wiihgBmBgBAYIAE1zQI9Xo/j0kEER25qZqZiJrJtSZxvaBIhKPiwuzcMHTb7brrmpRS1/UpJSZCJETYb3dD7EVUsjjvc47DMIApO/aOQyiqqizL4uDOjXpSTyeTqqrKsuRiNnbJ8V2MT8+xL8sSSbu2H0+kUJoB5GQgUPrp5earoY8gYd9tj2aJ0CPYCBQQgJHF5JekdxRUCBGYx8+JiIYMRBerbbdfAxKAjXWDiNfAlJGJnfPOueCcc4Vz46HumR2zc8x0/YcdswGNZQUGo/zvnjx6tFmvnfNZ8m63IUTnvPMcQphMqqOD+WQ6nU4ni8VsMpnWk8l0MquqKnhvgAZjeG6QJDGnvuv7YQAIjsgsj7hMwEgpp9SjOo9lzUVNZY2GKWWNDcYOSje/tXx/u9tsu/0wrM42H9bl8by8DQY2bjNEdqQ6ig9gADBahCpEBKoKxmCq9tbDe4vJ28555713gYgQYcR1BDQeDkQ8hkhGqWUUKtTMFEbdBxFFVURFskoeQ0im5gDz/fu35vP5wcHB8uBgOqnLsq7quixKIk5JUkp9Pwwx9t3Qd/1mc972vYyoNCUwQzIEHBUOIlqevEXMkpPoaMsxgBlYlkEpubKiwnExNsYMKACcWi7Doigr3a262NZpOJwtEAgJdSR0BqbmnJcsCGMUwwBGA+ANOQRThcX08OR4PsQ4wtiREpml8bYn1XwdLrxeixECCoAiYFYFMxEdxS+AEcOrvMEe7n/2P/1fSJahj23f98PQtc3FxVnXdTmnmGKKUUTGcIBjQsSxVAGB2QdPwTl2QVQ1SxYdhgQUaEw/iYz3ghAyERoBiDa7br9Xrm0+K8tAwSNOBQDTnryriFzwx6eLb5ZuMR4co9E+ejCSM5Mzw2vXE4GQDBSQMpAhAObNvqsLUNXr1JGZSjbQ0XhSlXFfG+AoY6jmUenVa+QOOspeNqZMxoIDUwU190/+yf9XJGeREateX3syXtlkY+8nj+PNZjSegjFGEVVpRu5ECOOOL0Ko6kK5UgXT0dYYn7yBIakHCgSqKnmXr1oB39QzrYqCyswigMk7qooABmqGo3uOaDaG05AJkFkyAOhoLKMBEI+vA4iG1PXaNI2ZMjsFRIMsacRNAMhMklVM7RqpGzMROUIY+iGm4ZpWjQrYuOKjSqxgqo4Z2YWgNu5eEcmSclQRGT8nIQKhZ/behSJURVVWZVmWRVEWRSjKogxFURRj/Kgd8ifPcp+NDAnd2M4AEYhGxwGAEMhTgWZ5KFbtWVN1k4nvhr7b71B1e/nCDeXDd37NTJiQmUXBTAkJCQhofF/jRTY6Et3xJZBEMQkul1NVw9ExBZCcicjGDSU6mgwynlEikiVLAucOjhZxiKOykvO4QRXN1AwRVE1ydpvNVlTBDJkck/d+Mp2UVVGVVV1X3oeqLEMIIRTMTMg40nADNcsiWXIS1D4jZmbe96mPNEShLKbgPL+5owcBEUbzYOy1hg6Kmm5J1ze6Onvx4vJFQ27SS3freA5maoDGcbCx2dFIsCzbdWRjdPQgy6g5W86QxZLifLEIzl/fZgag+uaBAYgKAqrqeBSq5pxl3E3OOQQY/zpKo0NMKqqmOBaxgXvv/XeqsgrBh7L0xEAcfBjBCIClLCJixllGWm3MDKgI5L1nAkIHaEUITEwI6yaZ5t2+LymPWNx7570zyWrgvCfilLJe14YCoMM6dSzymsoiRSmKUNTTkXOoCSKOKn0CQFVCAASDN2YPmA8+C/apTzmrWsqWojqCN8GOcWHxeumMxmOGGQDGq0kUgXDEOgBhNGnRVMfJEtBrNwjVzJ0c3TQ0EU1REohznGJSVSRkYjPxTOy5LAIxj+za4NovIcRr4MeEMEp/bdtLTnFAQSIDVTRfeO88IWSRnDMiqJGIMrH3LidhKheTh6Vb5fi6nByX5VwB8phgNqMRyiJmRDVEwFHrNAA1SFFSlhg1K2SBrDBkKez6xBl34mjwGF7bNjKiv+uxHANTwPHIeXNT1S8X743sMDplrunawgcicMEXRcFEokqEzrNjBiDH9IYSXF95BeYATFUNcKwQE1BQRGq6xIR9n8xlxw6RIemuifVkUgVXFxazDMNAgGUIOeUscaSuZaiczyHQzaN3S78syqrphmtjBgAJk44sDQvnq9LnLEkhSRrSOFhtSVDMRDBFpdlIAOANG+JxmRRgNHIYKeuonZiagoHKmDy1N/6Fvml2I28ABHPHRwdlUYwJGe/9tXY84nzAURoFIEJCg18GDM2UxlK+phQwHuE5DSiwazzWhCgkaOwNsGm6piuyucKb57Cchr7v+75LKYIBIwDQyclDibcW03vtEJshF0UwpJwTE1VFVddl10Vi1mz7SKLQ9hkMs5IKD4JJLCZA9lmvC8IA6Nofujbcxj2ppiMfeJNvtl+arobXwI2Rrl1rMwQjJAB0dTVBBHcdhwZANjMCHHs/XceeVcexgrEHv6mxEV4DmgGBgagmQ6TB2BSpz2ColiIgEJf7DlAbLKicz5IWCirWiSETAKhz/u17P2ybpo+xrkPKFpzzXLmJ5SxZtE8EXGz3fTtkMVeWAZn6flDlPuUkkBWRwLsUc0IiAlAVABzPtlGzHD/iNRg10//+Sv2yI1zv3TEeB2hjK1BEcoCgAKMWZ9d7F3SExUTX8SQAGjnZL9NIMKJ2Gu2DseJSlsst7NN0cftWNaN2u26TekBX1M3gTFsGuWpc1KyQ0HIdShccoRYsRSjayFjMKtd7dmJZATQN0YiIsmGzHYqiMGQDEcVNI8FjVsyiBuxKPz9ewibuzl823XXpAJhco9M3TxpGAWMEbkZG176U2pufGBHptblOBkBEIgIGCtkR0SjOjh8e39Qh2CiUjNsYEMkxjVVl8IbU2/WG9kwKFmPeNDFi8fnT9eHJwXRyA2JTCFhvaK1qytm8kxCqfY8McLXLs4mH1J716WAR2nYDpofL+nK9zmlwvuqTEnIoa19Ms0m3z9O6rKazbrMdMgJC1DILZFOJ4eLlsLq8TE0zIYwpIfD4/scZgpGwIMLotyKCqorIWHFmI6jEEZEBGCgkzSOr9t5LFpHsxuIc/0d6k4MYhxyyZDRAMCQ2gCzKOF7hPIog4y+yGSQRJOj7HCNG1r7Jg8WsnsvTaaUHRYMiJgQmh8vF6w0xppxyFVzTaz9AThAGaLpceDzfQttijuZLVA3zeb2LmNpcFrzZD683RIgGtNv3vpyJ5iFXQ2ra5qpvWkYlgF5I1NBGMRpjjGMlIQI5BoSRAF5X05sAnIoQIoBTFSIcw5JmmpIQjRIQO3ZuFHARYQS4414W1XEvExOZjplIAhtZlarg9bYVM0XE0vkYddgNjUJvDr1wiUApzspYLtBQU1OEsN6n+TQ65+uC1yuTlLvkysBdBtGptsyUtjv0blpm3/a6bgZi/+qyCaGuSjKUrLpdXQ3RlClbaAbnuFbJuUuBmtLJfqspQRFIZIxD6IhuRM3yGMXK+AbliRkTmSgzm2pOAgQ5Z3wj4Y8HmKoigssxOudUsl6zAVRVZvLeXyNXsDFIKCJj4Hd8IgDoxgUEBENRzUYI0F++jtAX00G758Z16ScIkyGFrouEmTk7Xmy3ESkx1zHRbpfmk9THTGBZ4PAw9E2XpJpUOUuK0cSg63suyvkUU+p9MU292+xi0r1Dy0JDWgEiYiFKYumQJA4D2LhLCIBUBUBMR4EBCCHlEUUAEaUsiKYCI6aHa1aqo/A97tARfbkxTiQq17VDiOgAQNXGG9JGxxwJEIgIRyRHhDlngYToiFDVnCOTNJvXZy/PIT4X2UM4lfK0o/tRfYqxTRo8suHjl6nvI6MAUsaF9S/VrG36sjAweXFWx6FWKM82XDgRY8e5GRLnatM6YmIOoToZQhIwgBx3K4xDbp4GNrPy9M7s7fvZNDs3gf/ekfuma42nOxNCynaNs0YpYtxcNMaPxtPZzEZyOq4XOHakYowMON5ATyoyDHEMs4nkMcE7Cnkj/UTEUaUxM8KcsxkQEsTc3ziWFO9/8tHjWYExvdTVyqbIsyPkYh9TiihumnWuEox88GrRK95qumwITcSxRAExuD7lqk8OyFwZMWvMnWoETRwgJSG0OGDs+5D2aX+hknE5++7XZh/c192ub/pQlMUo6dEbdHOtpRgCAJNTtrEVOkdj7MoUCMnQrmfJENUspeSYxIyIXd8l5/iXRZVFctZRjbnuo6pJBQENTFXfICx7M4MABsAMMebF1CH4o4Ur6ne/erRTTCEMNX5Ow9O2EdxG8HPjEmyZOpZkPRGAmTl0hRkF7wAG5DT0NICCggH6IuyuMhhabkQjasMhi4ordJI27f5MQ3nz7p1JWX3/29Mb87TfdVXFZcExxjGQRsTX2US8hgeqOGYtVTMS5gTEOLL98QMSIY2TwqqIkJMwUxZxBkbM4/Em4zDL6EheTyleb9cRSY0arWRBRhADAAWE8cbanNo+z2aTou9/9DW4d/vOLz6Tdr8zKpG86QXKhdl5UZTsJymuLaoIIpEJKHnmEOVae3LeIaiZEYF2WdWyTMhazw3RUGAY0hDzBJEPTk9u3zl59z6fHibvMhiUk3LKDhTHxj5KNACgBtcYCWnkIKhAxCNMEAEwSpaYaIw7qkFMopqZ6ZqMWnYpZQAYS2tUM1Svj6oRzqUsI2EeU3iICqqMbGaIhsSi2QD7vn/58nx5fFxXJWp6cByPDxeSJxdrOr9K2/0SS0TLBkjeu8Ihduw4xW3uO9GERtXswFSHdg9mzgcAZ9IyowAXxV7zEOoZ0dKXFQ79wUH1tfcOTg5sEjpAQHTkKu+dFz17fTnE/u6t07GFMZEqvjlDDEBzHmGqETICgHOmykSipKrIOnZRQhXR0YEf5VmXJeecRksDkUJwI95FJFMTzaYWJY/bWNWCZw7eOUeEjp3qqKJA1w/90H3x6LF35WRaFd4fnrijZbh1Ug558ux+fXZ5+Or1vmujcx5Z0ZfoKtQ9Fy2BEeLi5E7f9K6IQ7d17Lu+I6yy0HQ6FyBf6/Lw6OjQ37np53W/nHvUAQDJV/XsYMjQ7prLq92z58/jsLtxtMySTAEM1NHYzQEMcZwlVDMTNYUEgKiEgGYZkcavHAAwvHaISSSbmWRAIjduhnHVRYeck2Meb5S+7n8IzpGqiaonAsSUZOyVRIRgzE7Nuq7rh16SxT7uhwxcv9pePbi9LEJyIRwfhskkvv1wzlQ1jVxulvuNnF8MkGdtq0enh5cXXdu56UER3NBHU7HTCo+Pp4eHuJiGxYIIxHOsClPJKRVZbOhJANudbF6cb/e7zdWFpM5hKhzFmDXbNe3XUQYgVVMzsKwAjslkPMgwZ3GOQcFQHaOosSMzcMyqNtIdRDZT9wbgA5IRoEgeMRQhISGzU83XxBkti6KCiOaMI1QjIoCkYj7UN27devH8uciQ2waAsQ9X7gQAyBWhqpEd4KbwBkQHy2Ix1+MbUbKAGrrzH/7w1DkfJbWtQ0dlWc6mdVV4Iu6a/dC3/TCkYUiizXbTbDZD3+aUhpTl2jDOqEPhHSCyK5fLub2RoeyXOSvN4wiKQzI1x06vOZDmrM4xAUvWLHkcoE+aCcEAx5UyVXdNna7dRGPma4/WhJhNjRgRyTGykTmQLCn3knT0FEa2JSr7Dr/2/jdv3jo9Ww8gfbffdt1wemO+WM7KsmQmMzw4OvGBy6JQtW7om6ZJQ2umMcpyWSH5rs0b25Mr1AZrdu0OHJOk2DZNjENRlM4EqA9TLU4OiSzFtGt7BASVEFwo54jueFk5ZDAdtxXh9XyAGRLAtWCJqKZErHJ9uZqqAamaXpNlMFVVVGZvJjS66M45ABjtCSIyUwIAdgCGhGCQUlJNzETEzOSc8+LMEsg4qTA6oTTE4cvHux//+Dt32y2C2++2u9X50dH85PTB0eFBKAskqiezsURFdRiGdr+PcWBHzW6f4tB1XTmblUhFEdarVYx9Ufi+25HYUeknN5aItDo/E9TZ/LBenJzeOt2vz5+/OC/r2cHxybe//rDdbtZXF00vFxfbKmQCFBO+/vAykjlEJh7nvkxViZAA34RClYgRr9PuY8cb4YZIRkOnCqN1jARMbEZmCkY2on24JlMiqgIxRmYmdEXBQ9crCDEasgwyn9YDxtcvru7dP237ZlqXzKdmeRi6bpi6opxNZswh5zxOC5lqznHfNGCcU2rbDlVc8KKWkoiIEXExCSKbzTpFqWZztoQQUQeCYrmc3r198qx5HQr39tfeu320kCiELmU2qLxrACSrMOE4MMjEhGgAWZWBiDEnIwIRVURmArDgvKoR8TiH5j2rjFiNc85D6hyCMoEBqUpM0TuvakwjBxq1MRxiIiREtFHhUAjBF1XhsqQkOWZEzindvXvw7nu3UIbByJfVZt9OA+R8PdwCwKpCBGYgKkgEQKAiaYh9Q6BDHHIeNKc+9rHvEHG/OssxpZgXR0ery9ViOZ0fnYpCO0iOEYEPjo4Wpw8ePPgApF+vV/t9a4YX5y9z2nrnxvv/nSNEFB1HAA0AVYTeCJh0/a02RAgqoGYiycwQYBjSaII5YkCrq4kbWSFey56koqOQOI47jcCXiHJMRVVpRiQwUhEFGVtMIiIRU4QPf/Gh85Nf+Ze+5apNzHR8dLjd7vr9VvKAkEGzK0oksiGaWlmwTKfhenJqBqrb/XZ7eaE5IoEPREhlVbX7rVyPOvYhhOXxreCrlOJkPiPiB+9/GyTl1IihmqY0fPH5oycvn908OSwLr57NwKUxBiAAkWhcH3TKaoBoRAwGSWLfRURg58rSp6SmpmpEJmrAGlP2PjhVQwJTcY67rv/l6qQkkjNeDzkzsmNy6LKpAXKKMY0ZdCRiGoY+C7CHP/iDf/z0yZPv/vD7y8P5ya2jz55N/uHvuwfH7dsP+P7t4Z23jw8Pi8KTsFO1oghoxszTyWxIuawWi9lh22yrulZVyXFzdSVDxGkxKSvPXHj/7PFXPlRHR6cHR0eLo5Pjo6Vj6tv+9fn5+fn6j//kZ0+eP14uF4BgapIV0ZIKIhBzTnlUyYkxpSQqhMRMYODcdXQopZhTGvN+CDS6fH1WQhz63nXdIFnGjAog2DjeS6Rijtkgx5SimXN+n3aAxuz7vgfDmKKqAiIYiIIomFhRhI8++Refff7zd9/9+ne+9/2JX3Qt/tHPLv/bP0cKsKyfvHUrPLzN77w1nZSxLlUtDkPKWUFts9p2zdasCeTESFX7Ybg438bE21b2veti6rIfYqYi3XrP/Tv/Qzme25dfPvv8y8eff/7ln//0j1Jq6+nURPa7VosAIN4zExuio9wP42iwOecNQFQcu5wiEY0+jnM+xkSEOSckCsGbwjAMMSXHFGPEf+/f+/e7rvPewZhbHa3mnIvgf0lxmBwxxTioKrMD0Jx1VBvGkRdVjCkDcNMn8rRdXzW7fVHUt+/cWxy+82J7+urCLtqjXc9ZCyAGAg9D5VIZNDhxnGSQ/bZru+i8okWJvQiqkUhnWoFlLNgks9P5ZHjn4eGv/uDBzenui8++/PLxV1fnL/f9tiyLyXRRl6VnLqvACEzjiDuNIpLkZNfkBM10pCjj1xr+Mg8AgABKfI3SGdl5SjmbmYrhv/F3/x5eG6SQJV87Gdffe+bUDExpzPqY2LWLAUyccx6/OAoJVa9z+knM0PV9pyaWht1uq5JDqGeLG/PDe1zfTXDc5cU+1u1AbaS+137QnEFzsjwQ5pwd6I7yimzwNDjc15PlcgnzGU1rmdc9w5CH/dnLp2evX7d9SwRFGYqiLqqqLKoq+BHfgCleDwGT9zzqd5Kzmo3pgdHaRkIAEFHneDRCEZHJAUBKERHHUbSxkvB3f+dvERORAwMDGZUGNSNk55yo/JJVmcI4ewhwHZJRFSIHNsItFFUAFDUFcI5yktXVRRz6rt33wwCmxH5ST+vpwWxxNJ0dFtU8lHNyBbnSjFJWMhWNpjENETGjDUN7OUrY283VbrNq2l3fdyLZOfLeex+KahJCWQTPzN67sWs7dgCCyEhgYi54FcNrH/taAh2tFnozTQlIpuJDULFxpAzhWj6wUWAwdUPsR9+ByI3phJGsZ8spxTECgngtm43WDjOLyHi1AcCYk5M309QOCWOMDFWGVJWBCZgpFH1KQ0pp36zWm3N7agYGNpr+PF45da1VjrkMGYdFVDWP2uyorIwEvix9CKEoCudCKComcoxjMEEgw3XNgOTEjsEw9+IcmY5z4zge7UhgijpmBwGIWbOkJL/0pUXGS8pQJI9C4P8fvwFkqD3nYRgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong['imgs'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ff3dddc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a teddy bear with a bow and pink dress and a brown teddy bear in shirt and pants'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong['caption_w'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "193978d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>imgs</th>\n",
       "      <th>caption</th>\n",
       "      <th>cat</th>\n",
       "      <th>y</th>\n",
       "      <th>caption_w</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>000000115299.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-3.797961711883545, 1.0124297142028809, 0.41...</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>A man made replica of a palm tree on a beach.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>000000061676.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[0.8911221027374268, -0.39232003688812256, -0...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>a motorbike standing in a two sided beautiful ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>000000135267.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-0.6677790284156799, -0.946922779083252, -0....</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>some plants two mirrors and silver handle bars</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>000000145791.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-0.022466225549578667, -0.483224481344223, 0...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>a weird sign does it mean the men at work are ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1  \\\n",
       "335  000000115299.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "154  000000061676.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "31   000000135267.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "361  000000145791.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                                  imgs  \\\n",
       "335  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "154  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "31   <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "361  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                               caption  cat  y  \\\n",
       "335  [[-3.797961711883545, 1.0124297142028809, 0.41...   28  1   \n",
       "154  [[0.8911221027374268, -0.39232003688812256, -0...    4  1   \n",
       "31   [[-0.6677790284156799, -0.946922779083252, -0....    4  1   \n",
       "361  [[-0.022466225549578667, -0.483224481344223, 0...    8  1   \n",
       "\n",
       "                                             caption_w  y_pred  \n",
       "335      A man made replica of a palm tree on a beach.   False  \n",
       "154  a motorbike standing in a two sided beautiful ...   False  \n",
       "31      some plants two mirrors and silver handle bars   False  \n",
       "361  a weird sign does it mean the men at work are ...   False  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong[wrong['y_pred']==0]  #number of false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d82ba53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test[df_test['y_pred']==1])   #number of matches predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5b695b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(right[right['y_pred']==1]) #true positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d18e4fbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wrong[wrong['y_pred']==1]) #false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "292a15ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6267605633802817"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "89/(53+89) #precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62333cb2",
   "metadata": {},
   "source": [
    "We can see that most of the mistakes come from false positive and only 4 mistakes are due to false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "32474d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m,'best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d305742",
   "metadata": {},
   "source": [
    "##   One can load this model by using the following code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee9fb62",
   "metadata": {},
   "source": [
    "see the documentation in cap_models.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cf6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cap_models\n",
    "m = torch.load('best_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f37ed",
   "metadata": {},
   "source": [
    "# Check for the bottleneck\n",
    "Should we work on improving the NLP part of encoding the captions or  woud it be more efficient to improve the convolutionnal layers that encode the images?\n",
    "To answer this question we will will divide our learner in 2 : one that uses the images to predict their category ; the other that uses the captions to predict the category of the image associated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe43bae",
   "metadata": {},
   "source": [
    "first we need to access the categories. They appear under 'name' in the coco dictionnary."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f1143b8",
   "metadata": {},
   "source": [
    "Adapted train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "19d7a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['caption']=data_df['caption'].apply(encode_and_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "c4e10bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "800\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#Images scaling\n",
    "\n",
    "images=np.array([np.array(im) for im in data_df['imgs']])\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "images_scaled = StandardScaler().fit_transform(images.reshape(images.shape[0],30000)).reshape(images.shape[0], 100, 100, 3)\n",
    "\n",
    "\n",
    "#Divide in train(80%)/val(10%)/test(10%)\n",
    "\n",
    "#from transformers import BertTokenizer, BertModel\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "n_train = round(.8*images.shape[0])\n",
    "n_val =round(.1*images.shape[0])\n",
    "im_train = images_scaled[:n_train]\n",
    "cap_train = np.stack(np.array(data_df['caption'].iloc[:n_train]))\n",
    "y_train = np.array(data_df['cat'].iloc[:n_train])     #this time our targets are the (90) categories\n",
    "y_train= y_train-1                                     #we want the categories between 0 and 89 (instead of 1 to 90)\n",
    "im_val = images_scaled[n_train:n_train+n_val]\n",
    "cap_val = np.stack(np.array(data_df['caption'].iloc[n_train:n_train+n_val]))\n",
    "y_val = np.array(data_df['cat'].iloc[n_train:n_train+n_val])\n",
    "y_val = y_val-1\n",
    "im_test = images[n_train+n_val:]\n",
    "cap_test = np.stack(np.array(data_df['caption'].iloc[n_train+n_val:]))\n",
    "y_test= np.array(data_df['cat'].iloc[n_train+n_val:])\n",
    "y_test=y_test-1\n",
    "\n",
    "\n",
    "print(len(im_train))\n",
    "print(len(cap_train))\n",
    "print(len(im_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978c502",
   "metadata": {},
   "source": [
    "We check the image part of our model by creating a classifier that uses the same conv and linear layers to predict the categories of our images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2133a53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn                   #the image classifier\n",
    "class Im_classifier(nn.Module):\n",
    "    def __init__(self, hidden_size, LSTM_out_size=500, height=100, width=100):\n",
    "        super(Im_classifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.layers1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, 3, padding=1), # three input channels, three output channels, 3x3 window\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.MaxPool2d(2, 2), # 2x2 window with stride of 2\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.layers2 = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, 3, padding=1), # three input channels, three output channels, 3x3 window\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.MaxPool2d(2, 2), # 2x2 window with stride of 2\n",
    "            nn.Tanh() \n",
    "        )\n",
    "        \n",
    "        self.layers3 = nn.Sequential(\n",
    "            nn.Conv2d(3, 3, 4, padding=1), # three input channels, three output channels, 4x4 window\n",
    "            nn.BatchNorm2d(3),\n",
    "            nn.Tanh() \n",
    "        )\n",
    "        \n",
    "                \n",
    "                \n",
    "        self.layers4 = nn.Sequential(                               #3 dense layers to classify the output\n",
    "            nn.Linear((int(self.height * self.width * 3/16)), hidden_size),  \n",
    "            nn.Dropout(0.4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, int(hidden_size/2)),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(hidden_size/2), 90),             #90 categories\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, batch):            #batch is a tupple \n",
    "        batch_size = batch.size()[0]\n",
    "        \n",
    "        # permute the channels to the form pytorch expects\n",
    "        current_matrix = batch.float().permute(0, 3, 1, 2)\n",
    "        current_matrix = self.layers1(current_matrix)\n",
    "        Im_matrix = self.layers2(current_matrix)\n",
    "        Im_matrix = Im_matrix.reshape(-1, int(self.height * self.width * 3/16))\n",
    "        \n",
    "        \n",
    "        return self.layers4(Im_matrix)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "df21fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable                     #the caption classifier\n",
    "import torch.nn as nn\n",
    "class Caption_classifier(nn.Module):\n",
    "    def __init__(self, hidden_size, LSTM_out_size=500, height=100, width=100, device=device):\n",
    "        super(Caption_classifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.LSTM_out_size = LSTM_out_size\n",
    "        \n",
    "        \n",
    "        \n",
    "                \n",
    "        self.lstm = nn.LSTM(100, LSTM_out_size, batch_first=True)\n",
    "        \n",
    "        self.layers4 = nn.Sequential(                               #3 dense layers to classify the output\n",
    "            nn.Linear(self.LSTM_out_size, hidden_size),  \n",
    "            nn.Dropout(0.4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, int(hidden_size/2)),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(hidden_size/2), 90),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, batch):            #batch is a tupple \n",
    "        batch_size = batch.size()[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        h_0 = Variable(torch.zeros(1, batch_size, self.LSTM_out_size)).to(self.device)\n",
    "        c_0 = Variable(torch.zeros(1, batch_size, self.LSTM_out_size)).to(self.device)\n",
    "\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(batch, (h_0, c_0))\n",
    "        out =final_hidden_state[-1]        \n",
    "       \n",
    "        return self.layers4(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4a90a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim                  #training function for the image classifier\n",
    "def train_im(im_train,cap_train,y_train, batch_size, epochs, model=None):\n",
    "    b = Batcher(im_train,cap_train,y_train, batch_size, max_iter=epochs)\n",
    "    if not model:\n",
    "        m =Im_conv_layer(3000, im_train.shape[1], im_train.shape[2]).to(device)\n",
    "    else:\n",
    "        m = model\n",
    "    m.train()\n",
    "    loss = nn.NLLLoss()    #for multi class classification task\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.005)\n",
    "    epoch = 0\n",
    "    for split in b:\n",
    "        train_acc=[]\n",
    "        for batch in split:\n",
    "            tot_loss = 0\n",
    "            #print(batch[0].shape)          \n",
    "            optimizer.zero_grad()\n",
    "            o = m(torch.tensor(batch[0],dtype=torch.float32))\n",
    "            #o = torch.argmax(o,dim=1).float()\n",
    "            #y = np.zeros((batch[0].shape[0],90))\n",
    "            #for i in range(batch[0].shape[0]):\n",
    "            #    j = batch[2][i] -1\n",
    "            #    y[i,j]=1\n",
    "            #l = loss(o.reshape(batch[0].shape[0],-1),torch.tensor(batch[2],dtype=torch.float32,device=device))\n",
    "            l = loss(o.reshape(batch[0].shape[0],-1), torch.LongTensor(batch[2]))\n",
    "            tot_loss += l\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            batch_train_accuracy = torch.sum(torch.argmax(o.reshape(batch[0].shape[0],-1),dim=1)==torch.LongTensor(batch[2]))\n",
    "            train_acc.append((batch_train_accuracy,batch[0].shape[0]))\n",
    "        print(\"Total loss in epoch {} is {}.\".format(epoch, tot_loss))\n",
    "        epoch += 1\n",
    "        \n",
    "        if epoch %10 == 0:\n",
    "            tp=0\n",
    "            np=0\n",
    "            for n,denom in train_acc:\n",
    "                tp+=n\n",
    "                np+=denom\n",
    "            train_accuracy = tp/np\n",
    "            m.eval()\n",
    "            b_val = Batcher(im_val,cap_val,y_val,  batch_size, max_iter=1)\n",
    "      \n",
    "            correct = 0\n",
    "            split = next(b_val) \n",
    "            val_acc = []\n",
    "            for batch in split:  # Iterate in batches over the training/test dataset.\n",
    "\n",
    "\n",
    "                o =  m(torch.tensor(batch[0],dtype=torch.float32)) \n",
    "                batch_val_accuracy = torch.sum(torch.argmax(o.reshape(batch[0].shape[0],-1),dim=1)==torch.LongTensor(batch[2]))\n",
    "                val_acc.append((batch_train_accuracy,batch[0].shape[0]))\n",
    "            tpv=0\n",
    "            npv=0\n",
    "            for n,denom in val_acc:\n",
    "                tpv+=n\n",
    "                npv+=denom\n",
    "            val_accuracy = tpv/npv\n",
    "            print('train_acc={}'.format(train_accuracy))\n",
    "            print('val_acc={}'.format(val_accuracy))\n",
    "            file_name = 'cap_cat'+str(epoch)\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': m.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, file_name)\n",
    "            m.train()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3774340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training function for the caption classifier\n",
    "def train_cap(im_train,cap_train,y_train, im_val, cap_val, y_val, batch_size, epochs,device =device, model=None):\n",
    "    b = Batcher(im_train,cap_train,y_train,  batch_size, max_iter=epochs)\n",
    "    m = model\n",
    "    m.train()\n",
    "    loss = nn.NLLLoss().to(device)    #for multi class classification task\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.005)\n",
    "    epoch = 0\n",
    "    for split in b:\n",
    "        tot_loss = 0\n",
    "        train_acc = []\n",
    "        for batch in split:              \n",
    "            optimizer.zero_grad()\n",
    "            o = m(torch.tensor(batch[1],dtype=torch.float32,device=device))\n",
    "            \n",
    "            l = loss(o.reshape(batch[0].shape[0],-1), torch.LongTensor(batch[2]).to(device))\n",
    "            tot_loss += l\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            batch_train_accuracy = torch.sum(torch.argmax(o.reshape(batch[0].shape[0],-1),dim=1)==torch.LongTensor(batch[2]).to(device))\n",
    "            train_acc.append((batch_train_accuracy,batch[0].shape[0]))\n",
    "        print(\"Total loss in epoch {} is {}.\".format(epoch, tot_loss))\n",
    "        epoch += 1\n",
    "        \n",
    "        if epoch %5 == 0:      #every 10 epochs, print the training accuracy, the validation accuracy and loss, \n",
    "            np=0                #and save the model param\n",
    "            tp=0\n",
    "            for n,denom in train_acc:\n",
    "                tp+=n\n",
    "                np+=denom\n",
    "            train_accuracy = tp/np\n",
    "            file_name = 'caption_class'+str(epoch)\n",
    "            torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': m.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, file_name)\n",
    "            m.eval()\n",
    "            with torch.no_grad():\n",
    "                b_val = Batcher(im_val,cap_val,y_val,  batch_size, max_iter=2)\n",
    "\n",
    "                correct = 0\n",
    "                split = next(b_val) \n",
    "                val_acc = []\n",
    "                l_val=0\n",
    "                for batch in split:  # Iterate in batches over the validation dataset.\n",
    "\n",
    "\n",
    "                    o = m(torch.tensor(batch[1],dtype=torch.float32,device=device))\n",
    "            \n",
    "                    l_val += loss(o.reshape(batch[0].shape[0],-1), torch.LongTensor(batch[2]).to(device))\n",
    "                    batch_val_accuracy = torch.sum(torch.argmax(o.reshape(batch[0].shape[0],-1),dim=1)==torch.LongTensor(batch[2]).to(device))\n",
    "                    val_acc.append((batch_val_accuracy,batch[0].shape[0]))\n",
    "                tpv=0\n",
    "                npv=0\n",
    "                for n,denom in val_acc:\n",
    "                    tpv+=n\n",
    "                    npv+=denom\n",
    "                val_accuracy = tpv/npv\n",
    "                print('val_loss={}'.format(l_val))\n",
    "                print('train_acc={}'.format(train_accuracy))\n",
    "                print('val_acc={}'.format(val_accuracy))\n",
    "            m.train()\n",
    "\n",
    "    return m\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "abe4a049",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_class = Im_classifier(3000, im_train.shape[1], im_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "58119997",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_class = Caption_classifier(3000, im_train.shape[1], im_train.shape[2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1c608f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusmoreyo@GU.GU.SE/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 7.451404571533203.\n",
      "Total loss in epoch 1 is 5.0584492683410645.\n",
      "Total loss in epoch 2 is 4.683510780334473.\n",
      "Total loss in epoch 3 is 4.039694309234619.\n",
      "Total loss in epoch 4 is 4.171459197998047.\n",
      "Total loss in epoch 5 is 3.900845766067505.\n",
      "Total loss in epoch 6 is 3.2547528743743896.\n",
      "Total loss in epoch 7 is 3.304232120513916.\n",
      "Total loss in epoch 8 is 3.8690378665924072.\n",
      "Total loss in epoch 9 is 3.9178333282470703.\n",
      "train_acc=0.20999999344348907\n",
      "val_acc=0.14000000059604645\n",
      "Total loss in epoch 10 is 3.9714438915252686.\n",
      "Total loss in epoch 11 is 3.6456305980682373.\n",
      "Total loss in epoch 12 is 3.8494365215301514.\n",
      "Total loss in epoch 13 is 3.3829681873321533.\n",
      "Total loss in epoch 14 is 2.587573766708374.\n",
      "Total loss in epoch 15 is 3.508437156677246.\n",
      "Total loss in epoch 16 is 2.4930009841918945.\n",
      "Total loss in epoch 17 is 2.5025436878204346.\n",
      "Total loss in epoch 18 is 2.4125235080718994.\n",
      "Total loss in epoch 19 is 3.4437179565429688.\n",
      "train_acc=0.3787499964237213\n",
      "val_acc=0.1599999964237213\n",
      "Total loss in epoch 20 is 4.378978729248047.\n",
      "Total loss in epoch 21 is 2.6231319904327393.\n",
      "Total loss in epoch 22 is 2.412431478500366.\n",
      "Total loss in epoch 23 is 2.6295363903045654.\n",
      "Total loss in epoch 24 is 1.8768361806869507.\n",
      "Total loss in epoch 25 is 2.653837203979492.\n",
      "Total loss in epoch 26 is 2.451784133911133.\n",
      "Total loss in epoch 27 is 2.028017044067383.\n",
      "Total loss in epoch 28 is 2.5847890377044678.\n",
      "Total loss in epoch 29 is 2.496131181716919.\n",
      "train_acc=0.45124998688697815\n",
      "val_acc=0.25999999046325684\n",
      "Total loss in epoch 30 is 2.8888778686523438.\n",
      "Total loss in epoch 31 is 1.7554535865783691.\n",
      "Total loss in epoch 32 is 2.3065195083618164.\n",
      "Total loss in epoch 33 is 2.676894187927246.\n",
      "Total loss in epoch 34 is 2.511125087738037.\n",
      "Total loss in epoch 35 is 1.6481038331985474.\n",
      "Total loss in epoch 36 is 1.8234198093414307.\n",
      "Total loss in epoch 37 is 2.226024627685547.\n",
      "Total loss in epoch 38 is 2.5433506965637207.\n",
      "Total loss in epoch 39 is 2.7653849124908447.\n",
      "train_acc=0.5049999952316284\n",
      "val_acc=0.2800000011920929\n",
      "Total loss in epoch 40 is 1.7715693712234497.\n",
      "Total loss in epoch 41 is 1.6728284358978271.\n",
      "Total loss in epoch 42 is 2.499960422515869.\n",
      "Total loss in epoch 43 is 2.307020664215088.\n",
      "Total loss in epoch 44 is 1.4131200313568115.\n",
      "Total loss in epoch 45 is 3.045374631881714.\n",
      "Total loss in epoch 46 is 1.4475631713867188.\n",
      "Total loss in epoch 47 is 2.331697940826416.\n",
      "Total loss in epoch 48 is 1.3770709037780762.\n",
      "Total loss in epoch 49 is 1.7164921760559082.\n",
      "train_acc=0.5950000286102295\n",
      "val_acc=0.3400000035762787\n",
      "Total loss in epoch 50 is 1.387093186378479.\n",
      "Total loss in epoch 51 is 2.4176979064941406.\n",
      "Total loss in epoch 52 is 3.7159769535064697.\n",
      "Total loss in epoch 53 is 2.295445680618286.\n",
      "Total loss in epoch 54 is 2.4638407230377197.\n",
      "Total loss in epoch 55 is 1.9316935539245605.\n",
      "Total loss in epoch 56 is 2.1097140312194824.\n",
      "Total loss in epoch 57 is 2.4160819053649902.\n",
      "Total loss in epoch 58 is 1.6985028982162476.\n",
      "Total loss in epoch 59 is 1.0904031991958618.\n",
      "train_acc=0.6137499809265137\n",
      "val_acc=0.46000000834465027\n",
      "Total loss in epoch 60 is 2.4562172889709473.\n",
      "Total loss in epoch 61 is 1.045723557472229.\n",
      "Total loss in epoch 62 is 1.2520772218704224.\n",
      "Total loss in epoch 63 is 1.7163735628128052.\n",
      "Total loss in epoch 64 is 1.5492169857025146.\n",
      "Total loss in epoch 65 is 1.312366008758545.\n",
      "Total loss in epoch 66 is 1.4793771505355835.\n",
      "Total loss in epoch 67 is 1.018922209739685.\n",
      "Total loss in epoch 68 is 1.2596110105514526.\n",
      "Total loss in epoch 69 is 0.9965542554855347.\n",
      "train_acc=0.6974999904632568\n",
      "val_acc=0.5\n",
      "Total loss in epoch 70 is 1.1825530529022217.\n",
      "Total loss in epoch 71 is 0.6223303079605103.\n",
      "Total loss in epoch 72 is 1.7445805072784424.\n",
      "Total loss in epoch 73 is 1.3778841495513916.\n",
      "Total loss in epoch 74 is 0.8197029829025269.\n",
      "Total loss in epoch 75 is 1.5514107942581177.\n",
      "Total loss in epoch 76 is 0.7136862874031067.\n",
      "Total loss in epoch 77 is 1.9505202770233154.\n",
      "Total loss in epoch 78 is 1.1249638795852661.\n",
      "Total loss in epoch 79 is 1.48041570186615.\n",
      "train_acc=0.7087500095367432\n",
      "val_acc=0.47999998927116394\n",
      "Total loss in epoch 80 is 2.3157007694244385.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Im_classifier(\n",
       "  (layers1): Sequential(\n",
       "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Tanh()\n",
       "  )\n",
       "  (layers2): Sequential(\n",
       "    (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Tanh()\n",
       "  )\n",
       "  (layers3): Sequential(\n",
       "    (0): Conv2d(3, 3, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Tanh()\n",
       "  )\n",
       "  (layers4): Sequential(\n",
       "    (0): Linear(in_features=1875, out_features=3000, bias=True)\n",
       "    (1): Dropout(p=0.4, inplace=False)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=3000, out_features=1500, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Linear(in_features=1500, out_features=90, bias=True)\n",
       "    (6): LogSoftmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_im(im_train,cap_train,y_train, batch_size=64, epochs=81, model=im_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699ac51b",
   "metadata": {},
   "source": [
    "Around 50% of the images categories are properly predicted (with 90 categories, this looks pretty good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e875d9f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gusmoreyo@GU.GU.SE/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 62.133975982666016.\n",
      "Total loss in epoch 1 is 49.22002410888672.\n",
      "Total loss in epoch 2 is 47.6337890625.\n",
      "Total loss in epoch 3 is 47.726566314697266.\n",
      "Total loss in epoch 4 is 46.587989807128906.\n",
      "val_loss=7.121696472167969\n",
      "train_acc=0.09624999761581421\n",
      "val_acc=0.019999999552965164\n",
      "Total loss in epoch 5 is 43.204933166503906.\n",
      "Total loss in epoch 6 is 40.58451843261719.\n",
      "Total loss in epoch 7 is 38.48310852050781.\n",
      "Total loss in epoch 8 is 36.5279655456543.\n",
      "Total loss in epoch 9 is 35.390750885009766.\n",
      "val_loss=6.096098899841309\n",
      "train_acc=0.23624999821186066\n",
      "val_acc=0.2199999988079071\n",
      "Total loss in epoch 10 is 33.865760803222656.\n",
      "Total loss in epoch 11 is 31.362751007080078.\n",
      "Total loss in epoch 12 is 29.669170379638672.\n",
      "Total loss in epoch 13 is 30.313520431518555.\n",
      "Total loss in epoch 14 is 35.79331588745117.\n",
      "val_loss=5.643027305603027\n",
      "train_acc=0.3075000047683716\n",
      "val_acc=0.25\n",
      "Total loss in epoch 15 is 30.449983596801758.\n",
      "Total loss in epoch 16 is 29.777902603149414.\n",
      "Total loss in epoch 17 is 28.058124542236328.\n",
      "Total loss in epoch 18 is 32.054290771484375.\n",
      "Total loss in epoch 19 is 30.413022994995117.\n",
      "val_loss=6.137280464172363\n",
      "train_acc=0.3449999988079071\n",
      "val_acc=0.29999998211860657\n",
      "Total loss in epoch 20 is 29.37419319152832.\n",
      "Total loss in epoch 21 is 29.412099838256836.\n",
      "Total loss in epoch 22 is 26.431142807006836.\n",
      "Total loss in epoch 23 is 25.694929122924805.\n",
      "Total loss in epoch 24 is 24.521535873413086.\n",
      "val_loss=6.098479747772217\n",
      "train_acc=0.4424999952316284\n",
      "val_acc=0.3700000047683716\n",
      "Total loss in epoch 25 is 26.95949935913086.\n",
      "Total loss in epoch 26 is 25.148317337036133.\n",
      "Total loss in epoch 27 is 24.832733154296875.\n",
      "Total loss in epoch 28 is 26.158918380737305.\n",
      "Total loss in epoch 29 is 23.051816940307617.\n",
      "val_loss=6.484609603881836\n",
      "train_acc=0.5037499666213989\n",
      "val_acc=0.3799999952316284\n",
      "Total loss in epoch 30 is 24.07505989074707.\n",
      "Total loss in epoch 31 is 23.451332092285156.\n",
      "Total loss in epoch 32 is 24.270299911499023.\n",
      "Total loss in epoch 33 is 22.86560821533203.\n",
      "Total loss in epoch 34 is 23.835742950439453.\n",
      "val_loss=8.218925476074219\n",
      "train_acc=0.512499988079071\n",
      "val_acc=0.3400000035762787\n",
      "Total loss in epoch 35 is 33.282615661621094.\n",
      "Total loss in epoch 36 is 29.51024055480957.\n",
      "Total loss in epoch 37 is 23.432939529418945.\n",
      "Total loss in epoch 38 is 24.461557388305664.\n",
      "Total loss in epoch 39 is 22.83469009399414.\n",
      "val_loss=10.425302505493164\n",
      "train_acc=0.5475000143051147\n",
      "val_acc=0.35999998450279236\n",
      "Total loss in epoch 40 is 27.871835708618164.\n",
      "Total loss in epoch 41 is 24.037948608398438.\n",
      "Total loss in epoch 42 is 20.99471664428711.\n",
      "Total loss in epoch 43 is 17.526721954345703.\n",
      "Total loss in epoch 44 is 15.834355354309082.\n",
      "val_loss=8.202706336975098\n",
      "train_acc=0.6712499856948853\n",
      "val_acc=0.4899999797344208\n",
      "Total loss in epoch 45 is 14.166815757751465.\n",
      "Total loss in epoch 46 is 12.53821086883545.\n",
      "Total loss in epoch 47 is 13.302279472351074.\n",
      "Total loss in epoch 48 is 14.090818405151367.\n",
      "Total loss in epoch 49 is 13.72024154663086.\n",
      "val_loss=8.799781799316406\n",
      "train_acc=0.7262499928474426\n",
      "val_acc=0.550000011920929\n",
      "Total loss in epoch 50 is 13.738154411315918.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Caption_classifier(\n",
       "  (lstm): LSTM(100, 100, batch_first=True)\n",
       "  (layers4): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=3000, bias=True)\n",
       "    (1): Dropout(p=0.4, inplace=False)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=3000, out_features=1500, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Linear(in_features=1500, out_features=90, bias=True)\n",
       "    (6): LogSoftmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cap(im_train,cap_train,y_train,im_val,cap_val,y_val, batch_size=64, epochs=51,  model=cap_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4528da93",
   "metadata": {},
   "source": [
    "55% accuracy on the validation set. The LSTM part performs in the same range as the image classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebb762b",
   "metadata": {},
   "source": [
    "As the caption classification task seems simple in comparaison of the image classification, we look for simple wayd to improve on it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254350ba",
   "metadata": {},
   "source": [
    "First, we just add a second LSTM layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "310a73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Caption_classifier2(nn.Module):\n",
    "    def __init__(self, hidden_size, LSTM_out_size=500, height=100, width=100,device=device):\n",
    "        super(Caption_classifier2, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device =device\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.LSTM_out_size = LSTM_out_size\n",
    "        \n",
    "        \n",
    "        \n",
    "                \n",
    "        self.lstm = nn.LSTM(100, LSTM_out_size, batch_first=True, num_layers=2)\n",
    "        \n",
    "        self.layers4 = nn.Sequential(                               #3 dense layers to classify the output\n",
    "            nn.Linear(self.LSTM_out_size, hidden_size),  \n",
    "            nn.Dropout(0.4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, int(hidden_size/2)),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(int(hidden_size/2), 90),\n",
    "            nn.LogSoftmax()\n",
    "        )\n",
    "        \n",
    "    def forward(self, batch):            #batch is a tupple \n",
    "        batch_size = batch.size()[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "        h_0 = Variable(torch.zeros(2, batch_size, self.LSTM_out_size)).to(self.device)\n",
    "        c_0 = Variable(torch.zeros(2, batch_size, self.LSTM_out_size)).to(self.device)\n",
    "\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(batch, (h_0, c_0))\n",
    "        out =final_hidden_state[-1]        \n",
    "       \n",
    "        return self.layers4(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c9148e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_class2 = Caption_classifier2(3000, im_train.shape[1], im_train.shape[2]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2f4e988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 67.20703125.\n",
      "Total loss in epoch 1 is 50.27626037597656.\n",
      "Total loss in epoch 2 is 48.12720489501953.\n",
      "Total loss in epoch 3 is 47.57423400878906.\n",
      "Total loss in epoch 4 is 47.16326904296875.\n",
      "val_loss=7.566479682922363\n",
      "train_acc=0.08249999582767487\n",
      "val_acc=0.07000000029802322\n",
      "Total loss in epoch 5 is 46.913368225097656.\n",
      "Total loss in epoch 6 is 46.72233581542969.\n",
      "Total loss in epoch 7 is 46.628318786621094.\n",
      "Total loss in epoch 8 is 46.90315628051758.\n",
      "Total loss in epoch 9 is 46.57677459716797.\n",
      "val_loss=7.606777191162109\n",
      "train_acc=0.07374999672174454\n",
      "val_acc=0.07000000029802322\n",
      "Total loss in epoch 10 is 46.74083709716797.\n",
      "Total loss in epoch 11 is 44.421390533447266.\n",
      "Total loss in epoch 12 is 41.11968231201172.\n",
      "Total loss in epoch 13 is 40.24326705932617.\n",
      "Total loss in epoch 14 is 39.617313385009766.\n",
      "val_loss=6.568538665771484\n",
      "train_acc=0.17249999940395355\n",
      "val_acc=0.14000000059604645\n",
      "Total loss in epoch 15 is 36.44403076171875.\n",
      "Total loss in epoch 16 is 35.822509765625.\n",
      "Total loss in epoch 17 is 32.443397521972656.\n",
      "Total loss in epoch 18 is 32.67518615722656.\n",
      "Total loss in epoch 19 is 32.4571533203125.\n",
      "val_loss=5.7434492111206055\n",
      "train_acc=0.32249999046325684\n",
      "val_acc=0.23999999463558197\n",
      "Total loss in epoch 20 is 31.071754455566406.\n",
      "Total loss in epoch 21 is 29.337610244750977.\n",
      "Total loss in epoch 22 is 27.393295288085938.\n",
      "Total loss in epoch 23 is 27.406131744384766.\n",
      "Total loss in epoch 24 is 24.255828857421875.\n",
      "val_loss=5.355259895324707\n",
      "train_acc=0.45124998688697815\n",
      "val_acc=0.35999998450279236\n",
      "Total loss in epoch 25 is 24.334138870239258.\n",
      "Total loss in epoch 26 is 23.45113182067871.\n",
      "Total loss in epoch 27 is 21.79274559020996.\n",
      "Total loss in epoch 28 is 21.534313201904297.\n",
      "Total loss in epoch 29 is 20.312740325927734.\n",
      "val_loss=5.376606464385986\n",
      "train_acc=0.5224999785423279\n",
      "val_acc=0.429999977350235\n",
      "Total loss in epoch 30 is 20.945106506347656.\n",
      "Total loss in epoch 31 is 20.284460067749023.\n",
      "Total loss in epoch 32 is 18.524456024169922.\n",
      "Total loss in epoch 33 is 20.58173179626465.\n",
      "Total loss in epoch 34 is 20.142555236816406.\n",
      "val_loss=4.88364839553833\n",
      "train_acc=0.5174999833106995\n",
      "val_acc=0.550000011920929\n",
      "Total loss in epoch 35 is 19.016475677490234.\n",
      "Total loss in epoch 36 is 18.41840171813965.\n",
      "Total loss in epoch 37 is 18.787063598632812.\n",
      "Total loss in epoch 38 is 15.777584075927734.\n",
      "Total loss in epoch 39 is 14.19224739074707.\n",
      "val_loss=6.74547004699707\n",
      "train_acc=0.6474999785423279\n",
      "val_acc=0.44999998807907104\n",
      "Total loss in epoch 40 is 14.482041358947754.\n",
      "Total loss in epoch 41 is 14.370163917541504.\n",
      "Total loss in epoch 42 is 13.270631790161133.\n",
      "Total loss in epoch 43 is 14.057809829711914.\n",
      "Total loss in epoch 44 is 15.839176177978516.\n",
      "val_loss=7.401457786560059\n",
      "train_acc=0.7137500047683716\n",
      "val_acc=0.5899999737739563\n",
      "Total loss in epoch 45 is 16.113862991333008.\n",
      "Total loss in epoch 46 is 14.06799602508545.\n",
      "Total loss in epoch 47 is 15.48752498626709.\n",
      "Total loss in epoch 48 is 14.310968399047852.\n",
      "Total loss in epoch 49 is 13.171345710754395.\n",
      "val_loss=9.040746688842773\n",
      "train_acc=0.6924999952316284\n",
      "val_acc=0.5199999809265137\n",
      "Total loss in epoch 50 is 13.627304077148438.\n",
      "Total loss in epoch 51 is 10.371889114379883.\n",
      "Total loss in epoch 52 is 10.486520767211914.\n",
      "Total loss in epoch 53 is 14.041773796081543.\n",
      "Total loss in epoch 54 is 11.647502899169922.\n",
      "val_loss=6.201947212219238\n",
      "train_acc=0.7537499666213989\n",
      "val_acc=0.7199999690055847\n",
      "Total loss in epoch 55 is 8.088216781616211.\n",
      "Total loss in epoch 56 is 8.591436386108398.\n",
      "Total loss in epoch 57 is 8.819942474365234.\n",
      "Total loss in epoch 58 is 8.899260520935059.\n",
      "Total loss in epoch 59 is 9.213634490966797.\n",
      "val_loss=8.534759521484375\n",
      "train_acc=0.8187499642372131\n",
      "val_acc=0.6800000071525574\n",
      "Total loss in epoch 60 is 7.737926959991455.\n",
      "Total loss in epoch 61 is 6.526646614074707.\n",
      "Total loss in epoch 62 is 7.2875847816467285.\n",
      "Total loss in epoch 63 is 7.74466609954834.\n",
      "Total loss in epoch 64 is 6.844936847686768.\n",
      "val_loss=9.028336524963379\n",
      "train_acc=0.8862499594688416\n",
      "val_acc=0.6699999570846558\n",
      "Total loss in epoch 65 is 9.333209991455078.\n",
      "Total loss in epoch 66 is 10.677631378173828.\n",
      "Total loss in epoch 67 is 12.47033977508545.\n",
      "Total loss in epoch 68 is 19.03447151184082.\n",
      "Total loss in epoch 69 is 20.968948364257812.\n",
      "val_loss=13.433974266052246\n",
      "train_acc=0.7799999713897705\n",
      "val_acc=0.5699999928474426\n",
      "Total loss in epoch 70 is 16.084156036376953.\n",
      "Total loss in epoch 71 is 14.453357696533203.\n",
      "Total loss in epoch 72 is 14.693378448486328.\n",
      "Total loss in epoch 73 is 16.64691925048828.\n",
      "Total loss in epoch 74 is 15.462355613708496.\n",
      "val_loss=11.906964302062988\n",
      "train_acc=0.8237499594688416\n",
      "val_acc=0.6899999976158142\n",
      "Total loss in epoch 75 is 11.596726417541504.\n",
      "Total loss in epoch 76 is 14.590740203857422.\n",
      "Total loss in epoch 77 is 15.576825141906738.\n",
      "Total loss in epoch 78 is 11.368041038513184.\n",
      "Total loss in epoch 79 is 11.268133163452148.\n",
      "val_loss=15.789196014404297\n",
      "train_acc=0.8787499666213989\n",
      "val_acc=0.6599999666213989\n",
      "Total loss in epoch 80 is 10.506467819213867.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Caption_classifier2(\n",
       "  (lstm): LSTM(100, 100, num_layers=2, batch_first=True)\n",
       "  (layers4): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=3000, bias=True)\n",
       "    (1): Dropout(p=0.4, inplace=False)\n",
       "    (2): Tanh()\n",
       "    (3): Linear(in_features=3000, out_features=1500, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Linear(in_features=1500, out_features=90, bias=True)\n",
       "    (6): LogSoftmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cap(im_train,cap_train,y_train,im_val,cap_val,y_val, batch_size=64, epochs=81,  model=cap_class2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0579b6",
   "metadata": {},
   "source": [
    "2 layers LSTM need ot be trained longer. It improves on the validation accuracy up to near 70%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855b9ee5",
   "metadata": {},
   "source": [
    "So, one meaningful and easy improvement to our main classifier would be to add (at least) one LSTM layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a7fae",
   "metadata": {},
   "source": [
    "Also, as the NLP task is less memory consumming than the image recognition, one simple way to improve would be to train the LSTM layer(s) to classify the category of a caption on all the coco dataset (or at least a substantially bigger subset).\n",
    "But we chose another way...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3445d061",
   "metadata": {},
   "source": [
    "# Part Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b488102",
   "metadata": {},
   "source": [
    "# URN instead of LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f1d488c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class UnitaryRNN(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super().__init__()\n",
    "        self.embedding_size = embedding_size\n",
    "        n = math.ceil(.5+math.sqrt(2*self.embedding_size+.25))   #we need n(n-1)/2 >= embedding_size\n",
    "        self.n = n                                               #in fact it is now implemented in such a way that we need\n",
    "                                                                 #the expression in paranthesis to be an integer\n",
    "        # for creating the upper tringulars\n",
    "        self.ix_mat = torch.zeros(n,n).long()\n",
    "        for i in range(0,n):\n",
    "            for j in range(i+1,n):\n",
    "                self.ix_mat[i,j] = (i* (2*n - i - 3))//2 + j - 1 + 1\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        device = text.device\n",
    "        x = torch.cat([torch.zeros(text.shape[:-1]).to(device).unsqueeze(-1), text], dim=-1)\n",
    "        tri = torch.index_select(x, -1, self.ix_mat.flatten().to(device)).reshape((*text.shape[:-1],self.n,self.n))\n",
    "        tri = tri - tri.transpose(-2, -1)\n",
    "        exp_mat = torch.matrix_exp(tri)\n",
    "\n",
    "        h = torch.zeros(self.n).to(device)\n",
    "        h[0] = 1\n",
    "        for i in range(text.shape[0]):\n",
    "            h = torch.matmul(exp_mat[i], h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "60645611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class URNclassifier(nn.Module):\n",
    "    def __init__(self, embedding_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding_size = embedding_size\n",
    "        n = math.ceil(.5+math.sqrt(2*self.embedding_size+.25))\n",
    "        self.embedding = nn.Embedding(1475,self.embedding_size)  #vocab_size+1\n",
    "        self.urn_layer = UnitaryRNN(self.embedding_size)\n",
    "        self.linear = nn.Linear(n,90)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, sentence):\n",
    "        x = self.embedding(sentence)\n",
    "        x = self.urn_layer(x)\n",
    "        return self.softmax(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ee4031cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = UnitaryRNN(105)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232106ab",
   "metadata": {},
   "source": [
    "As input, we need padded sequences of integers where each integer is the number of the corresponding word in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "acf58eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran_Id=annIds[:10000]                                                   #we reconstruct data_df as captions were replaced by their encoding for the former architectures\n",
    "list_captions_ann=captions.loadAnns(ids=ran_Id)\n",
    "list_captions = [ann['caption'] for ann in list_captions_ann if ann['image_id'] in im_ids]\n",
    "data_df['caption_w']=list_captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "44f8f2c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1474"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "all_w=[]\n",
    "for sentence in list(data_df['caption_w']):\n",
    "    all_w+=nltk.word_tokenize(sentence.lower())\n",
    "len(all_w)\n",
    "len(set(all_w))                #get the number of unique words\n",
    "                                #this number +1 will be the vocab size for the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9319ac41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A small clock hanging up with some lamps.',\n",
       " 'a button on a black keyboard on a desk',\n",
       " 'A toilet with the seat up in a run down paneled bathroom.',\n",
       " 'a zebra and some billy goats grazing in the open field.',\n",
       " 'A large tall tower with a clock on the top.',\n",
       " \"Crude shoes have been tied to the elephant's feet.\",\n",
       " 'an overhead view of a toilet with something inside',\n",
       " 'An elephant walks in a dry field area',\n",
       " 'A broken wood fence seen through a window in a derelict building.',\n",
       " 'The almost all white cat is sleeping on a shoe. ',\n",
       " 'An old tusked elephant walking on a dirt road',\n",
       " 'Two black bears in the woods playing near the trees.',\n",
       " 'A very small bathroom with blue walls and a white toilet.',\n",
       " 'Banana connected to plastic device shown producing electricity.',\n",
       " 'A pizza before it was cook on an oven tray.',\n",
       " 'A bathroom toilet with a paper dispenser and bowl brush.',\n",
       " 'a very small bathroom with two toilet paper holders',\n",
       " 'A large long train on a steel track.',\n",
       " 'A railroad train traveling down the train tracks',\n",
       " 'An individual is in the open view in the picture. \\n',\n",
       " 'A bus pulls up to a sidewalk and bus stop.',\n",
       " 'A teddy bear hanging on a fence by a string of fabric around its neck.',\n",
       " 'A train is going over a mountain top.',\n",
       " 'A sandwich on a plate with pulled pork and barbeque with cilantro leaves on top. ',\n",
       " 'an airplane flies thorough an overcast sky ',\n",
       " 'A grey elephant standing in the middle of a tree covered field.',\n",
       " 'A tray with two different tools sitting on it.',\n",
       " 'A stationary passenger train shows a lot of graffiti.',\n",
       " 'A dog peeks its head out of an open window.  ',\n",
       " 'A FedEx airplane flies in the sky with mountains behind.',\n",
       " 'A panda bear tilts its head to the side',\n",
       " 'some plants two mirrors and silver handle bars',\n",
       " 'A large airplane is flying low across the runway.',\n",
       " 'The stop sign is across the street from a large house.',\n",
       " 'Flowers sit in a vase with a statuette next to them. ',\n",
       " 'A hand held mirror hanging on the wall.',\n",
       " 'A single engine prop airplane flying in the sky on a cloudy day.',\n",
       " 'an image of flowers in a vase on a window sill',\n",
       " 'some old train cars and some weeds one car red the other blue',\n",
       " 'A Woman hanging on tight to the rope while water skiing.',\n",
       " 'A big elephant is taking a drink on a nice day.',\n",
       " 'A yellow building has a red door, and a brick sidewalk alongside of it, with a silver fire hydrant. ',\n",
       " 'Polar bear being rolled in dirt near some trees',\n",
       " 'A cow with a tag in its ear looking observantly.',\n",
       " 'A bench sitting next to a tree in the woods .',\n",
       " 'Red white and blue city bus on urban lot.',\n",
       " 'An elephant stands in grass in front of trees and shrubs. ',\n",
       " 'A large brown bear with his mouth open sitting on the grass.',\n",
       " 'a solitary zebra standing in the shade beneath a tree',\n",
       " 'An old house with a clock and statues ',\n",
       " 'A big building with a clock tower on it.',\n",
       " 'The golden-maned horse in his pen is looking over the gate.',\n",
       " 'The under belly of a modern jet airliner in the sky',\n",
       " 'a cat sleeps on a red carpet with tennis shoes',\n",
       " 'an open bathroom door reveals a toilet and tub',\n",
       " 'A small boat near another floating vessel in the ocean.',\n",
       " 'Some garden picked vegetables are in a large pile.',\n",
       " 'An empty park bench over looking a beautiful mountain landscape.',\n",
       " 'Two dolls with crazy hair and interesting clothes.',\n",
       " 'A vase with an oriental design is on a pedestal. ',\n",
       " 'A picture of a very big plane on the ground.',\n",
       " \"A lone brown horse has grass in it's mouth.\",\n",
       " 'a wooden bench standing in front of a bunch of trees',\n",
       " 'A mass of trees in the woods in fall',\n",
       " 'A fire hydrant between two trees by a bubbling river',\n",
       " 'A fridge that is silver and in a kitchen.',\n",
       " 'An old train car on display at a museum. ',\n",
       " 'A train car is decorated with grafiti, as is a nearby utility box.',\n",
       " 'An old, run down city bus sits parked, with rust.',\n",
       " 'A small hummingbird perches on a thin branch.',\n",
       " 'A pizza topped with weird slices of meat.',\n",
       " 'A toilet sits with its lid open amid a tile floor and tiled wall.',\n",
       " 'This is a view of the clouds from inside of an airplane.',\n",
       " 'A motorcycle is stopped on a dirt road.',\n",
       " 'A giraffe is looking down at the ground.',\n",
       " 'A small, homemade pizza with some strange vegetables.',\n",
       " 'Wheat bread with deli meat, sauce and sauerkraut. ',\n",
       " 'A cat laying in the entrance of a hotel. ',\n",
       " 'An airport with an airplane that has a red tale',\n",
       " 'A grey and white cat laying on dirt next to a fence.',\n",
       " 'This is a bear walking on a wooden log',\n",
       " 'A worn teddy bear is lying on the ground.',\n",
       " 'A giraffe walking on a plain with a snow capped mountain behind it.',\n",
       " 'A giraffe that is standing in the grass.',\n",
       " 'The airplane has taken off from the airport. ',\n",
       " 'A clock tower out in the middle of nowhere,',\n",
       " 'A large pair of scissors sticking out of the ground.',\n",
       " 'a couple of appliances sit on top of a carpet ',\n",
       " 'Multi colored scissors with a multi colored ribbon.',\n",
       " 'a kayak on the beach very close to a large body of water',\n",
       " 'a truck on a sandy beach on a cloudy day',\n",
       " 'A red painted water pipe on a snow covered sidewalk curb in front of a blue wall.',\n",
       " 'A small train rides the train tracks around forestation. ',\n",
       " 'A bridge over a blue river on a sunny day.',\n",
       " 'an air plane flying thru the air with a sky background',\n",
       " 'A clock tower standing near another tall building.',\n",
       " 'a close up of a small bird on small rocks near a body of water',\n",
       " 'A turtle toy placed next to a large pizza.',\n",
       " 'A microwave oven sitting upon a small green table.',\n",
       " 'a kitchen counter with a microwave and a toaster ',\n",
       " 'A giraffe that measures approximately twelve feet tall.',\n",
       " 'A large modern metallic refrigerator next to a washer and dryer.',\n",
       " 'A wooden bench is shown on a brick walkway.',\n",
       " 'A yellow crop dusting plane flies low over crops.',\n",
       " 'A blue train car sitting on top of train tracks.',\n",
       " 'The rotted out bed of a truck left in the woods.',\n",
       " 'a close up of a skate board on a tree branch',\n",
       " 'A donut on top of a paper sitting on a table.',\n",
       " 'Sign indicating motorists to stop at intersection with trees lining sides.',\n",
       " \"A car's passenger side mirror reflects the image of a long freight train.\",\n",
       " 'A jet is sitting on the cold and oct runway.',\n",
       " 'a large house with a street sign on the corner of the street',\n",
       " 'a large air plane flying thru the air',\n",
       " 'a boat docked next to a pier outside of a house.',\n",
       " 'A brown and black horse stands in a field wearing a harness',\n",
       " 'A white and red train parked near a bridge.',\n",
       " 'Small black and white bird sitting on a thin branch.',\n",
       " 'A very lush green tree with bunches of green bananas.',\n",
       " 'a wooden object on top of a metal grail door',\n",
       " 'A cream colored teddy bear sitting on a tree branch\\n',\n",
       " 'Giraffe in its natural habitat snacking on a tree',\n",
       " \"A white pickup truck with two large atv's sitting on it's flatbed.\",\n",
       " 'A large gray airplane flies through the sky.',\n",
       " 'a plane flying under a mostly cloudy sky ',\n",
       " 'A cloud covered mountain sitting above a forest.',\n",
       " 'The red and white plane is a huge traveling unit.',\n",
       " 'A train passing down a station, in the middle of the day.',\n",
       " 'Person combing their hair with a blue comb with a picture on it. ',\n",
       " 'The flowers feature several favorite  pastel colors.',\n",
       " 'A wooden bench outside in front of some plants.',\n",
       " 'A bed with a colorful blanket sitting under a picture.',\n",
       " 'A man is staring out of a boat window.',\n",
       " 'A plane that is flying in a clear blue sky.',\n",
       " 'A bird that has its wings stretched out on a beach. ',\n",
       " 'A train parked next to a building with people looking on.',\n",
       " 'An elephant standing in tall grass surrounded by trees and shrubs.',\n",
       " 'a close up of an animal behind a fence with tall grass',\n",
       " 'A cat in a car seat in the back of a car.',\n",
       " 'A giraffe standing in front of some trees.',\n",
       " 'A giraffe standing next to a tree with no leaves.',\n",
       " 'A sink area in the bathroom with a blue door.',\n",
       " 'A wooden bench beneath a tree at a scenic lookout point.',\n",
       " 'A mostly empty sky with a small airplane visible.',\n",
       " 'An old red train caboose sits idle off the tracks as a monument.',\n",
       " 'A sheep and its baby are in the large field',\n",
       " 'A work truck is parked outside of a large garage.',\n",
       " 'Two red flowers set in a green vase.',\n",
       " 'Park with trees, green grass and a white sitting bench.',\n",
       " 'A small biplane flying through a bright blue sky.',\n",
       " 'A room with refrigerator and pictures on the walls. ',\n",
       " 'A gray and white cat happily hugging a shoe.',\n",
       " 'The tip of an airplane wing and a large amount of land from the air.',\n",
       " 'A small plane flying through a gray cloudy sky.',\n",
       " 'A stoplight turned red at twilight in front of buildings.',\n",
       " 'a motorbike standing in a two sided beautiful wall',\n",
       " 'a close up of a stuffed animal leaning against a wall',\n",
       " 'A brown bear sitting on a bunch of fallen logs',\n",
       " 'A teddy bear looking down into a small trapdoor in an old floor',\n",
       " 'A red bus driving down a road next to a store front.',\n",
       " 'A  shadow of a person flying a kite on a sandy beach.',\n",
       " 'A small airliner proceeds down the runway on takeoff.',\n",
       " 'A large bird perched on top of a tree with lots of leaves.',\n",
       " 'Large bird of prey dips into a body of water.',\n",
       " 'A cow standing by the feed bin in a fenced in area.',\n",
       " 'An open door on a large train cart',\n",
       " 'There is a pan with colored food in it',\n",
       " 'Bathroom sink and cabinet with mirror and lights',\n",
       " 'Two loafs of bread sitting on a counter behind a window.',\n",
       " 'A skier holding two ski poles while standing on snow covered ground.',\n",
       " 'A striped zebra eats some of the bright green grass.',\n",
       " 'A white horse grazes in a field near a forest. ',\n",
       " 'a bird stands on a window child blocker',\n",
       " 'A red fire hydrant in a deep brick alcove.',\n",
       " 'A jetliner wing flying though a blue sky over the clouds.',\n",
       " 'A plane is flying in the air against a blue sky.',\n",
       " 'A stop sign sits near a field and a mountain.',\n",
       " 'Union Pacific train engine pulling railroad cars along the train tracks.',\n",
       " 'A bench sitting next to a wet sidewalk.',\n",
       " 'a close up of a plane engine attached to a wing',\n",
       " 'Bottom view of an airliner flying directly over head.',\n",
       " 'A swing hanging by chains in the woods. ',\n",
       " 'A giraffe in its own natural habitat during the day.',\n",
       " 'A grey striped tie is on the table next to a pen.',\n",
       " 'A dog is staring intently out the window.',\n",
       " 'A red stop sign sitting under a cloudy sky.',\n",
       " 'A sheep standing in a shaded area in a clearing in the woods.',\n",
       " 'An animal that is out by some water.',\n",
       " 'A bunch of apples hanging from a green tree.',\n",
       " 'A tall giraffe standing next to a tree in a forest.',\n",
       " 'a boy is performing a skateboard trick in the air',\n",
       " 'A yellow sign warns of a plank surface in front of a large gray building.',\n",
       " 'A giraffe is standing outside in a field.',\n",
       " 'A traffic light reads red near the Main Street sign. ',\n",
       " 'Green and yellow bananas growing on a banana plant. ',\n",
       " 'A blacn and white cow sticking its head over a fence.',\n",
       " 'An computer map image of driving directions using GPS.',\n",
       " 'a black mirror a sink and a small shelf',\n",
       " \"A train with it's doors open sitting next to a platform.\",\n",
       " 'A black and white image of a pair of scissors cutting into some paper sitting on an object. ',\n",
       " 'A close up of a plane passing overhead.',\n",
       " 'A large open bathroom with tile floors and shower',\n",
       " 'Wooden crates sit in a parking lot next to a train.',\n",
       " 'A stop sign overgrown with vegetation near a road.',\n",
       " 'a black-faced sheep standing alone on the side of a grassy hill',\n",
       " 'a woman brushing her long red hair ',\n",
       " 'A small bedroom contains a twin bed and small nightstand. ',\n",
       " 'A cat laying on top of a floor next to a  white wall.',\n",
       " 'Round lit street signs in the middle of a city. ',\n",
       " 'A cat sitting in a room amongst several pair of shoes. ',\n",
       " 'A grey-scale photograph of a rear bicycle tire lifted for repair. ',\n",
       " 'A train is passing across a suspension bridge',\n",
       " 'Close up of teddy bear lying down on blanket with wall',\n",
       " 'A \"stop ahead\" sign silhouetted against a washed out sky.',\n",
       " 'A large bathroom mirror over a bathroom sink.',\n",
       " 'a giraffe is standing on some grass and some trees',\n",
       " 'A bird stands on a beach with its wings extended.',\n",
       " 'A bench that is covered and standing in snow.',\n",
       " 'A NARROW HALLWAY WITH A TOILET IN THE BATHROOM',\n",
       " 'Stuffed teddy bear wearing shirt displayed in dimly lit photo.',\n",
       " 'A red stop sign topped with a green street sign.',\n",
       " 'wooden car beside a tree on a green hill',\n",
       " 'the inside of church with a big clock',\n",
       " 'a semi truck with the in n out logo on the side of it ',\n",
       " 'A small cow standing next to a metal fence.',\n",
       " 'A yellow parking meter is shown on a street.',\n",
       " 'A paper plate with fruit and a jar of orange marmalade ',\n",
       " 'A pile of toilet paper sitting on top of a toilet.',\n",
       " 'A silver train car waiting in a train station.',\n",
       " 'A cat napping inside of a large planter.',\n",
       " 'A red and white motorcycle parked on the pavement ',\n",
       " 'A giraffe in front of a tree in a field.',\n",
       " 'A back side view of a zebra looking back on a field.',\n",
       " 'a clock tower with a white clock some water and buildings',\n",
       " 'A picture of a zebra in some green grass.',\n",
       " 'a cow sitting on top of a hill eating in the rocks',\n",
       " 'A black bear is sitting on some rocks ',\n",
       " 'A clear green vase filled with flowers and water.',\n",
       " 'A kitchen with a window, pot and refrigerator. ',\n",
       " 'A sheep grazing on grass in a field. ',\n",
       " 'A train engine with many carts pulled into a station.',\n",
       " 'The airplane flies low to the ground during sunset.',\n",
       " 'A fire hydrant is standing by a city street.',\n",
       " 'A motorcycle parked next to squares of colored hanging fabric.',\n",
       " 'a giraffe near many trees and bushes ',\n",
       " 'a pizza in a pizza box on a table ',\n",
       " 'a fire hydrant with a hose inside of it ',\n",
       " 'An old train by a shack on a river.',\n",
       " 'A bathroom is equipped with double rolls of toilet paper.',\n",
       " 'a tv set sitting in the sand next to the water',\n",
       " 'Fairy boat at the dock in front of some buildings.',\n",
       " 'A black fire hydrant sits with an orange traffic cone.',\n",
       " 'A blue and silver plane flying through a cloudless sky. ',\n",
       " 'A giraffe in a field looking behind back.',\n",
       " 'A train traveling over a bridge that spans the width of a river.',\n",
       " 'A calling bird is pictured on a rock near the ocean.',\n",
       " 'A building with a clock on the front of it. ',\n",
       " 'A brown bear investigating something on top of a rock.',\n",
       " 'A skateboard lying upside down on a beach.',\n",
       " 'Inside of a bathroom with a toilet and trash can.',\n",
       " 'A pigeon is standing and eating in the street.',\n",
       " 'The bus door are opened up a crack to see 42 Street. ',\n",
       " 'a giraffe standing in a field with trees in the background ',\n",
       " 'an old image of a red seal air plane ',\n",
       " 'an image of an elephant carrying cargo on its back\\n',\n",
       " 'A bathroom with a large black tile shower.',\n",
       " 'A green toilet lying in a wooded field. ',\n",
       " 'an elephant standing by some water so it can drink some ',\n",
       " 'There is a clock hanging form the ceiling with roman numerals',\n",
       " 'An elephant and a rhinoceros share a field with a pond.',\n",
       " 'A suitcase full of clothes sitting on the floor.',\n",
       " 'A cluster of bananas are hanging from a tree.',\n",
       " 'A cake shaped as a train of some sort.',\n",
       " 'This Asian meal of meat and vegetables can be eaten chopsticks.',\n",
       " 'an orange and white cat and a red towel ',\n",
       " \"A refrigerator freezer with it's door open in a kitchen.\",\n",
       " 'A scarecrow without a head and a crow standing on his arm.',\n",
       " 'The kitchen has a small refrigerator near the door. ',\n",
       " 'A U.S. Air Force plane on a runway. ',\n",
       " 'The tower of the building has a clock displayed on it.',\n",
       " 'a white toilet and bath tub in a small bathroom',\n",
       " 'a stop sign with some graffit on it',\n",
       " 'A bird with bright yellow and orange feathers on a perch.',\n",
       " 'A warning sign in the middle of water with a fire hydrant in the foreground.',\n",
       " 'A large piece of broccoli sitting inside of a leafy plant.',\n",
       " 'A black and white zebra walking in the grass. ',\n",
       " 'A bird sitting on a bare thorn branch.',\n",
       " 'A young cow is on a chain in a pasture.',\n",
       " 'a yellow train that is going under a bridge',\n",
       " 'Reflections of light streaming thru a building window at night.',\n",
       " 'A store freezer is shown with food inside.',\n",
       " 'A large clock hanging off the side of a yellow building.',\n",
       " 'A fire hydrant with chipped paint in a field. ',\n",
       " 'A gray remote control sitting on a desk',\n",
       " 'A side view of the cab and part of the trailer of a tractor trailer truck',\n",
       " 'a dig is standing behind a red window',\n",
       " 'A pizza pie with vegetables of some sort on it.',\n",
       " 'The town has a small church in it. ',\n",
       " 'An empty refrigerator is tossed outside a building.',\n",
       " 'a cow stands in front of tall stacks of hay on a grassy field',\n",
       " 'A white clock tower is a nice day.',\n",
       " 'A giraffe sticking his tongue out with trees nearby',\n",
       " 'A suitcase sitting next to a brick wall.',\n",
       " 'A lady cross country skiing in a competition.',\n",
       " 'This city has had a very hard winter with snow.',\n",
       " 'Upward view of a building in Hong Kong lit up at night.',\n",
       " 'A bear cub walking in a field of grass.',\n",
       " 'a dusty zebra standing in a dusty field',\n",
       " 'A semi truck is driving down the highway.',\n",
       " 'A cat sitting on a log in the middle of a wood',\n",
       " 'a toilet with the lid closed in between the sink and bathtub',\n",
       " 'A long train traveling down tracks with rusted cars.',\n",
       " 'A brown bear stands among ferns in a forest.',\n",
       " 'a cement slab with a porcelain drain next to a bucket and broom. ',\n",
       " 'A jumbo jet is parked in front of a mountain.',\n",
       " 'A train his highly decorated with a sign that says monkey.',\n",
       " 'A pair of slippers are in front of the electronic toilet. ',\n",
       " 'A kitchen in the process of being remodeled.',\n",
       " 'Stairs that have some fading green paint on them.',\n",
       " 'A building with a clock on the front and a rooftop weathervane on the top',\n",
       " 'Bathroom scene of a toilet next to a used roll of toilet paper.',\n",
       " 'A small bear smelling the ground in front of a tree trunk.',\n",
       " 'A hot dog with sauerkraut and a side of fries.',\n",
       " 'A brown and white cow sitting on grass hill next to trees.',\n",
       " 'A fire hose that is rollled up and connected to a water source.',\n",
       " 'A train traveling along a snow covered country.',\n",
       " 'A sign directs commuters to Track 2 and Track 4 to New York.',\n",
       " 'a large passenger airplane flying over some palm trees',\n",
       " 'The zebra is eating grass in the sun.',\n",
       " 'A pair of train carts making a transfer to a different set of tracks.',\n",
       " 'A broken toilet sitting outside of a motel room.',\n",
       " 'A red fire hydrant on a sidewalk near the street.',\n",
       " 'White stove with two pots on top in kitchen.',\n",
       " 'a steel bridge over the water with a train',\n",
       " 'Three old cast iron bathtubs in a brick room.',\n",
       " 'a pair of scissors sitting on some black mesh fabric',\n",
       " 'A man made replica of a palm tree on a beach.',\n",
       " 'A motorcycle kickstand down on a parking lot',\n",
       " 'A train engine pouring out steam into the air next to a hillside forest.',\n",
       " 'Fake flowers in a golden heart shaped vase on a window sill',\n",
       " 'A large zebra eating grass from a field.',\n",
       " 'A large clock tower on the side of a building.',\n",
       " 'a yellow fire hydrant near many bushes ',\n",
       " 'A tug boat sits in the water near farm land. ',\n",
       " 'An elephant standing around in he middle of a grassy area.',\n",
       " 'This is a Stop sign and no right turn sign pictured at night.',\n",
       " 'A very large elephant standing alone in some brush.',\n",
       " 'surfboarder falling into a wave near the shore of the beach',\n",
       " 'An old picture of a red fire truck with snow on the ground.',\n",
       " 'a dog standing in a trail with woods in the background',\n",
       " 'A bathroom with a sink, mirror and an electric hand dryer.',\n",
       " 'A clock hanging from a glass ceiling near a ramp. ',\n",
       " 'A shower curtain drawn over a bath tub by a toilet.',\n",
       " 'An assortment of food left on a white plate',\n",
       " 'A metal toilet and some tissue in a bathroom.',\n",
       " 'A dark colored bear walking on all fours in a tall grass field.',\n",
       " 'A plane rests on the tarmac at the far end of a field and some buildings.',\n",
       " 'A train traveling past a graffiti covered wall.',\n",
       " 'There is a dirty toilet that is in the facility',\n",
       " 'A brown horse grazing in a grassy field.',\n",
       " 'A jet taking off from an airport runway.',\n",
       " 'There is a green garden with pink, white, yellow, and red flowers in it.',\n",
       " 'a weird sign does it mean the men at work are dead',\n",
       " 'A tower with a clock extends into the sky. ',\n",
       " 'A bird is perched on top of a building.',\n",
       " 'a silver trailer with some black red and purple graffiti on it',\n",
       " 'A plane that is flying in the air.',\n",
       " 'an image of a brown bird perched on a tree branch',\n",
       " 'A dark wall clock with light face on white wall.',\n",
       " 'A white toilet and a tub in a room.',\n",
       " 'A pile of oranges is set on a plate.',\n",
       " 'Two small sandwiches sitting next to a salad. ',\n",
       " 'A TV sitting on top of a stone covered beach.',\n",
       " 'A bathroom toilet with handles, toilet paper and trash cans.',\n",
       " 'A single, small boat on a placid lake',\n",
       " 'Black and white photograph looking up at a stone clock tower',\n",
       " 'A truck is parked near some trees in a grassy area.',\n",
       " 'A zebra walking across a grassy open field.',\n",
       " 'A large gray elephant standing in a desert.',\n",
       " 'A zebra who is standing in a field.',\n",
       " 'A light with multiple bulbs is on a tall post.',\n",
       " 'A large white bird walking across a pond.',\n",
       " 'a yellow sign on an empty open road',\n",
       " 'A giraffe that is standing in the grass.',\n",
       " 'A young Giraffe enjoying the sun on the grass.',\n",
       " 'A giraffe standing next to a field filled with trees.',\n",
       " 'A small pizza has a curly topping on it.',\n",
       " 'A single cow in a field with a mountain in the background. ',\n",
       " 'A sandwich with ham and greens on a plate.',\n",
       " 'A stop sign with an \"eating animals\" sticker on it.',\n",
       " \"A boat sitting on someone's lawn near an abandoned brick house. \",\n",
       " 'An old glass vase containing flowers on a glass table.',\n",
       " 'A building with the focus at the clock tower of the building.',\n",
       " 'A very long counter with a sink and mirror in a bathroom.',\n",
       " 'A single giraffe feeding on some thin tree branches.',\n",
       " ' A fish eye look at a recently fixed up bath.',\n",
       " 'A cat lying on a mat with shoes ',\n",
       " 'An old fashioned train moves along the tracks .',\n",
       " 'A large panda bear sitting on top of a wooden post.',\n",
       " 'A suitcase sitting on the ground near another case.',\n",
       " 'Large bull laying out on the beach away from the water',\n",
       " 'A plane enters the intersection of an airport landing.',\n",
       " 'A yellow nad black train on a railroad track',\n",
       " 'A clean bathroom with white and green tiles.',\n",
       " 'A little kitten standing next to a white shoe.',\n",
       " 'a old train sitting parked on some tracks',\n",
       " 'A red stop sign sitting on the side of a road.',\n",
       " 'The water the boat is in is reflecting the sun.',\n",
       " 'A water skier holding a tow rope behind a boat.',\n",
       " 'A sheep in a grassy area next to a tree.',\n",
       " 'A TRAIN IS ON THE TRAIN TRACKS ',\n",
       " 'The clock is on display on the shelf in the room. ',\n",
       " 'Red caboose part of train, near rural station with water tower,  heavy over cast skies.  ',\n",
       " 'A train moving along a track near a field.',\n",
       " 'A toilet on top of a platform in a residential home.',\n",
       " 'A railroad track with a unique look to the picture.',\n",
       " 'A doorway leading into a delapitated wall in a room.',\n",
       " 'A clock on the street side shows the time as 5:00',\n",
       " 'A white-themed bathroom and a bathtub with tiled walls.',\n",
       " 'A bear lying down with his head on a rock.',\n",
       " 'Some images of some cute assorted animals eating.',\n",
       " 'a maroon train traveling down a train track next to trees',\n",
       " 'A fire hydrant that is by a street.',\n",
       " 'A Frisco clock that currently reads 2:25. ',\n",
       " 'A giraffe eating leaves from a bush in a field.',\n",
       " 'A large silver plane flying through the air.',\n",
       " 'A horse in a penn standing on a farm as the sun sets.',\n",
       " 'Flower vase shaped like three attached, white guns.',\n",
       " 'A pinj and white flower in a small, blue and white vase.',\n",
       " 'Traffic light in front of building with small balconies on corner windows',\n",
       " 'A stone park with lots of green plants on it.',\n",
       " 'A vase on a window sill with cards next to it',\n",
       " 'A zebra leaning over to eat some hay in a field.',\n",
       " 'Two large pillows sit on a bed as sunlight seeps into the room. ',\n",
       " 'A giraffe walks a path near some palm trees',\n",
       " 'A fluffly cat lays down in the drawer of a dresser.',\n",
       " 'Close up view of a large sandwich and pickle on a plate.',\n",
       " 'a horse in a saddle next to a house',\n",
       " 'there is a small hot plea that is inside of the fridge',\n",
       " 'a plate with a bunch of food on it ',\n",
       " 'a pole with street signs and a green light ',\n",
       " 'Blue and white passenger train sitting in a storage yard. ',\n",
       " 'A close up of a fire hydrant covered in graffiti.',\n",
       " 'A big taco salad of meat, tomatoes, onions, and pepper.',\n",
       " 'a long train that is on a rail road track',\n",
       " 'a black and blonde dog is laying down',\n",
       " 'A giraffe walking through the grass towards a wall.',\n",
       " 'A giraffe with its eyes peeled open eating grass from the ground.',\n",
       " 'An overripe banana and a piece of bread or biscuit sit on top of a plastic bag.',\n",
       " 'A red train traveling past a loading platform.',\n",
       " 'A small dog sleeping on the pillow on a bed.',\n",
       " 'Umbrella discarded in an outdoor public trash can.',\n",
       " 'A black bear stands in the grass alone.',\n",
       " 'a white box with door handles and a traffic meter painted on it',\n",
       " 'A train moving on a track during the day.',\n",
       " 'A pudgy little bird roosts on a twig, surrounded by long leaves.',\n",
       " 'a fire hydrant out in a large open field.',\n",
       " 'A zebra walking outside in an open field.',\n",
       " 'a giraffe eating leaves off of a tree near a building',\n",
       " 'A giraffe lying down outside in a pasture. ',\n",
       " 'Toy train rounding the curve on the tracks.',\n",
       " 'The mural,  a painting of giraffes, is displayed  in the barren woods',\n",
       " 'A blue and white bus is parker by a museum.',\n",
       " 'Various shaped cookies being baked inside an oven.',\n",
       " 'This is an image of an Air Canada plane flying.',\n",
       " 'An airplane in a stationary position for people to examine. ',\n",
       " 'A stop sign that is hanging on a pole.',\n",
       " 'Two toned cake topped with daisies made from icing.',\n",
       " 'White toilet in blue and white bathroom with black bucket.',\n",
       " 'an image of a small pizza on a pan',\n",
       " 'A cat is looking out the window with a chandelier in the background.',\n",
       " 'A hard hat is stored on a shelf under a time clock.',\n",
       " 'A train is pulled up to the train station. ',\n",
       " 'A baby elephant standing next to a tree and a few bushes.',\n",
       " 'A white room with a metal bench and a woven basket beside it.',\n",
       " 'A toilet with a speedometer on top of it',\n",
       " 'A chocolate cake decorated with flowers and long, purple candles sits on a blue plate on the floor.',\n",
       " 'An old rusty car with a headlight missing',\n",
       " 'a colorful little teddy bear sitting in front of a blanket with white stars',\n",
       " 'an image of an old fashioned parking meter',\n",
       " 'A yellow dump truck that is near a building.',\n",
       " 'A large clock towers on top of a building.',\n",
       " 'An unusual bird on the ground getting ready to fly away.',\n",
       " 'A camera with a pair of small scissors and two photos.',\n",
       " 'The side view train carts on top of rail road tracks.',\n",
       " 'a little model boat speeding across the water',\n",
       " 'A giraffe crossing a dirt road, with trees and shrubs in the background.',\n",
       " 'A huge jumbo jet is taking off from a runway.',\n",
       " 'A ram stands alone in grass between large rocks.',\n",
       " 'Train traveling on tracks through city near glass buildings.',\n",
       " 'A window with a table sitting underneath it.',\n",
       " 'A white and red airplane ascends into the sky.',\n",
       " 'A bed with white and red striped blankets and pillow cases.',\n",
       " 'A giraffe crossing a dirt road headed towards grassy brush.',\n",
       " 'A passenger train speeding down the train tracks.',\n",
       " 'A small airplane parked in a metal hanger.',\n",
       " 'A white plate has a dessert and lime on it.',\n",
       " 'A bathroom with a toilet and a white bath tub',\n",
       " 'a yellow and white train and some trees',\n",
       " 'A dirty toilet in a dirty bathroom with laminate flooring. ',\n",
       " \"A long train is on it's tracks with trees nearby. \",\n",
       " 'Brown and white cat sitting on the ledge of a window. ',\n",
       " 'A elephant walking away from a watering hole in a zoo enclosure.',\n",
       " 'A bathroom area with toilet and various cleaning utensils.',\n",
       " 'A giraffe is standing in a field with low trees.',\n",
       " 'A lone zebra that is standing near a rock.',\n",
       " 'A white and gray cat laying in a red cat bed.',\n",
       " 'A skier going down a snowy slope near trees.',\n",
       " 'A train is making a turn past a closed station.',\n",
       " 'A jet plane speeds down the runway at an airport.',\n",
       " 'A train is heading in for its next stop.',\n",
       " 'A variety of signs are attached to a pole.',\n",
       " 'An old, dirty bathroom contains a mop, bucket and a filthy toilet.',\n",
       " 'a toilet hooked up on top of a roof in an open area',\n",
       " 'A large bear standing behind a tree in a forest.',\n",
       " 'A stark white small bathroom containing just a toilet ',\n",
       " 'A white airplane flying on a cloudy day',\n",
       " 'a very big bear locked in a park',\n",
       " 'A yak needs long hair to survive in these mountains.',\n",
       " 'Stop sign placed in the middle of a single roads curve.',\n",
       " 'A person hiking through a snow covered valley.',\n",
       " 'A wide open door and curtain covered windows decorate the side of plane.',\n",
       " 'A dog lying in a pile of shoes',\n",
       " 'A black cat standing in front of a door under a window.',\n",
       " 'A ripe orange sitting in a dark background.',\n",
       " 'A giraffe standing in a field on a sunny day.',\n",
       " 'A green bug sits inside a glass jar. ',\n",
       " 'Corner of a layer cake with frosting and walnuts.',\n",
       " 'A lioness bites at the neck of a zebra as she takes it down.',\n",
       " 'A microwave with a radioactive warning sticker on the front.',\n",
       " 'A handicapped public toilet with rails and bars.',\n",
       " 'A large Thomas the Tank Engine birthday cake.',\n",
       " 'A cat lays on the couch, staring at something out of frame.',\n",
       " 'A horse that is standing in the grass.',\n",
       " 'a lit up street sign close to some neon lights ',\n",
       " 'a bear smelling something in the middle of a street ',\n",
       " 'A bathroom with a toilet and a scale.',\n",
       " 'An elephant with tusks standing in an enclosure.',\n",
       " \"A birthday cake is topped with a dog's head made out of frosting.\",\n",
       " 'A parrot perches itself on the branches of a leafy tree.',\n",
       " 'The Big Ben clock tower towering over the city of London.',\n",
       " 'The stop sign on the street is vandalized. ',\n",
       " 'A swan in the water floating across the water.',\n",
       " 'an old diesel locomotive coming upon a track switch ',\n",
       " 'A large broccoli plant has grows a big piece of broccoli.',\n",
       " 'A clock in a building with mountains in the background.',\n",
       " 'A jumbo jet airplane flying through a clear blue sky.',\n",
       " 'A traffic light and street sign next to building in rain.',\n",
       " 'A street sign for Miss America Way in front of the Atlantic City Convention Center.',\n",
       " 'Two giraffes walking through the fields of Africa',\n",
       " 'there are many different signs on this street pole',\n",
       " 'This is a stop sign at the corner of Swampfox and Gamecock.',\n",
       " 'A picture of a dog sitting in the backseat of a car.',\n",
       " 'A short clock tower is pictured with a large building in the background.',\n",
       " 'A giraffe licking the poles of a hut ',\n",
       " 'This train has a design an it says a new tramway for saint petersburg',\n",
       " 'a toilet sitting outside by a wall ',\n",
       " 'there is a large plane in the sky that says one world',\n",
       " 'A single giraffe that is walking in a field. ',\n",
       " 'White bathroom with a black tiled wall inside the shower. ',\n",
       " 'A wooden park bench near a gnarled old tree.',\n",
       " 'A red bench with painted red trees are pictured on a snowy day.',\n",
       " 'A white sink sitting next to a bath tub in a bathroom.',\n",
       " 'A single adult zebra walking in the wild.',\n",
       " 'a big clock that is on some kind of table',\n",
       " 'A large jetliner flying over a body of water.',\n",
       " 'A zebra standing on top of a dirt field.',\n",
       " 'A black bear eating in a large grassy field with flowers.',\n",
       " 'A pizza that is laying down on a table.',\n",
       " 'A fire truck that is in a hanger.',\n",
       " 'Two animals are standing by a pool of water.',\n",
       " 'A lone airplane is flying high against a grey sky.',\n",
       " 'a blue and yellow street sign and a stop war sign',\n",
       " 'there is a brown bear that is walking by a fence',\n",
       " 'The is rustic Hotel Diamond nestled in a woodsy setting.',\n",
       " 'A giraffe looks at the back of its enclosure.',\n",
       " 'a cat laying on the floor next to a fish bowl',\n",
       " 'A dog sitting on a table while wearing a hat.',\n",
       " 'A blue and white airplane that says \"Air transit\" landing on an airport. ',\n",
       " 'A white toilet sitting next to three trash cans.',\n",
       " 'A pizza sits on the floor near an open flame',\n",
       " 'A bear looks around in a rocky enclosure. ',\n",
       " 'A tropical bird perches on a rope surrounded by greenery. ',\n",
       " 'A giraffe standing in a lush green field.',\n",
       " 'A modern toilet is seen in this bathroom.',\n",
       " 'A blue sign with brown trim sitting on top of an orange post.',\n",
       " 'A train parked on the rails during the night.',\n",
       " 'A horse walking across a dry grass field.',\n",
       " 'An umbrella sitting on top of a hill next to a body of water.',\n",
       " 'A picture of a red building is  highlighted by a gate and train tracks outlining it.',\n",
       " 'a bed room with a bed and a large window',\n",
       " 'A lit lamp on the bed side table near the bed.',\n",
       " 'A stop sign attached to the corner of a building ',\n",
       " 'The poor duck is in a severely polluted waterway.',\n",
       " 'A parking meter sitting in front of a graffiti covered wall.',\n",
       " 'A locomotive train spewing smoke on the tracks.',\n",
       " 'a seagul is flying over the water on the beach',\n",
       " 'Plane landing on tarmac with buildings and sky',\n",
       " 'this sheep is standing on the grass on a field',\n",
       " 'A black Toyota Tundra parked in front of a garage.',\n",
       " 'A bench and trashcan are frozen in the park. ',\n",
       " 'A bird sitting on some plants in the water.',\n",
       " 'A clock on a white wall placed underneath a large window',\n",
       " 'A pizza pie with olive bits sits on cardboard. ',\n",
       " 'A sandwich made out of two donuts sitting on top of a plate covered in chocolate sauce.',\n",
       " 'A plane is covered while sitting at an airport',\n",
       " 'A bathroom with a glass shower door and a wood framed mirror. ',\n",
       " 'a street sign for masonic on a city street',\n",
       " 'An elephant curiously looking over an exhibit fence.',\n",
       " 'This zebra has black and white strips and is in the woods that is partially shaded.  ',\n",
       " 'A large airplane flying through a cloudy blue sky.',\n",
       " 'A small bird sitting on the branch of a tree.',\n",
       " 'The red fire hydrant is the focal point in front of the building.',\n",
       " 'A streamlined white train driving on the tracks',\n",
       " 'The zebra is eating something on the ground.',\n",
       " 'A rusted out fire hydrant sitting next to bags of garbage.',\n",
       " 'A giraffe is rubbing its neck against a tall pole',\n",
       " 'Red traffic light on cement post that includes street names and parking rules.',\n",
       " 'An airplane is flying overhead against a blue sky.',\n",
       " 'THERE IS A STREET CLOCK ON DISPLAY ON THE STREET',\n",
       " 'a double deckered bus driving on a city street',\n",
       " 'Tree air fresheners are hanging on a bathroom wall.',\n",
       " 'An elephant walks around on a cloudy day.',\n",
       " 'A photo of a bird that has been distorted.',\n",
       " 'A train pulling into a train station with large windows.',\n",
       " 'An airplane flies high above the mast of a ship.',\n",
       " 'The toilet space walls are tiled in black and white ',\n",
       " 'A motorcycle parked with no rider and a large stretch of empty land in the background.',\n",
       " 'A train traveling the track near a dirt and gravel trail.',\n",
       " 'A airplane that is sitting on a runway.',\n",
       " 'A young and old zebra stand in the dirt.',\n",
       " 'A small yellow plane is leaving the hangar.',\n",
       " 'A brown horse grazing in field behind a fence.',\n",
       " 'The giraffe is a tall a the tree trunks near to it.',\n",
       " 'Two horses an adult and a baby are in a big field.',\n",
       " 'A stainless steel refrigerator sitting on cardboard in a kitchen',\n",
       " 'A woolly sheep seen through a chicken-wire fence in an overgrown pasture.',\n",
       " 'a wooden desk with a computer keyboard on it ',\n",
       " 'A long haired gray cat sits on a window sill.',\n",
       " 'A train is riding past a building on an overpass.',\n",
       " 'A plane on a runway about to take off.',\n",
       " 'an empty park bench sitting among the trees',\n",
       " 'A mirror hangs on the wall in a bathroom.',\n",
       " 'A large oven with two turkeys, roast and ham on the racks.',\n",
       " 'A stop sign with the word driving written on it',\n",
       " 'A purple bird sitting on a branch of a tree. ',\n",
       " 'A bear looking forward in a forest. ',\n",
       " 'A coat seems to stand on a park bench',\n",
       " 'a grey and white cat is sitting on some shoes',\n",
       " 'A flower arrangement is displayed in a setting.',\n",
       " 'A KLM passenger jet taxis on an airport runway.',\n",
       " 'The apple symbol is show on the Premacy car.',\n",
       " 'All you can see in the image is a stop sign and tree.',\n",
       " 'A small red bird perched on a branch.',\n",
       " 'A clock with an inscription is shown here.',\n",
       " 'Plane standing still on runway preparing to take off.',\n",
       " 'a blue and white bird snatching a worm',\n",
       " 'A toilet right next to a drying machine',\n",
       " ' a small bird on a branch in tree',\n",
       " 'Mirror finish engine attached to a black frame of a motorcycle.',\n",
       " 'A brown bear walking on all fours near a lake with something in his mouth. ',\n",
       " 'a tiled bathroom with a sink and bath tub',\n",
       " 'A old tower clock next to a glass office building',\n",
       " 'The zebra is eating the grass in the field',\n",
       " 'there is a large beige horse standing in a stable',\n",
       " 'A city filled with tall buildings and a bridge over a river.',\n",
       " 'A close up of a very small and cute bird.',\n",
       " 'Black and white photo of steam engine train on tracks along the water.',\n",
       " 'A clock with a picture of a young Asian girl wearing a hat.',\n",
       " 'A statue of a horse with blue reins.',\n",
       " 'A baby elephant taking a stroll at the zoo',\n",
       " 'A large bed with a wooden frame and sheets made up.',\n",
       " 'A brown teddy bear in a forest with trees and shrubbery.',\n",
       " 'there is a broken tree log on the ground ',\n",
       " 'A piece of cake is sitting on a plate.',\n",
       " 'The bear in the zoo enclosure is an the edge of the pond.',\n",
       " 'two fried flat breads with broccoli shredded cheese and BBQ sauce',\n",
       " 'A red and white fire hydrant is on the lawn.',\n",
       " 'A cat sleeps on a concrete hearth of a building',\n",
       " 'A bathroom with step in shower and bathtub combo',\n",
       " 'A huge white airplane is about to fly away on the airstrip. ',\n",
       " 'A trick plane blowing a trail of smoke in the sky.',\n",
       " 'A lion takes a nap while a giraffe cranes its neck.',\n",
       " 'A very nice looking plane flying in the sky.',\n",
       " 'A bird of prey glides through the air high in the sky.',\n",
       " 'a fancy bed room with a canopy and a chandelier ',\n",
       " 'Close up view of a wall-mounted oven in a kitchen.',\n",
       " 'A polar bear standing on a rock at the edge of the water.',\n",
       " 'A polar bear standing on the rocks in its enclosure.',\n",
       " 'A blue train engine sitting on rail road tracks. ',\n",
       " 'An airplane banks into a left turn in a cloudy sky. ',\n",
       " 'A train travels down the tracks, with houses nearby.',\n",
       " 'a large air plane flying in the air ',\n",
       " 'A horse wearing a red blanket grazing under a power line tower.',\n",
       " 'A person skis down a mountain facing the camera.',\n",
       " 'a double decker bus sit parked on a gravel road ',\n",
       " 'A pink fire hydrant, with chains attached to it, sitting in the middle of grass area',\n",
       " 'A toilet with a brown toilet seat on a floor with small colorful tiles.',\n",
       " 'a short passenger train on a track by a grassy hill',\n",
       " 'A giraffe stands tall among the dry trees.',\n",
       " 'an adult white polar bear walking on wet rocks',\n",
       " 'A bench in some grass near some trees.',\n",
       " 'A view of a bathroom consisting of a toilet and a shower stall.',\n",
       " 'a plane in the air by a plume of smoke ',\n",
       " 'a look down in a city with trees and snow surrounding it',\n",
       " 'A white clock has black numbers and hands.',\n",
       " 'A white and yellow bus driving in the street.',\n",
       " 'A black and white dog barking at somehting',\n",
       " 'a red and white jet on a runway and brown grass',\n",
       " 'there is a clock int he middle of all the signs.',\n",
       " 'A large airplane that is painted in white, orange, and red has just taken off.',\n",
       " 'A giraffe eats from a feeding trough inside a cage.',\n",
       " 'A clock tower against a deep blue sky in town',\n",
       " 'Graphical drawing of low bed in a plain room.',\n",
       " 'Either the dog likes hats or his owner thought this would be a good picture.',\n",
       " 'A plane leaves a long contrail in the air.',\n",
       " 'A photo of a river with a train bridge across it.',\n",
       " 'A silver fire hydrant on grassy area next to trees.',\n",
       " 'A small airplane waits on a runway in front of a row of trees.',\n",
       " 'A cheese pizza inside a box sitting on a table. ',\n",
       " 'A giraffe with large brown eyes stares into the camera.',\n",
       " 'A cat laying down on the ground with some shoes.',\n",
       " 'A stack of dark and some light colored clothing sitting next to a computer mouse.',\n",
       " 'A photo of a kite flying as high as a tree.',\n",
       " 'A massive building with a clock at the very top.',\n",
       " 'A train is approaching a tunnel in the side of a mountain.',\n",
       " 'An antique clock with a time telling 12:00.',\n",
       " 'The passenger train is traveling through a mountain valley.',\n",
       " 'Panda bear on back eating bamboo on top of rocks.',\n",
       " 'A fire hydrant is in the dark by a sidewalk.',\n",
       " 'a bed that has a big skirt on it',\n",
       " 'A mid sized commercial airline flying in the air ',\n",
       " 'A small bathroom has a toilet and bathtub',\n",
       " 'a red and white sign and some parking spaces',\n",
       " 'A dirty looking corner of a rest room with a bucket.',\n",
       " 'A red train going on top of a bridge. ',\n",
       " 'Reflective image of a boat on the water.',\n",
       " 'A plane flying low over some electric poles.',\n",
       " 'A messy bed in a dark hotel room.',\n",
       " 'Picture of a small bathroom with an orb',\n",
       " 'a cat standing by a iron fence trying to sneak through it ',\n",
       " 'Small wildflowers are blooming near a wooden bench.',\n",
       " 'A small plane moving along the water during the day.',\n",
       " 'A plane flying in the sky above the clouds during sunset. ',\n",
       " 'a giraffe standing under a tree in a fenced in area',\n",
       " 'The huge airliner is flying next to the clouds. ',\n",
       " 'a hot dog with red peppers and banana peppers',\n",
       " 'A calico cat sits directly on the keyboard of an open laptop.',\n",
       " 'A vase with three large, pink, multi-petaled flowers.',\n",
       " 'A black  and white clock on the side of a building',\n",
       " 'A teddy bear with other stuffed animals with a note on the bear',\n",
       " 'A bus is traveling down a country road.',\n",
       " 'a close up of a dog on a beach with his tongue out',\n",
       " 'A toilet is full of dirt looking material.',\n",
       " 'a close up of a dog in a bath tub ',\n",
       " 'there are a pink pair of sneakers and a pink frisbee',\n",
       " 'A black and white photo of a railroad crossing.',\n",
       " 'A polar bear swimming through water in a zoo. ',\n",
       " 'The toilet bowl is dirty and needs to be flushed. ',\n",
       " 'A motorcycle that is parked by some stairs.',\n",
       " 'A small bird stands near the green grass.',\n",
       " 'Bench made from limbs and logs in a park setting.',\n",
       " 'a close up of a note written on a piece of paper ',\n",
       " 'A shot of some bananas on the tree. ',\n",
       " 'A cat laying on the ground in a room.',\n",
       " 'Zebra standing in area with colorful plants growing nearby.',\n",
       " 'A toilet seat attached to a chair with a bucket under it. ',\n",
       " 'A white bird is flying during the day near water',\n",
       " 'A horse standing in a mountain paddock during the day',\n",
       " 'a clock that is on top of a large building',\n",
       " 'a dog is getting ready to lay down in his dog bed',\n",
       " 'A cow lying down asleep in the sand',\n",
       " 'A sign attached to the top of a clock.',\n",
       " 'Small clock on a wall next to a mirror and coat rack. ',\n",
       " 'Bright blue and silver fire hydrant next to a field.',\n",
       " 'A giraffe standing under a several tree branches.',\n",
       " 'A large clock tower with a huge cross on top of it.',\n",
       " 'A zebra that is looking at the ground.',\n",
       " 'An black and white picture of a makeshift bed.',\n",
       " 'A jet plane is flying directly overhead against the blue sky.',\n",
       " 'large airplane flying high in the clear blue sky',\n",
       " 'A polar bear walks atop an outcropping of rocks.',\n",
       " 'A stack of bins provides handy dry storage close to the fridge.',\n",
       " 'A clock tower is on a building in the city. ',\n",
       " 'A dim bathroom with a light over the sink',\n",
       " 'A train is crossing on an overpass near a billboard.',\n",
       " 'A large clock tower underneath a bunch of clouds.',\n",
       " 'A large tower with a clock on it and a cross on the top',\n",
       " \"A circular mirror reflecting a woman's stomach in turquoise shirt.\",\n",
       " 'A terrier walking on a sidewalk next to a patch of grass.',\n",
       " 'A swan in the tall grass and water. ',\n",
       " 'A steeple with a clock is outlined against the blue sky.',\n",
       " 'A row of benches beside a tennis court.',\n",
       " 'A plan that is flying high in the sky.',\n",
       " 'Bullet holes in a stop sign in a rule area',\n",
       " 'A very small bathroom has a sloped roof and a skylight. ',\n",
       " 'Orange grown in between two branches squished on the edges.',\n",
       " 'The bed has a sheer canopy over it. ',\n",
       " 'a large air plane flying in the air ',\n",
       " 'A giraffe standing on top of a brush covered field.',\n",
       " 'Cat laying in front of mirrors with candles by it looking at self',\n",
       " 'a brown bear walks lazily along the dirt',\n",
       " 'Scissors are sitting on the table with needles and a pin cushion behind it.',\n",
       " 'a dog in a car looking hanging out the window',\n",
       " 'Plane with graphics on the side sitting out on the runway',\n",
       " 'A coffee pot and a package set in front of a toaster oven.',\n",
       " 'A combination shower and bathtub with an open window.',\n",
       " 'A teddy bear and other toys sit outside next to a plant.',\n",
       " 'The fire hydrant is standing in the middle of the chaos.',\n",
       " 'A white bird perched on a rock by the ocean.',\n",
       " 'Orange cat watching in room with empty shoes.',\n",
       " 'A baby elephant standing in the dirt next to a shrub',\n",
       " 'A giraffe standing in the forest staring at the camera.',\n",
       " 'A single bird that is resting on a window pane. ',\n",
       " 'a red and white stop sign at a four way intersection',\n",
       " 'Glazed doughnut on a green napkin on a pink counter top',\n",
       " 'A black and brown dog is wrapped in a sheet.',\n",
       " 'A bear in water with paws on a plastic container.',\n",
       " 'The kitchen has a gas cooktop and oven.',\n",
       " 'A view of a sign that states it is prohibited to remove this item.',\n",
       " 'A bear walks over a tree branch in shallow water. ',\n",
       " 'A giraffe walking up a small rise next to a road.',\n",
       " 'a fire hydrant sits on a brick side walk ',\n",
       " 'a mess spilled on the oven door and floor',\n",
       " 'A zebra standing next to a fountain and a wooden fence.',\n",
       " 'A giraffe is in the foreground while an animal with very long, straight black horns stands in the background. ',\n",
       " 'A fire hydrant stands crookedly in a wooded area.',\n",
       " 'The toilet has a cosmetic bag and paper on the back.',\n",
       " 'A bird with spread wings is on the sand.',\n",
       " 'An airplane sits on a runway in the middle of snowy grass.',\n",
       " 'Flowers inside a vase next to a windowsill.',\n",
       " 'A train covered in snow on top of train tracks.',\n",
       " 'An upper image of a building and a Haight sign. ',\n",
       " 'A picture of some vegetables being grown in the sunlight.',\n",
       " \"A skateboard and it's wheels being parked in one area.\",\n",
       " 'An orange sitting on top of a wet beach.',\n",
       " 'A brown and speckled bird on a branch.',\n",
       " 'A white small toilet area of a bathroom.',\n",
       " 'A tall statue of a horse sitting among yellow flowers.',\n",
       " 'Two slices of homemade pizza on a plate.',\n",
       " \"The pickup truck was little more than an advertising shill for its owner's failing business.\",\n",
       " 'A freight train is sitting idle on train tracks.',\n",
       " 'A bench that is beautifully shaded by a tree.',\n",
       " 'A zebra grazing on grass in an enclosure',\n",
       " 'very many candles on a fridge with the lights on',\n",
       " 'A bunch of bananas are on an empty store shelf.',\n",
       " 'A view of a plane wing overlooking a mountain range.',\n",
       " 'A zebra eating hay out of a container near a rock.',\n",
       " \"A passenger jet with it's landing gear still engaged.\",\n",
       " 'Signs hang on a pole against the blue of the sky.',\n",
       " 'A red fire hydrant sitting next to a wooden wall.',\n",
       " 'Commercial jet, possibly Singapore Air, in flight, overcast skies.',\n",
       " 'a hot dog on  a white roll with onions and mustard and chips',\n",
       " 'commuting signs showing the cyclist and round about signs',\n",
       " 'The black and white cow is eating grass from the field.',\n",
       " 'A red fire hydrant leaking water all over a street.',\n",
       " 'A green plant has a lot of leaves on it. ',\n",
       " 'A long train going down the train track',\n",
       " 'A zebra standing alert on a field in a zoo area.',\n",
       " 'A black horse stabled and leashed with a blue lead.',\n",
       " 'Sausage and asparagus on a piece of cooked break. ',\n",
       " 'An up close picture of a giraffe with its eyes open',\n",
       " 'This older style toilet is in a small bathroom.',\n",
       " 'A vintage train makes its way through a valley.',\n",
       " 'An elephant with its ear flapped up crossing a road.',\n",
       " 'A dark concrete room with a toilet in the center.',\n",
       " 'An elephant under a canopy with a fence in background.',\n",
       " 'A giraffe approaches a small tree in the field.',\n",
       " 'A train on a rail line in the countryside',\n",
       " 'A modem, scissors and other household items are displayed.',\n",
       " 'Two dogs, one wearing a hat, rest in the tall grass by the edge of the woods in the background. ',\n",
       " 'a small dog is sitting on a table',\n",
       " 'a person is parasailing  in the water with a helmet on',\n",
       " 'There is animal wall paper on the wall surrounding this toilet. ',\n",
       " 'Park bench sitting on the inside of a wooded area. ',\n",
       " 'A teddy bear sitting next to a pair of boots.',\n",
       " 'A blue clock with roman numerals on a tower.',\n",
       " 'The view is from the back of a horse, riding in a dry, grassy field towards a pond on a sunny say.',\n",
       " 'the plane is taking off and the bottom is blue',\n",
       " 'A picture of two black and white street signs above a traffic light.',\n",
       " 'A bird stands on top of the sand and water.',\n",
       " 'A clock sits above a pattern and under a logo.',\n",
       " 'A Wii remote is left on the table.',\n",
       " 'A giraffe is standing inside a wet enclosure.',\n",
       " 'A zebra grazing on grass next to a stone wall.',\n",
       " 'an elephant is eating some leaves and is standing by a log',\n",
       " 'a toilet in a white tiled public bathroom',\n",
       " 'A wall mounted clock with two metal sculptures around it.',\n",
       " 'Various street signs in front of an apartment building.',\n",
       " 'A suit jacket, dress shirt and tie displayed on a mannequin.',\n",
       " 'A large black dog up in the air on a beach.',\n",
       " 'a brown door a rug and a white toilet',\n",
       " 'A bus traveling across a bridge in the snow.',\n",
       " 'A zebra leaned over eating grass in a field.',\n",
       " 'A small zebra stands still in the middle of an outdoor setting.',\n",
       " 'a blue jay is sitting out on a branch',\n",
       " 'There is a glass of wine sitting on the table.',\n",
       " 'A plane flies through a bright but cloudy sky.',\n",
       " 'A graffiti covered dumpster sits on a sidewalk.',\n",
       " 'A giraffe finds some sparse shade in his habitat',\n",
       " 'Red train engine holding other cars to it. ',\n",
       " 'A zebra in a shed with a container next to it',\n",
       " 'an antique-styled double bed in a room with a chandelier and carved moldings on the ceiling',\n",
       " 'An out of focus picture of a computer keyboard.',\n",
       " 'Meat and rice are served with a side of broccoli.',\n",
       " 'A red fire hydrant sitting on the side of a sidewalk.',\n",
       " 'A train being pulled by an orange engine.',\n",
       " 'Two butterflies are sitting on an orange half.',\n",
       " 'The moon in the sky above a jetliner.',\n",
       " 'a big plane sits parked in front of a building ',\n",
       " 'A black bair on a rock beside a wooden fence',\n",
       " 'Several green bananas growing on a banana tree',\n",
       " ' Cat with its head wedged between the window looking outside',\n",
       " 'A large long red train on a track.',\n",
       " 'a large light tower with a clock built into the side of it',\n",
       " 'A large airplane is flying across the sky.',\n",
       " 'A donut that has been partially eaten sitting on a napkin.',\n",
       " 'a sad cow walking through an empty area',\n",
       " 'A beautiful hotel room with a tan bed and wooden headboard',\n",
       " 'A white an blue fire hydrant on grassy yard next to sidewalk.',\n",
       " 'there is a black and white cow eating from the grass on the field',\n",
       " 'A white train pulling into a station with red sign on front of it.',\n",
       " 'a boat is docked and some water and a fence',\n",
       " 'A fire hydrant by  some bushes in front of a building.',\n",
       " 'A lone duck on the grass near water',\n",
       " 'Close up of the writing that is on a parking meter.',\n",
       " 'A white refrigerator in an alcove in a kitchen.',\n",
       " 'A bathroom with a white toilet and a metal grate.',\n",
       " 'A stop sign in the middle of nowhere. ',\n",
       " 'Cooking a chicken and vegetable pizza on an outdoor grill.',\n",
       " 'A captive black bear lumbers around in the grass. ',\n",
       " 'A close up of a hero sandwich containing chicken and tomatos',\n",
       " 'dinner cooking in the oven, with door open',\n",
       " 'A light colored bear waling in a field with flowers, rocks and grass.',\n",
       " 'A grandfather clock made of wooden rods rests against the wall of a house.',\n",
       " 'The birthday cake is decorated with icing and sticks. ',\n",
       " 'A large sheep standing on top of a lush green hillside.',\n",
       " 'A bent One Way sign adorns the pole of this stoplight. ',\n",
       " 'a black and white cow beside a feeder looking up',\n",
       " 'Stocky horse is standing in the middle of a fenced area.',\n",
       " 'A pillow with blue leaves is put on the bed.',\n",
       " 'An open field with a bench and a mountain.',\n",
       " 'A giraffe eating next to a building. ',\n",
       " 'A cramped bathroom with a standing shower that has clear glass doors.',\n",
       " 'A black cow stands alone in a grassy field.',\n",
       " 'An airplane flies high over snow capped mountains.',\n",
       " 'A photograph of a giraffe in the wild. ',\n",
       " 'A room with empty shelves, a sink and a trashcan.',\n",
       " 'A toy train runs along an outdoor track.',\n",
       " 'The dirty white stove is in a ruined kitchen.',\n",
       " 'A long train traveling through a wooded area billowing smoke.',\n",
       " 'A person in blue jacket snowboarding down a hill.',\n",
       " 'A green truck is parked in a concrete parking lot.',\n",
       " 'A parakeet perching atop a pair of used Vans shoes.',\n",
       " 'A wet teddy bear face down on the sidewalk.',\n",
       " 'A long bench on the side of the building.',\n",
       " 'A fire hydrant is situated at the bottom of a grassy hill. ',\n",
       " 'A bird flying over the beach to the water',\n",
       " 'View of body of water with a water surfer in motion standing on board holding handle. and water splashing behind.',\n",
       " 'A bench sits in front of an asphalt that is being overgrown with grass',\n",
       " 'An empty wooden bench with an empty path stretching into the distance.',\n",
       " 'A broken down school bus parked in a lot.',\n",
       " 'A clock is shown at the top of the stairs.',\n",
       " 'Three rocks are sitting on top of a larger rock under some trees; one rock has a picture of a stop sign on it, one rock has another road sign on it, and one rock has some writing on it.',\n",
       " 'A bench is situated on the edge of a very small dock.',\n",
       " 'A person in the snow holding ski poles.',\n",
       " 'this is an image of a man in a phone booth.',\n",
       " 'a bird that is sitting on a small light.',\n",
       " 'A train engine carrying carts down a track.',\n",
       " 'Black-and-white sheep eating grass on the side of the mountain. ',\n",
       " 'An airplane flying in the big blue sky with no clouds',\n",
       " 'some red yellow and blue pandas on a white skateboard',\n",
       " 'An old, stained elaborate roman numerical clock on a clear day',\n",
       " 'Train on a track driving through a grassy field.',\n",
       " 'A couple of traffic signs sitting on top of a stop sign.',\n",
       " 'A zebra that is standing in a pen.',\n",
       " 'a fighter jet sitting on the run way',\n",
       " 'A wet cell phone sitting on a surface besides some keys.',\n",
       " 'A close of of the font end of a motorcycle.',\n",
       " 'A defunct microwave oven sits abandoned by the edge of a marsh.',\n",
       " 'A fire place between two book display cases with mirrors in the back.',\n",
       " 'A Zebra grazing and looking for grass to eat.',\n",
       " 'a person is out in the snow with some skis',\n",
       " 'A long yellow and black train is approaching an intersection.',\n",
       " 'A clock lodged between two bent, metal stands.',\n",
       " 'Large direction signs above a highway in front of office buildings.',\n",
       " 'A kitten peeks out from an open window.',\n",
       " 'A zebra grazing in a field in front of various trees.',\n",
       " 'On the table are alcohol wipes and bandaids',\n",
       " 'Toilet without a toilet seat in a cement room',\n",
       " 'A lamp that is reflecting off a table. ',\n",
       " 'One elephant in a wire enclosure in a zoo.',\n",
       " 'A clock and bells mounted outside of a building.',\n",
       " 'A teddy bear wearing a red jacket sits on a beige carpet.',\n",
       " 'A jet is flying in the sky while being photographed',\n",
       " 'hamburger and chicken sandwich wrapped in wax paper',\n",
       " 'a vase with some flowers growing out of it ',\n",
       " 'a toilet also made into a sink with pipe running too it',\n",
       " 'A train is parked on the side of the road. ',\n",
       " 'The young horse is struggling to get up from a fall.',\n",
       " 'a clock on a tower of a small building with mountains in the background']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_df['caption_w'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9146c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_cap = {word:i+1 for i,word in enumerate(list(set(all_w)))}  #0 is kept for the padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2f361179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_enc(sentence):\n",
    "    sentence = nltk.word_tokenize(sentence.lower())\n",
    "    return [dico_cap[w] for w in sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "841671ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['urn_cap']=data_df['caption_w'].apply(cap_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3b50006f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df['urn_cap'].apply(len).max() #length to which we need to pad the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "87094de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_cap(sentence, data_df):\n",
    "    l = data_df['urn_cap'].apply(len).max()\n",
    "    miss = l-len(sentence)\n",
    "    return [0]*miss+sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "51453c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['urn_cap']=data_df['urn_cap'].apply(lambda x:pad_cap(x,data_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3f8319d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cap(cap_train,y_train, cap_val, y_val, epochs, model):\n",
    "    \n",
    "    m = model\n",
    "    m.train()\n",
    "    loss = nn.NLLLoss()    #for multi class classification task\n",
    "    optimizer = optim.Adam(m.parameters(), lr=0.005)\n",
    "    epoch = 0\n",
    "    for e in range(epochs):\n",
    "        train_accuracy=0\n",
    "        tot_loss = 0\n",
    "        for i in range(len(cap_train)):\n",
    "            sent = cap_train[i]\n",
    "            \n",
    "                   \n",
    "            optimizer.zero_grad()\n",
    "            o = m(torch.LongTensor(sent))\n",
    "            \n",
    "            l = loss(o, torch.tensor(y_train[i]-1))\n",
    "            tot_loss += l\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_accuracy += torch.argmax(o)==torch.tensor(y_train[i]-1)\n",
    "        \n",
    "        print(\"Total loss in epoch {} is {}.\".format(epoch, tot_loss))\n",
    "        epoch += 1\n",
    "        train_accuracy = train_accuracy/len(cap_train) \n",
    "        if epoch %10 == 0:\n",
    "            \n",
    "            m.eval()\n",
    "            val_accuracy=0\n",
    "            for i in range(len(cap_val)):\n",
    "                sent = cap_val[i]\n",
    "                out = m(torch.LongTensor(sent))\n",
    "                val_accuracy += torch.argmax(out)==torch.tensor(y_val[i]-1)\n",
    "      \n",
    "            \n",
    "            val_accuracy = val_accuracy/len(cap_val)\n",
    "            print('train_acc={}'.format(train_accuracy))\n",
    "            print('val_acc={}'.format(val_accuracy))\n",
    "            file_name = 'urn'+str(epoch)\n",
    "            \n",
    "            m.train()\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "c043f9f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>imgs</th>\n",
       "      <th>caption</th>\n",
       "      <th>cat</th>\n",
       "      <th>y</th>\n",
       "      <th>caption_w</th>\n",
       "      <th>urn_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000316250.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-0.6405193209648132, -1.4194706678390503, 0....</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>A small clock hanging up with some lamps.</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000497187.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[0.2704429030418396, 0.42941799759864807, 0.1...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>a button on a black keyboard on a desk</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000483348.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[2.349658489227295, 0.06488067656755447, -1.4...</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>A toilet with the seat up in a run down panele...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000367400.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[2.1123123168945312, 0.20900174975395203, -0....</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>a zebra and some billy goats grazing in the op...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000540784.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-1.00090754032135, -0.6644606590270996, 1.83...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>A large tall tower with a clock on the top.</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>000000574592.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-2.348522186279297, -0.7619928121566772, -0....</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>a vase with some flowers growing out of it</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>000000281427.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[2.349658489227295, 0.06488067656755447, -1.4...</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>a toilet also made into a sink with pipe runni...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>000000422423.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[0.3813672363758087, -0.43124091625213623, -0...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>A train is parked on the side of the road.</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>000000163107.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-1.3799556493759155, -1.9577091932296753, 0....</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>The young horse is struggling to get up from a...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>000000010964.jpg</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>&lt;PIL.Image.Image image mode=RGB size=100x100 a...</td>\n",
       "      <td>[[-2.1130001544952393, 1.9674150943756104, 0.3...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>a clock on a tower of a small building with mo...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                                                  1  \\\n",
       "0    000000316250.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "1    000000497187.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "2    000000483348.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "3    000000367400.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "4    000000540784.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "..                ...                                                ...   \n",
       "995  000000574592.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "996  000000281427.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "997  000000422423.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "998  000000163107.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "999  000000010964.jpg  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                                  imgs  \\\n",
       "0    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "1    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "2    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "3    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "4    <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "..                                                 ...   \n",
       "995  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "996  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "997  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "998  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "999  <PIL.Image.Image image mode=RGB size=100x100 a...   \n",
       "\n",
       "                                               caption  cat  y  \\\n",
       "0    [[-0.6405193209648132, -1.4194706678390503, 0....   85  1   \n",
       "1    [[0.2704429030418396, 0.42941799759864807, 0.1...   76  1   \n",
       "2    [[2.349658489227295, 0.06488067656755447, -1.4...   70  1   \n",
       "3    [[2.1123123168945312, 0.20900174975395203, -0....   24  1   \n",
       "4    [[-1.00090754032135, -0.6644606590270996, 1.83...   85  1   \n",
       "..                                                 ...  ... ..   \n",
       "995  [[-2.348522186279297, -0.7619928121566772, -0....   86  1   \n",
       "996  [[2.349658489227295, 0.06488067656755447, -1.4...   81  1   \n",
       "997  [[0.3813672363758087, -0.43124091625213623, -0...    7  1   \n",
       "998  [[-1.3799556493759155, -1.9577091932296753, 0....   19  1   \n",
       "999  [[-2.1130001544952393, 1.9674150943756104, 0.3...   85  1   \n",
       "\n",
       "                                             caption_w  \\\n",
       "0            A small clock hanging up with some lamps.   \n",
       "1               a button on a black keyboard on a desk   \n",
       "2    A toilet with the seat up in a run down panele...   \n",
       "3    a zebra and some billy goats grazing in the op...   \n",
       "4          A large tall tower with a clock on the top.   \n",
       "..                                                 ...   \n",
       "995        a vase with some flowers growing out of it    \n",
       "996  a toilet also made into a sink with pipe runni...   \n",
       "997        A train is parked on the side of the road.    \n",
       "998  The young horse is struggling to get up from a...   \n",
       "999  a clock on a tower of a small building with mo...   \n",
       "\n",
       "                                               urn_cap  \n",
       "0    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "..                                                 ...  \n",
       "995  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "996  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "999  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "4966abb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "n_train = round(.8*len(data_df))    #only train and val to simplify\n",
    "\n",
    "cap_train = np.stack(np.array(data_df['urn_cap'].iloc[:n_train]))\n",
    "y_train = np.array(data_df['cat'].iloc[:n_train])     # our targets are the (90) categories\n",
    "\n",
    "cap_val = np.stack(np.array(data_df['urn_cap'].iloc[n_train:]))\n",
    "y_val = np.array(data_df['cat'].iloc[n_train:])\n",
    "\n",
    "\n",
    "\n",
    "print(len(cap_train))\n",
    "\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "a11941de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 44)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap_val[:4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "96127ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.7014e+21,  7.0065e-45, -1.2598e-01, -7.2944e-01,  1.3297e-01,\n",
       "        -3.4087e-02,  1.8618e-01, -1.1880e-01, -6.3833e-02, -1.1451e-02,\n",
       "         2.5780e-01,  1.2937e-01,  1.7338e-01,  2.2528e-01,  1.2335e-01,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  1.5835e-43,  0.0000e+00,\n",
       "        -6.1543e-37,  3.0911e-41, -5.3224e-37,  3.0911e-41])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(y_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "816f42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "urn1=URNclassifier(105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6db75084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2854184/1849587363.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.softmax(self.linear(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 3201.625.\n",
      "Total loss in epoch 1 is 2871.499755859375.\n",
      "Total loss in epoch 2 is 2825.593994140625.\n",
      "Total loss in epoch 3 is 2796.134765625.\n",
      "Total loss in epoch 4 is 2794.2412109375.\n",
      "Total loss in epoch 5 is 2761.53759765625.\n",
      "Total loss in epoch 6 is 2734.967529296875.\n",
      "Total loss in epoch 7 is 2750.1572265625.\n",
      "Total loss in epoch 8 is 2672.353515625.\n",
      "Total loss in epoch 9 is 2636.181640625.\n",
      "train_acc=0.16249999403953552\n",
      "val_acc=0.07000000029802322\n",
      "Total loss in epoch 10 is 2575.74267578125.\n",
      "Total loss in epoch 11 is 2517.33447265625.\n",
      "Total loss in epoch 12 is 2451.755859375.\n",
      "Total loss in epoch 13 is 2416.510009765625.\n",
      "Total loss in epoch 14 is 2306.6982421875.\n",
      "Total loss in epoch 15 is 2276.1650390625.\n",
      "Total loss in epoch 16 is 2206.06298828125.\n",
      "Total loss in epoch 17 is 2130.4248046875.\n",
      "Total loss in epoch 18 is 2046.5179443359375.\n",
      "Total loss in epoch 19 is 2052.020263671875.\n",
      "train_acc=0.3725000023841858\n",
      "val_acc=0.054999999701976776\n",
      "Total loss in epoch 20 is 1967.464111328125.\n",
      "Total loss in epoch 21 is 1952.5738525390625.\n",
      "Total loss in epoch 22 is 1925.205322265625.\n",
      "Total loss in epoch 23 is 1867.629150390625.\n",
      "Total loss in epoch 24 is 1832.3385009765625.\n",
      "Total loss in epoch 25 is 1791.1143798828125.\n",
      "Total loss in epoch 26 is 1811.01171875.\n",
      "Total loss in epoch 27 is 1805.255615234375.\n",
      "Total loss in epoch 28 is 1745.7752685546875.\n",
      "Total loss in epoch 29 is 1723.33349609375.\n",
      "train_acc=0.4749999940395355\n",
      "val_acc=0.06499999761581421\n",
      "Total loss in epoch 30 is 1726.4500732421875.\n",
      "Total loss in epoch 31 is 1673.1634521484375.\n",
      "Total loss in epoch 32 is 1625.2691650390625.\n",
      "Total loss in epoch 33 is 1678.322509765625.\n",
      "Total loss in epoch 34 is 1717.2786865234375.\n",
      "Total loss in epoch 35 is 1669.1265869140625.\n",
      "Total loss in epoch 36 is 1627.4075927734375.\n",
      "Total loss in epoch 37 is 1629.172119140625.\n",
      "Total loss in epoch 38 is 1633.293212890625.\n",
      "Total loss in epoch 39 is 1613.495849609375.\n",
      "train_acc=0.5149999856948853\n",
      "val_acc=0.03999999910593033\n",
      "Total loss in epoch 40 is 1620.6676025390625.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "URNclassifier(\n",
       "  (embedding): Embedding(1475, 105)\n",
       "  (urn_layer): UnitaryRNN()\n",
       "  (linear): Linear(in_features=15, out_features=90, bias=True)\n",
       "  (softmax): LogSoftmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cap(cap_train,y_train, cap_val, y_val, epochs=41, model=urn1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eec231d",
   "metadata": {},
   "source": [
    "With 90 categories, if the model was making random prediction, we would expect an accuracy around .01. .07 of val_accuracy is weak but it nevertheless shows that some learning has taken place.\n",
    "\n",
    "However we can see that our model quickly starts overfitting.\n",
    "We can try embedding with lower number of dimensions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f718820a",
   "metadata": {},
   "outputs": [],
   "source": [
    "urn2=URNclassifier(45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "97ed8a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2854184/1849587363.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self.softmax(self.linear(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss in epoch 0 is 3184.132080078125.\n",
      "Total loss in epoch 1 is 2838.473388671875.\n",
      "Total loss in epoch 2 is 2802.661376953125.\n",
      "Total loss in epoch 3 is 2810.038330078125.\n",
      "Total loss in epoch 4 is 2719.708984375.\n",
      "Total loss in epoch 5 is 2770.886474609375.\n",
      "Total loss in epoch 6 is 2764.735595703125.\n",
      "Total loss in epoch 7 is 2750.774169921875.\n",
      "Total loss in epoch 8 is 2713.796630859375.\n",
      "Total loss in epoch 9 is 2694.397216796875.\n",
      "train_acc=0.13750000298023224\n",
      "val_acc=0.05999999865889549\n",
      "Total loss in epoch 10 is 2716.61669921875.\n",
      "Total loss in epoch 11 is 2755.96533203125.\n",
      "Total loss in epoch 12 is 2770.85888671875.\n",
      "Total loss in epoch 13 is 2756.70458984375.\n",
      "Total loss in epoch 14 is 2614.54736328125.\n",
      "Total loss in epoch 15 is 2792.875.\n",
      "Total loss in epoch 16 is 2720.59423828125.\n",
      "Total loss in epoch 17 is 2703.12890625.\n",
      "Total loss in epoch 18 is 2756.513916015625.\n",
      "Total loss in epoch 19 is 2744.0546875.\n",
      "train_acc=0.13124999403953552\n",
      "val_acc=0.05000000074505806\n",
      "Total loss in epoch 20 is 2787.586181640625.\n",
      "Total loss in epoch 21 is 2675.691162109375.\n",
      "Total loss in epoch 22 is 2754.382568359375.\n",
      "Total loss in epoch 23 is 2649.671630859375.\n",
      "Total loss in epoch 24 is 2721.5244140625.\n",
      "Total loss in epoch 25 is 2747.081298828125.\n",
      "Total loss in epoch 26 is 2692.354736328125.\n",
      "Total loss in epoch 27 is 2647.069091796875.\n",
      "Total loss in epoch 28 is 2707.12646484375.\n",
      "Total loss in epoch 29 is 2819.584228515625.\n",
      "train_acc=0.10499999672174454\n",
      "val_acc=0.07000000029802322\n",
      "Total loss in epoch 30 is 2786.323486328125.\n",
      "Total loss in epoch 31 is 2692.651611328125.\n",
      "Total loss in epoch 32 is 2696.986083984375.\n",
      "Total loss in epoch 33 is 2721.781494140625.\n",
      "Total loss in epoch 34 is 2747.463134765625.\n",
      "Total loss in epoch 35 is 2682.701416015625.\n",
      "Total loss in epoch 36 is 2785.060546875.\n",
      "Total loss in epoch 37 is 2640.288818359375.\n",
      "Total loss in epoch 38 is 2824.680908203125.\n",
      "Total loss in epoch 39 is 2694.765625.\n",
      "train_acc=0.15125000476837158\n",
      "val_acc=0.05000000074505806\n",
      "Total loss in epoch 40 is 2708.176025390625.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "URNclassifier(\n",
       "  (embedding): Embedding(1475, 45)\n",
       "  (urn_layer): UnitaryRNN()\n",
       "  (linear): Linear(in_features=10, out_features=90, bias=True)\n",
       "  (softmax): LogSoftmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cap(cap_train,y_train, cap_val, y_val, epochs=41, model=urn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d6f8f",
   "metadata": {},
   "source": [
    "The performance is the same. It still seems overfitting rapidly. However we would need to train longer to verify that (the learning is now slow in spite of the models being very small, because we don't use batches and we did not implement GPU). It would also be interesting to see if more data would help to tackle the overfitting issue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
